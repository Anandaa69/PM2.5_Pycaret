2025-03-13 00:51:42,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-13 00:51:42,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-13 00:51:42,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-13 00:51:42,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-13 00:51:43,016:INFO:PyCaret RegressionExperiment
2025-03-13 00:51:43,017:INFO:Logging name: reg-default-name
2025-03-13 00:51:43,017:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-13 00:51:43,017:INFO:version 3.3.2
2025-03-13 00:51:43,017:INFO:Initializing setup()
2025-03-13 00:51:43,017:INFO:self.USI: 9bef
2025-03-13 00:51:43,017:INFO:self._variable_keys: {'exp_name_log', 'fold_generator', 'html_param', 'fold_groups_param', '_ml_usecase', 'n_jobs_param', 'X_train', 'fold_shuffle_param', 'X', 'y', 'USI', 'gpu_n_jobs_param', 'seed', 'y_test', 'X_test', 'gpu_param', 'exp_id', '_available_plots', 'y_train', 'idx', 'log_plots_param', 'logging_param', 'data', 'target_param', 'transform_target_param', 'pipeline', 'memory'}
2025-03-13 00:51:43,017:INFO:Checking environment
2025-03-13 00:51:43,017:INFO:python_version: 3.11.9
2025-03-13 00:51:43,017:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-03-13 00:51:43,017:INFO:machine: AMD64
2025-03-13 00:51:43,017:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-13 00:51:43,021:INFO:Memory: svmem(total=34193833984, available=18379722752, percent=46.2, used=15814111232, free=18379722752)
2025-03-13 00:51:43,021:INFO:Physical Core: 6
2025-03-13 00:51:43,021:INFO:Logical Core: 12
2025-03-13 00:51:43,021:INFO:Checking libraries
2025-03-13 00:51:43,021:INFO:System:
2025-03-13 00:51:43,021:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-03-13 00:51:43,021:INFO:executable: d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Scripts\python.exe
2025-03-13 00:51:43,021:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-13 00:51:43,021:INFO:PyCaret required dependencies:
2025-03-13 00:51:43,035:INFO:                 pip: 24.0
2025-03-13 00:51:43,035:INFO:          setuptools: 65.5.0
2025-03-13 00:51:43,035:INFO:             pycaret: 3.3.2
2025-03-13 00:51:43,035:INFO:             IPython: 8.32.0
2025-03-13 00:51:43,035:INFO:          ipywidgets: 8.1.5
2025-03-13 00:51:43,035:INFO:                tqdm: 4.67.1
2025-03-13 00:51:43,035:INFO:               numpy: 1.26.4
2025-03-13 00:51:43,035:INFO:              pandas: 2.1.4
2025-03-13 00:51:43,035:INFO:              jinja2: 3.1.5
2025-03-13 00:51:43,035:INFO:               scipy: 1.11.4
2025-03-13 00:51:43,035:INFO:              joblib: 1.3.2
2025-03-13 00:51:43,035:INFO:             sklearn: 1.4.2
2025-03-13 00:51:43,035:INFO:                pyod: 2.0.3
2025-03-13 00:51:43,035:INFO:            imblearn: 0.13.0
2025-03-13 00:51:43,035:INFO:   category_encoders: 2.7.0
2025-03-13 00:51:43,035:INFO:            lightgbm: 4.6.0
2025-03-13 00:51:43,035:INFO:               numba: 0.61.0
2025-03-13 00:51:43,035:INFO:            requests: 2.32.3
2025-03-13 00:51:43,035:INFO:          matplotlib: 3.7.5
2025-03-13 00:51:43,035:INFO:          scikitplot: 0.3.7
2025-03-13 00:51:43,035:INFO:         yellowbrick: 1.5
2025-03-13 00:51:43,035:INFO:              plotly: 5.24.1
2025-03-13 00:51:43,035:INFO:    plotly-resampler: Not installed
2025-03-13 00:51:43,035:INFO:             kaleido: 0.2.1
2025-03-13 00:51:43,035:INFO:           schemdraw: 0.15
2025-03-13 00:51:43,035:INFO:         statsmodels: 0.14.4
2025-03-13 00:51:43,035:INFO:              sktime: 0.26.0
2025-03-13 00:51:43,035:INFO:               tbats: 1.1.3
2025-03-13 00:51:43,035:INFO:            pmdarima: 2.0.4
2025-03-13 00:51:43,035:INFO:              psutil: 7.0.0
2025-03-13 00:51:43,035:INFO:          markupsafe: 3.0.2
2025-03-13 00:51:43,035:INFO:             pickle5: Not installed
2025-03-13 00:51:43,035:INFO:         cloudpickle: 3.1.1
2025-03-13 00:51:43,035:INFO:         deprecation: 2.1.0
2025-03-13 00:51:43,037:INFO:              xxhash: 3.5.0
2025-03-13 00:51:43,037:INFO:           wurlitzer: Not installed
2025-03-13 00:51:43,037:INFO:PyCaret optional dependencies:
2025-03-13 00:51:43,045:INFO:                shap: Not installed
2025-03-13 00:51:43,045:INFO:           interpret: Not installed
2025-03-13 00:51:43,045:INFO:                umap: Not installed
2025-03-13 00:51:43,045:INFO:     ydata_profiling: Not installed
2025-03-13 00:51:43,045:INFO:  explainerdashboard: Not installed
2025-03-13 00:51:43,045:INFO:             autoviz: Not installed
2025-03-13 00:51:43,045:INFO:           fairlearn: Not installed
2025-03-13 00:51:43,045:INFO:          deepchecks: Not installed
2025-03-13 00:51:43,045:INFO:             xgboost: Not installed
2025-03-13 00:51:43,045:INFO:            catboost: Not installed
2025-03-13 00:51:43,045:INFO:              kmodes: Not installed
2025-03-13 00:51:43,045:INFO:             mlxtend: Not installed
2025-03-13 00:51:43,045:INFO:       statsforecast: Not installed
2025-03-13 00:51:43,045:INFO:        tune_sklearn: Not installed
2025-03-13 00:51:43,045:INFO:                 ray: Not installed
2025-03-13 00:51:43,045:INFO:            hyperopt: Not installed
2025-03-13 00:51:43,045:INFO:              optuna: Not installed
2025-03-13 00:51:43,045:INFO:               skopt: Not installed
2025-03-13 00:51:43,045:INFO:              mlflow: Not installed
2025-03-13 00:51:43,045:INFO:              gradio: Not installed
2025-03-13 00:51:43,045:INFO:             fastapi: Not installed
2025-03-13 00:51:43,045:INFO:             uvicorn: Not installed
2025-03-13 00:51:43,045:INFO:              m2cgen: Not installed
2025-03-13 00:51:43,045:INFO:           evidently: Not installed
2025-03-13 00:51:43,045:INFO:               fugue: Not installed
2025-03-13 00:51:43,045:INFO:           streamlit: Not installed
2025-03-13 00:51:43,045:INFO:             prophet: Not installed
2025-03-13 00:51:43,045:INFO:None
2025-03-13 00:51:43,045:INFO:Set up data.
2025-03-13 00:51:43,054:INFO:Set up folding strategy.
2025-03-13 00:51:43,054:INFO:Set up train/test split.
2025-03-13 00:51:43,058:INFO:Set up index.
2025-03-13 00:51:43,058:INFO:Assigning column types.
2025-03-13 00:51:43,064:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-13 00:51:43,066:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,067:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,071:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,114:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,143:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,146:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,148:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,188:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,215:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-13 00:51:43,221:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,222:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,268:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,295:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,298:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,301:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,338:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,370:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,371:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,371:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-13 00:51:43,376:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,412:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,443:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,450:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,486:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,515:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-13 00:51:43,560:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,634:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,662:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,662:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,662:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,662:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-13 00:51:43,705:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,734:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,783:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:51:43,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,811:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-13 00:51:43,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:43,952:INFO:Preparing preprocessing pipeline...
2025-03-13 00:51:43,954:INFO:Set up date feature engineering.
2025-03-13 00:51:43,954:INFO:Set up simple imputation.
2025-03-13 00:51:43,954:INFO:Set up removing outliers.
2025-03-13 00:51:43,989:INFO:Finished creating preprocessing pipeline.
2025-03-13 00:51:43,994:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Saeb0m\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['humidity', 'temperature', 'year',
                                             'month', 'day', 'day_of_week',
                                             'week_of_year', 'season',
                                             'dew_point', 'is_weekend',
                                             'tem...
                                             'pm_2_5_lag_4', 'pm_2_5_lag_5',
                                             'pm_2_5_lag_6', 'pm_2_5_lag_7',
                                             'pm_2_5_lag_8', 'pm_2_5_lag_9',
                                             'pm_2_5_lag_10', 'pm_2_5_lag_11',
                                             'pm_2_5_lag_12', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123)))])
2025-03-13 00:51:43,994:INFO:Creating final display dataframe.
2025-03-13 00:51:44,106:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            pm_2_5
2                   Target type        Regression
3           Original data shape         (500, 58)
4        Transformed data shape         (482, 60)
5   Transformed train set shape         (332, 60)
6    Transformed test set shape         (150, 60)
7              Numeric features                56
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13              Remove outliers              True
14           Outliers threshold              0.05
15               Fold Generator             KFold
16                  Fold Number                12
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              9bef
2025-03-13 00:51:44,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:44,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:44,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:44,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:51:44,269:INFO:setup() successfully completed in 1.27s...............
2025-03-13 00:51:44,277:INFO:Initializing compare_models()
2025-03-13 00:51:44,277:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-03-13 00:51:44,277:INFO:Checking exceptions
2025-03-13 00:51:44,281:INFO:Preparing display monitor
2025-03-13 00:51:44,298:INFO:Initializing Linear Regression
2025-03-13 00:51:44,299:INFO:Total runtime is 2.5331974029541016e-05 minutes
2025-03-13 00:51:44,302:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:44,302:INFO:Initializing create_model()
2025-03-13 00:51:44,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=lr, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:44,302:INFO:Checking exceptions
2025-03-13 00:51:44,302:INFO:Importing libraries
2025-03-13 00:51:44,302:INFO:Copying training dataset
2025-03-13 00:51:44,309:INFO:Defining folds
2025-03-13 00:51:44,309:INFO:Declaring metric variables
2025-03-13 00:51:44,311:INFO:Importing untrained model
2025-03-13 00:51:44,314:INFO:Linear Regression Imported successfully
2025-03-13 00:51:44,320:INFO:Starting cross validation
2025-03-13 00:51:44,325:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:47,772:INFO:Calculating mean and std
2025-03-13 00:51:47,774:INFO:Creating metrics dataframe
2025-03-13 00:51:47,777:INFO:Uploading results into container
2025-03-13 00:51:47,777:INFO:Uploading model into container now
2025-03-13 00:51:47,778:INFO:_master_model_container: 1
2025-03-13 00:51:47,778:INFO:_display_container: 2
2025-03-13 00:51:47,778:INFO:LinearRegression(n_jobs=-1)
2025-03-13 00:51:47,778:INFO:create_model() successfully completed......................................
2025-03-13 00:51:47,844:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:47,844:INFO:Creating metrics dataframe
2025-03-13 00:51:47,849:INFO:Initializing Lasso Regression
2025-03-13 00:51:47,849:INFO:Total runtime is 0.059177720546722413 minutes
2025-03-13 00:51:47,852:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:47,852:INFO:Initializing create_model()
2025-03-13 00:51:47,852:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=lasso, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:47,852:INFO:Checking exceptions
2025-03-13 00:51:47,852:INFO:Importing libraries
2025-03-13 00:51:47,852:INFO:Copying training dataset
2025-03-13 00:51:47,859:INFO:Defining folds
2025-03-13 00:51:47,859:INFO:Declaring metric variables
2025-03-13 00:51:47,861:INFO:Importing untrained model
2025-03-13 00:51:47,864:INFO:Lasso Regression Imported successfully
2025-03-13 00:51:47,868:INFO:Starting cross validation
2025-03-13 00:51:47,869:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:48,100:INFO:Calculating mean and std
2025-03-13 00:51:48,101:INFO:Creating metrics dataframe
2025-03-13 00:51:48,102:INFO:Uploading results into container
2025-03-13 00:51:48,102:INFO:Uploading model into container now
2025-03-13 00:51:48,102:INFO:_master_model_container: 2
2025-03-13 00:51:48,102:INFO:_display_container: 2
2025-03-13 00:51:48,104:INFO:Lasso(random_state=123)
2025-03-13 00:51:48,104:INFO:create_model() successfully completed......................................
2025-03-13 00:51:48,160:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:48,160:INFO:Creating metrics dataframe
2025-03-13 00:51:48,164:INFO:Initializing Ridge Regression
2025-03-13 00:51:48,164:INFO:Total runtime is 0.06443066596984863 minutes
2025-03-13 00:51:48,167:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:48,167:INFO:Initializing create_model()
2025-03-13 00:51:48,167:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=ridge, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:48,167:INFO:Checking exceptions
2025-03-13 00:51:48,167:INFO:Importing libraries
2025-03-13 00:51:48,167:INFO:Copying training dataset
2025-03-13 00:51:48,173:INFO:Defining folds
2025-03-13 00:51:48,173:INFO:Declaring metric variables
2025-03-13 00:51:48,174:INFO:Importing untrained model
2025-03-13 00:51:48,177:INFO:Ridge Regression Imported successfully
2025-03-13 00:51:48,185:INFO:Starting cross validation
2025-03-13 00:51:48,186:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:48,448:INFO:Calculating mean and std
2025-03-13 00:51:48,449:INFO:Creating metrics dataframe
2025-03-13 00:51:48,451:INFO:Uploading results into container
2025-03-13 00:51:48,451:INFO:Uploading model into container now
2025-03-13 00:51:48,452:INFO:_master_model_container: 3
2025-03-13 00:51:48,452:INFO:_display_container: 2
2025-03-13 00:51:48,452:INFO:Ridge(random_state=123)
2025-03-13 00:51:48,452:INFO:create_model() successfully completed......................................
2025-03-13 00:51:48,510:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:48,510:INFO:Creating metrics dataframe
2025-03-13 00:51:48,514:INFO:Initializing Elastic Net
2025-03-13 00:51:48,514:INFO:Total runtime is 0.0702679435412089 minutes
2025-03-13 00:51:48,516:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:48,517:INFO:Initializing create_model()
2025-03-13 00:51:48,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=en, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:48,517:INFO:Checking exceptions
2025-03-13 00:51:48,517:INFO:Importing libraries
2025-03-13 00:51:48,517:INFO:Copying training dataset
2025-03-13 00:51:48,523:INFO:Defining folds
2025-03-13 00:51:48,523:INFO:Declaring metric variables
2025-03-13 00:51:48,525:INFO:Importing untrained model
2025-03-13 00:51:48,528:INFO:Elastic Net Imported successfully
2025-03-13 00:51:48,534:INFO:Starting cross validation
2025-03-13 00:51:48,534:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:48,776:INFO:Calculating mean and std
2025-03-13 00:51:48,776:INFO:Creating metrics dataframe
2025-03-13 00:51:48,778:INFO:Uploading results into container
2025-03-13 00:51:48,778:INFO:Uploading model into container now
2025-03-13 00:51:48,778:INFO:_master_model_container: 4
2025-03-13 00:51:48,778:INFO:_display_container: 2
2025-03-13 00:51:48,779:INFO:ElasticNet(random_state=123)
2025-03-13 00:51:48,779:INFO:create_model() successfully completed......................................
2025-03-13 00:51:48,835:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:48,835:INFO:Creating metrics dataframe
2025-03-13 00:51:48,841:INFO:Initializing Least Angle Regression
2025-03-13 00:51:48,841:INFO:Total runtime is 0.07571347157160441 minutes
2025-03-13 00:51:48,843:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:48,843:INFO:Initializing create_model()
2025-03-13 00:51:48,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=lar, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:48,844:INFO:Checking exceptions
2025-03-13 00:51:48,844:INFO:Importing libraries
2025-03-13 00:51:48,844:INFO:Copying training dataset
2025-03-13 00:51:48,848:INFO:Defining folds
2025-03-13 00:51:48,848:INFO:Declaring metric variables
2025-03-13 00:51:48,851:INFO:Importing untrained model
2025-03-13 00:51:48,854:INFO:Least Angle Regression Imported successfully
2025-03-13 00:51:48,859:INFO:Starting cross validation
2025-03-13 00:51:48,861:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:49,047:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.326e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,049:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.508e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,050:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.457e-02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,051:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.133e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,051:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=5.205e-02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,051:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=9.775e-02, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,052:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.643e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,052:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.115e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,052:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.738e+06, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,054:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.028e-02, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,054:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.792e+06, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,056:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=3.725e+02, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,056:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=9.713e-03, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,056:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.226e-03, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,057:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.067e-03, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,057:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.694e-03, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,057:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.024e-02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,057:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.031e-03, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,064:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=9.716e+07, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,065:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.966e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,068:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.732e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,068:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.310e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,069:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=3.847e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,072:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.917e-02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,073:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.056e+03, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,075:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.260e-01, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,075:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.072e+03, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,075:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.081e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,075:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.961e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,081:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.575e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,081:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.057e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,083:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.135e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,084:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.617e-01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,084:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=1.734e+09, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,086:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=2.061e-01, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,086:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=5.030e+07, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,086:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=8.103e+09, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,087:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=4.871e+07, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,088:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.706e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,088:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.483e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,091:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.058e-01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,092:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=2.088e+04, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,092:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.204e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,092:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.201e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,108:INFO:Calculating mean and std
2025-03-13 00:51:49,109:INFO:Creating metrics dataframe
2025-03-13 00:51:49,110:INFO:Uploading results into container
2025-03-13 00:51:49,111:INFO:Uploading model into container now
2025-03-13 00:51:49,111:INFO:_master_model_container: 5
2025-03-13 00:51:49,111:INFO:_display_container: 2
2025-03-13 00:51:49,111:INFO:Lars(random_state=123)
2025-03-13 00:51:49,111:INFO:create_model() successfully completed......................................
2025-03-13 00:51:49,170:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:49,171:INFO:Creating metrics dataframe
2025-03-13 00:51:49,176:INFO:Initializing Lasso Least Angle Regression
2025-03-13 00:51:49,176:INFO:Total runtime is 0.08130501508712769 minutes
2025-03-13 00:51:49,178:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:49,178:INFO:Initializing create_model()
2025-03-13 00:51:49,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=llar, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:49,178:INFO:Checking exceptions
2025-03-13 00:51:49,178:INFO:Importing libraries
2025-03-13 00:51:49,178:INFO:Copying training dataset
2025-03-13 00:51:49,184:INFO:Defining folds
2025-03-13 00:51:49,184:INFO:Declaring metric variables
2025-03-13 00:51:49,185:INFO:Importing untrained model
2025-03-13 00:51:49,189:INFO:Lasso Least Angle Regression Imported successfully
2025-03-13 00:51:49,194:INFO:Starting cross validation
2025-03-13 00:51:49,194:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:49,394:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.966e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,395:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.653e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,402:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=1.617e+00, previous alpha=1.572e+00, with an active set of 23 regressors.
  warnings.warn(

2025-03-13 00:51:49,407:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.506e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,409:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.317e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:51:49,433:INFO:Calculating mean and std
2025-03-13 00:51:49,433:INFO:Creating metrics dataframe
2025-03-13 00:51:49,434:INFO:Uploading results into container
2025-03-13 00:51:49,434:INFO:Uploading model into container now
2025-03-13 00:51:49,436:INFO:_master_model_container: 6
2025-03-13 00:51:49,436:INFO:_display_container: 2
2025-03-13 00:51:49,436:INFO:LassoLars(random_state=123)
2025-03-13 00:51:49,436:INFO:create_model() successfully completed......................................
2025-03-13 00:51:49,492:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:49,492:INFO:Creating metrics dataframe
2025-03-13 00:51:49,499:INFO:Initializing Orthogonal Matching Pursuit
2025-03-13 00:51:49,499:INFO:Total runtime is 0.08667587041854859 minutes
2025-03-13 00:51:49,501:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:49,501:INFO:Initializing create_model()
2025-03-13 00:51:49,501:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=omp, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:49,501:INFO:Checking exceptions
2025-03-13 00:51:49,501:INFO:Importing libraries
2025-03-13 00:51:49,501:INFO:Copying training dataset
2025-03-13 00:51:49,509:INFO:Defining folds
2025-03-13 00:51:49,510:INFO:Declaring metric variables
2025-03-13 00:51:49,511:INFO:Importing untrained model
2025-03-13 00:51:49,513:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-13 00:51:49,519:INFO:Starting cross validation
2025-03-13 00:51:49,520:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:49,756:INFO:Calculating mean and std
2025-03-13 00:51:49,757:INFO:Creating metrics dataframe
2025-03-13 00:51:49,758:INFO:Uploading results into container
2025-03-13 00:51:49,759:INFO:Uploading model into container now
2025-03-13 00:51:49,759:INFO:_master_model_container: 7
2025-03-13 00:51:49,759:INFO:_display_container: 2
2025-03-13 00:51:49,759:INFO:OrthogonalMatchingPursuit()
2025-03-13 00:51:49,759:INFO:create_model() successfully completed......................................
2025-03-13 00:51:49,813:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:49,813:INFO:Creating metrics dataframe
2025-03-13 00:51:49,820:INFO:Initializing Bayesian Ridge
2025-03-13 00:51:49,820:INFO:Total runtime is 0.0920389453570048 minutes
2025-03-13 00:51:49,824:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:49,824:INFO:Initializing create_model()
2025-03-13 00:51:49,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=br, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:49,824:INFO:Checking exceptions
2025-03-13 00:51:49,824:INFO:Importing libraries
2025-03-13 00:51:49,824:INFO:Copying training dataset
2025-03-13 00:51:49,832:INFO:Defining folds
2025-03-13 00:51:49,832:INFO:Declaring metric variables
2025-03-13 00:51:49,835:INFO:Importing untrained model
2025-03-13 00:51:49,838:INFO:Bayesian Ridge Imported successfully
2025-03-13 00:51:49,842:INFO:Starting cross validation
2025-03-13 00:51:49,844:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:50,094:INFO:Calculating mean and std
2025-03-13 00:51:50,094:INFO:Creating metrics dataframe
2025-03-13 00:51:50,095:INFO:Uploading results into container
2025-03-13 00:51:50,095:INFO:Uploading model into container now
2025-03-13 00:51:50,095:INFO:_master_model_container: 8
2025-03-13 00:51:50,095:INFO:_display_container: 2
2025-03-13 00:51:50,097:INFO:BayesianRidge()
2025-03-13 00:51:50,097:INFO:create_model() successfully completed......................................
2025-03-13 00:51:50,154:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:50,154:INFO:Creating metrics dataframe
2025-03-13 00:51:50,159:INFO:Initializing Passive Aggressive Regressor
2025-03-13 00:51:50,159:INFO:Total runtime is 0.09767748117446899 minutes
2025-03-13 00:51:50,160:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:50,162:INFO:Initializing create_model()
2025-03-13 00:51:50,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=par, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:50,162:INFO:Checking exceptions
2025-03-13 00:51:50,162:INFO:Importing libraries
2025-03-13 00:51:50,162:INFO:Copying training dataset
2025-03-13 00:51:50,168:INFO:Defining folds
2025-03-13 00:51:50,168:INFO:Declaring metric variables
2025-03-13 00:51:50,169:INFO:Importing untrained model
2025-03-13 00:51:50,172:INFO:Passive Aggressive Regressor Imported successfully
2025-03-13 00:51:50,181:INFO:Starting cross validation
2025-03-13 00:51:50,183:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:50,451:INFO:Calculating mean and std
2025-03-13 00:51:50,451:INFO:Creating metrics dataframe
2025-03-13 00:51:50,453:INFO:Uploading results into container
2025-03-13 00:51:50,453:INFO:Uploading model into container now
2025-03-13 00:51:50,453:INFO:_master_model_container: 9
2025-03-13 00:51:50,453:INFO:_display_container: 2
2025-03-13 00:51:50,455:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-13 00:51:50,455:INFO:create_model() successfully completed......................................
2025-03-13 00:51:50,509:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:50,509:INFO:Creating metrics dataframe
2025-03-13 00:51:50,514:INFO:Initializing Huber Regressor
2025-03-13 00:51:50,514:INFO:Total runtime is 0.1035966157913208 minutes
2025-03-13 00:51:50,517:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:50,517:INFO:Initializing create_model()
2025-03-13 00:51:50,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=huber, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:50,517:INFO:Checking exceptions
2025-03-13 00:51:50,517:INFO:Importing libraries
2025-03-13 00:51:50,517:INFO:Copying training dataset
2025-03-13 00:51:50,523:INFO:Defining folds
2025-03-13 00:51:50,523:INFO:Declaring metric variables
2025-03-13 00:51:50,524:INFO:Importing untrained model
2025-03-13 00:51:50,527:INFO:Huber Regressor Imported successfully
2025-03-13 00:51:50,531:INFO:Starting cross validation
2025-03-13 00:51:50,532:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:50,726:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:51:50,726:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:51:50,730:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:51:50,733:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:51:50,747:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:51:50,747:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:51:50,751:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:51:50,755:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:51:50,760:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:51:50,760:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:51:50,763:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:51:50,766:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:51:50,784:INFO:Calculating mean and std
2025-03-13 00:51:50,784:INFO:Creating metrics dataframe
2025-03-13 00:51:50,785:INFO:Uploading results into container
2025-03-13 00:51:50,785:INFO:Uploading model into container now
2025-03-13 00:51:50,787:INFO:_master_model_container: 10
2025-03-13 00:51:50,787:INFO:_display_container: 2
2025-03-13 00:51:50,787:INFO:HuberRegressor()
2025-03-13 00:51:50,787:INFO:create_model() successfully completed......................................
2025-03-13 00:51:50,847:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:50,847:INFO:Creating metrics dataframe
2025-03-13 00:51:50,854:INFO:Initializing K Neighbors Regressor
2025-03-13 00:51:50,854:INFO:Total runtime is 0.10926887591679892 minutes
2025-03-13 00:51:50,856:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:50,856:INFO:Initializing create_model()
2025-03-13 00:51:50,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=knn, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:50,856:INFO:Checking exceptions
2025-03-13 00:51:50,856:INFO:Importing libraries
2025-03-13 00:51:50,856:INFO:Copying training dataset
2025-03-13 00:51:50,861:INFO:Defining folds
2025-03-13 00:51:50,861:INFO:Declaring metric variables
2025-03-13 00:51:50,864:INFO:Importing untrained model
2025-03-13 00:51:50,866:INFO:K Neighbors Regressor Imported successfully
2025-03-13 00:51:50,872:INFO:Starting cross validation
2025-03-13 00:51:50,872:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:51,250:INFO:Calculating mean and std
2025-03-13 00:51:51,251:INFO:Creating metrics dataframe
2025-03-13 00:51:51,252:INFO:Uploading results into container
2025-03-13 00:51:51,252:INFO:Uploading model into container now
2025-03-13 00:51:51,254:INFO:_master_model_container: 11
2025-03-13 00:51:51,254:INFO:_display_container: 2
2025-03-13 00:51:51,254:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-13 00:51:51,254:INFO:create_model() successfully completed......................................
2025-03-13 00:51:51,307:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:51,308:INFO:Creating metrics dataframe
2025-03-13 00:51:51,312:INFO:Initializing Decision Tree Regressor
2025-03-13 00:51:51,312:INFO:Total runtime is 0.11690877676010132 minutes
2025-03-13 00:51:51,316:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:51,316:INFO:Initializing create_model()
2025-03-13 00:51:51,316:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=dt, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:51,316:INFO:Checking exceptions
2025-03-13 00:51:51,316:INFO:Importing libraries
2025-03-13 00:51:51,316:INFO:Copying training dataset
2025-03-13 00:51:51,322:INFO:Defining folds
2025-03-13 00:51:51,323:INFO:Declaring metric variables
2025-03-13 00:51:51,324:INFO:Importing untrained model
2025-03-13 00:51:51,326:INFO:Decision Tree Regressor Imported successfully
2025-03-13 00:51:51,330:INFO:Starting cross validation
2025-03-13 00:51:51,331:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:51,579:INFO:Calculating mean and std
2025-03-13 00:51:51,579:INFO:Creating metrics dataframe
2025-03-13 00:51:51,580:INFO:Uploading results into container
2025-03-13 00:51:51,580:INFO:Uploading model into container now
2025-03-13 00:51:51,580:INFO:_master_model_container: 12
2025-03-13 00:51:51,580:INFO:_display_container: 2
2025-03-13 00:51:51,582:INFO:DecisionTreeRegressor(random_state=123)
2025-03-13 00:51:51,582:INFO:create_model() successfully completed......................................
2025-03-13 00:51:51,639:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:51,639:INFO:Creating metrics dataframe
2025-03-13 00:51:51,644:INFO:Initializing Random Forest Regressor
2025-03-13 00:51:51,644:INFO:Total runtime is 0.12242911656697592 minutes
2025-03-13 00:51:51,647:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:51,647:INFO:Initializing create_model()
2025-03-13 00:51:51,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=rf, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:51,647:INFO:Checking exceptions
2025-03-13 00:51:51,647:INFO:Importing libraries
2025-03-13 00:51:51,647:INFO:Copying training dataset
2025-03-13 00:51:51,654:INFO:Defining folds
2025-03-13 00:51:51,654:INFO:Declaring metric variables
2025-03-13 00:51:51,656:INFO:Importing untrained model
2025-03-13 00:51:51,659:INFO:Random Forest Regressor Imported successfully
2025-03-13 00:51:51,663:INFO:Starting cross validation
2025-03-13 00:51:51,663:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:53,090:INFO:Calculating mean and std
2025-03-13 00:51:53,099:INFO:Creating metrics dataframe
2025-03-13 00:51:53,104:INFO:Uploading results into container
2025-03-13 00:51:53,104:INFO:Uploading model into container now
2025-03-13 00:51:53,104:INFO:_master_model_container: 13
2025-03-13 00:51:53,104:INFO:_display_container: 2
2025-03-13 00:51:53,106:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:51:53,106:INFO:create_model() successfully completed......................................
2025-03-13 00:51:53,198:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:53,198:INFO:Creating metrics dataframe
2025-03-13 00:51:53,205:INFO:Initializing Extra Trees Regressor
2025-03-13 00:51:53,207:INFO:Total runtime is 0.14845012029012045 minutes
2025-03-13 00:51:53,208:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:53,208:INFO:Initializing create_model()
2025-03-13 00:51:53,208:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=et, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:53,208:INFO:Checking exceptions
2025-03-13 00:51:53,208:INFO:Importing libraries
2025-03-13 00:51:53,208:INFO:Copying training dataset
2025-03-13 00:51:53,217:INFO:Defining folds
2025-03-13 00:51:53,217:INFO:Declaring metric variables
2025-03-13 00:51:53,220:INFO:Importing untrained model
2025-03-13 00:51:53,221:INFO:Extra Trees Regressor Imported successfully
2025-03-13 00:51:53,225:INFO:Starting cross validation
2025-03-13 00:51:53,225:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:54,054:INFO:Calculating mean and std
2025-03-13 00:51:54,055:INFO:Creating metrics dataframe
2025-03-13 00:51:54,056:INFO:Uploading results into container
2025-03-13 00:51:54,056:INFO:Uploading model into container now
2025-03-13 00:51:54,056:INFO:_master_model_container: 14
2025-03-13 00:51:54,056:INFO:_display_container: 2
2025-03-13 00:51:54,058:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:51:54,058:INFO:create_model() successfully completed......................................
2025-03-13 00:51:54,112:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:54,112:INFO:Creating metrics dataframe
2025-03-13 00:51:54,118:INFO:Initializing AdaBoost Regressor
2025-03-13 00:51:54,118:INFO:Total runtime is 0.1636738141377767 minutes
2025-03-13 00:51:54,122:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:54,122:INFO:Initializing create_model()
2025-03-13 00:51:54,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=ada, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:54,122:INFO:Checking exceptions
2025-03-13 00:51:54,122:INFO:Importing libraries
2025-03-13 00:51:54,122:INFO:Copying training dataset
2025-03-13 00:51:54,130:INFO:Defining folds
2025-03-13 00:51:54,130:INFO:Declaring metric variables
2025-03-13 00:51:54,132:INFO:Importing untrained model
2025-03-13 00:51:54,140:INFO:AdaBoost Regressor Imported successfully
2025-03-13 00:51:54,154:INFO:Starting cross validation
2025-03-13 00:51:54,155:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:54,652:INFO:Calculating mean and std
2025-03-13 00:51:54,652:INFO:Creating metrics dataframe
2025-03-13 00:51:54,654:INFO:Uploading results into container
2025-03-13 00:51:54,656:INFO:Uploading model into container now
2025-03-13 00:51:54,656:INFO:_master_model_container: 15
2025-03-13 00:51:54,656:INFO:_display_container: 2
2025-03-13 00:51:54,656:INFO:AdaBoostRegressor(random_state=123)
2025-03-13 00:51:54,656:INFO:create_model() successfully completed......................................
2025-03-13 00:51:54,716:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:54,716:INFO:Creating metrics dataframe
2025-03-13 00:51:54,721:INFO:Initializing Gradient Boosting Regressor
2025-03-13 00:51:54,721:INFO:Total runtime is 0.17371129592259726 minutes
2025-03-13 00:51:54,724:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:54,724:INFO:Initializing create_model()
2025-03-13 00:51:54,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=gbr, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:54,724:INFO:Checking exceptions
2025-03-13 00:51:54,724:INFO:Importing libraries
2025-03-13 00:51:54,724:INFO:Copying training dataset
2025-03-13 00:51:54,729:INFO:Defining folds
2025-03-13 00:51:54,729:INFO:Declaring metric variables
2025-03-13 00:51:54,732:INFO:Importing untrained model
2025-03-13 00:51:54,735:INFO:Gradient Boosting Regressor Imported successfully
2025-03-13 00:51:54,740:INFO:Starting cross validation
2025-03-13 00:51:54,741:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:55,599:INFO:Calculating mean and std
2025-03-13 00:51:55,600:INFO:Creating metrics dataframe
2025-03-13 00:51:55,600:INFO:Uploading results into container
2025-03-13 00:51:55,602:INFO:Uploading model into container now
2025-03-13 00:51:55,602:INFO:_master_model_container: 16
2025-03-13 00:51:55,602:INFO:_display_container: 2
2025-03-13 00:51:55,602:INFO:GradientBoostingRegressor(random_state=123)
2025-03-13 00:51:55,602:INFO:create_model() successfully completed......................................
2025-03-13 00:51:55,658:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:55,658:INFO:Creating metrics dataframe
2025-03-13 00:51:55,664:INFO:Initializing Light Gradient Boosting Machine
2025-03-13 00:51:55,664:INFO:Total runtime is 0.18943433364232382 minutes
2025-03-13 00:51:55,667:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:55,667:INFO:Initializing create_model()
2025-03-13 00:51:55,667:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=lightgbm, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:55,667:INFO:Checking exceptions
2025-03-13 00:51:55,667:INFO:Importing libraries
2025-03-13 00:51:55,669:INFO:Copying training dataset
2025-03-13 00:51:55,674:INFO:Defining folds
2025-03-13 00:51:55,674:INFO:Declaring metric variables
2025-03-13 00:51:55,675:INFO:Importing untrained model
2025-03-13 00:51:55,678:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-13 00:51:55,683:INFO:Starting cross validation
2025-03-13 00:51:55,684:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:56,410:INFO:Calculating mean and std
2025-03-13 00:51:56,411:INFO:Creating metrics dataframe
2025-03-13 00:51:56,412:INFO:Uploading results into container
2025-03-13 00:51:56,412:INFO:Uploading model into container now
2025-03-13 00:51:56,412:INFO:_master_model_container: 17
2025-03-13 00:51:56,414:INFO:_display_container: 2
2025-03-13 00:51:56,414:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:51:56,414:INFO:create_model() successfully completed......................................
2025-03-13 00:51:56,484:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:56,485:INFO:Creating metrics dataframe
2025-03-13 00:51:56,494:INFO:Initializing Dummy Regressor
2025-03-13 00:51:56,494:INFO:Total runtime is 0.20326321919759116 minutes
2025-03-13 00:51:56,497:INFO:SubProcess create_model() called ==================================
2025-03-13 00:51:56,497:INFO:Initializing create_model()
2025-03-13 00:51:56,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=dummy, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A788D8290>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:56,497:INFO:Checking exceptions
2025-03-13 00:51:56,497:INFO:Importing libraries
2025-03-13 00:51:56,497:INFO:Copying training dataset
2025-03-13 00:51:56,506:INFO:Defining folds
2025-03-13 00:51:56,506:INFO:Declaring metric variables
2025-03-13 00:51:56,508:INFO:Importing untrained model
2025-03-13 00:51:56,512:INFO:Dummy Regressor Imported successfully
2025-03-13 00:51:56,517:INFO:Starting cross validation
2025-03-13 00:51:56,517:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:51:56,741:INFO:Calculating mean and std
2025-03-13 00:51:56,741:INFO:Creating metrics dataframe
2025-03-13 00:51:56,742:INFO:Uploading results into container
2025-03-13 00:51:56,742:INFO:Uploading model into container now
2025-03-13 00:51:56,742:INFO:_master_model_container: 18
2025-03-13 00:51:56,744:INFO:_display_container: 2
2025-03-13 00:51:56,744:INFO:DummyRegressor()
2025-03-13 00:51:56,744:INFO:create_model() successfully completed......................................
2025-03-13 00:51:56,799:INFO:SubProcess create_model() end ==================================
2025-03-13 00:51:56,799:INFO:Creating metrics dataframe
2025-03-13 00:51:56,807:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-03-13 00:51:56,811:INFO:Initializing create_model()
2025-03-13 00:51:56,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:56,811:INFO:Checking exceptions
2025-03-13 00:51:56,813:INFO:Importing libraries
2025-03-13 00:51:56,813:INFO:Copying training dataset
2025-03-13 00:51:56,817:INFO:Defining folds
2025-03-13 00:51:56,817:INFO:Declaring metric variables
2025-03-13 00:51:56,819:INFO:Importing untrained model
2025-03-13 00:51:56,819:INFO:Declaring custom model
2025-03-13 00:51:56,819:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-13 00:51:56,819:INFO:Cross validation set to False
2025-03-13 00:51:56,819:INFO:Fitting Model
2025-03-13 00:51:56,917:INFO:OrthogonalMatchingPursuit()
2025-03-13 00:51:56,917:INFO:create_model() successfully completed......................................
2025-03-13 00:51:56,974:INFO:Initializing create_model()
2025-03-13 00:51:56,975:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:56,975:INFO:Checking exceptions
2025-03-13 00:51:56,977:INFO:Importing libraries
2025-03-13 00:51:56,977:INFO:Copying training dataset
2025-03-13 00:51:56,983:INFO:Defining folds
2025-03-13 00:51:56,983:INFO:Declaring metric variables
2025-03-13 00:51:56,983:INFO:Importing untrained model
2025-03-13 00:51:56,983:INFO:Declaring custom model
2025-03-13 00:51:56,984:INFO:AdaBoost Regressor Imported successfully
2025-03-13 00:51:56,984:INFO:Cross validation set to False
2025-03-13 00:51:56,984:INFO:Fitting Model
2025-03-13 00:51:57,216:INFO:AdaBoostRegressor(random_state=123)
2025-03-13 00:51:57,216:INFO:create_model() successfully completed......................................
2025-03-13 00:51:57,277:INFO:Initializing create_model()
2025-03-13 00:51:57,277:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:57,278:INFO:Checking exceptions
2025-03-13 00:51:57,278:INFO:Importing libraries
2025-03-13 00:51:57,278:INFO:Copying training dataset
2025-03-13 00:51:57,286:INFO:Defining folds
2025-03-13 00:51:57,286:INFO:Declaring metric variables
2025-03-13 00:51:57,286:INFO:Importing untrained model
2025-03-13 00:51:57,286:INFO:Declaring custom model
2025-03-13 00:51:57,288:INFO:Extra Trees Regressor Imported successfully
2025-03-13 00:51:57,288:INFO:Cross validation set to False
2025-03-13 00:51:57,288:INFO:Fitting Model
2025-03-13 00:51:57,468:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:51:57,468:INFO:create_model() successfully completed......................................
2025-03-13 00:51:57,527:INFO:Initializing create_model()
2025-03-13 00:51:57,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=BayesianRidge(), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:57,527:INFO:Checking exceptions
2025-03-13 00:51:57,530:INFO:Importing libraries
2025-03-13 00:51:57,531:INFO:Copying training dataset
2025-03-13 00:51:57,537:INFO:Defining folds
2025-03-13 00:51:57,537:INFO:Declaring metric variables
2025-03-13 00:51:57,537:INFO:Importing untrained model
2025-03-13 00:51:57,537:INFO:Declaring custom model
2025-03-13 00:51:57,537:INFO:Bayesian Ridge Imported successfully
2025-03-13 00:51:57,538:INFO:Cross validation set to False
2025-03-13 00:51:57,538:INFO:Fitting Model
2025-03-13 00:51:57,645:INFO:BayesianRidge()
2025-03-13 00:51:57,645:INFO:create_model() successfully completed......................................
2025-03-13 00:51:57,705:INFO:Initializing create_model()
2025-03-13 00:51:57,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=LassoLars(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:57,705:INFO:Checking exceptions
2025-03-13 00:51:57,707:INFO:Importing libraries
2025-03-13 00:51:57,707:INFO:Copying training dataset
2025-03-13 00:51:57,716:INFO:Defining folds
2025-03-13 00:51:57,716:INFO:Declaring metric variables
2025-03-13 00:51:57,716:INFO:Importing untrained model
2025-03-13 00:51:57,716:INFO:Declaring custom model
2025-03-13 00:51:57,716:INFO:Lasso Least Angle Regression Imported successfully
2025-03-13 00:51:57,716:INFO:Cross validation set to False
2025-03-13 00:51:57,716:INFO:Fitting Model
2025-03-13 00:51:57,807:INFO:LassoLars(random_state=123)
2025-03-13 00:51:57,807:INFO:create_model() successfully completed......................................
2025-03-13 00:51:57,871:INFO:Initializing create_model()
2025-03-13 00:51:57,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=Lasso(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:57,872:INFO:Checking exceptions
2025-03-13 00:51:57,872:INFO:Importing libraries
2025-03-13 00:51:57,874:INFO:Copying training dataset
2025-03-13 00:51:57,878:INFO:Defining folds
2025-03-13 00:51:57,879:INFO:Declaring metric variables
2025-03-13 00:51:57,879:INFO:Importing untrained model
2025-03-13 00:51:57,879:INFO:Declaring custom model
2025-03-13 00:51:57,880:INFO:Lasso Regression Imported successfully
2025-03-13 00:51:57,880:INFO:Cross validation set to False
2025-03-13 00:51:57,880:INFO:Fitting Model
2025-03-13 00:51:57,973:INFO:Lasso(random_state=123)
2025-03-13 00:51:57,973:INFO:create_model() successfully completed......................................
2025-03-13 00:51:58,032:INFO:Initializing create_model()
2025-03-13 00:51:58,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:58,032:INFO:Checking exceptions
2025-03-13 00:51:58,034:INFO:Importing libraries
2025-03-13 00:51:58,034:INFO:Copying training dataset
2025-03-13 00:51:58,042:INFO:Defining folds
2025-03-13 00:51:58,042:INFO:Declaring metric variables
2025-03-13 00:51:58,042:INFO:Importing untrained model
2025-03-13 00:51:58,042:INFO:Declaring custom model
2025-03-13 00:51:58,042:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-13 00:51:58,043:INFO:Cross validation set to False
2025-03-13 00:51:58,043:INFO:Fitting Model
2025-03-13 00:51:58,141:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001112 seconds.
2025-03-13 00:51:58,141:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-13 00:51:58,141:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-13 00:51:58,142:INFO:[LightGBM] [Info] Total Bins 5183
2025-03-13 00:51:58,142:INFO:[LightGBM] [Info] Number of data points in the train set: 332, number of used features: 59
2025-03-13 00:51:58,144:INFO:[LightGBM] [Info] Start training from score 20.304244
2025-03-13 00:51:58,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:51:58,191:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:51:58,191:INFO:create_model() successfully completed......................................
2025-03-13 00:51:58,257:INFO:Initializing create_model()
2025-03-13 00:51:58,257:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=HuberRegressor(), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:58,257:INFO:Checking exceptions
2025-03-13 00:51:58,258:INFO:Importing libraries
2025-03-13 00:51:58,259:INFO:Copying training dataset
2025-03-13 00:51:58,267:INFO:Defining folds
2025-03-13 00:51:58,267:INFO:Declaring metric variables
2025-03-13 00:51:58,267:INFO:Importing untrained model
2025-03-13 00:51:58,267:INFO:Declaring custom model
2025-03-13 00:51:58,267:INFO:Huber Regressor Imported successfully
2025-03-13 00:51:58,268:INFO:Cross validation set to False
2025-03-13 00:51:58,268:INFO:Fitting Model
2025-03-13 00:51:58,400:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:51:58,401:INFO:HuberRegressor()
2025-03-13 00:51:58,401:INFO:create_model() successfully completed......................................
2025-03-13 00:51:58,457:INFO:Initializing create_model()
2025-03-13 00:51:58,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:58,457:INFO:Checking exceptions
2025-03-13 00:51:58,458:INFO:Importing libraries
2025-03-13 00:51:58,458:INFO:Copying training dataset
2025-03-13 00:51:58,464:INFO:Defining folds
2025-03-13 00:51:58,464:INFO:Declaring metric variables
2025-03-13 00:51:58,464:INFO:Importing untrained model
2025-03-13 00:51:58,464:INFO:Declaring custom model
2025-03-13 00:51:58,466:INFO:Gradient Boosting Regressor Imported successfully
2025-03-13 00:51:58,466:INFO:Cross validation set to False
2025-03-13 00:51:58,466:INFO:Fitting Model
2025-03-13 00:51:59,017:INFO:GradientBoostingRegressor(random_state=123)
2025-03-13 00:51:59,017:INFO:create_model() successfully completed......................................
2025-03-13 00:51:59,075:INFO:Initializing create_model()
2025-03-13 00:51:59,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=ElasticNet(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:59,075:INFO:Checking exceptions
2025-03-13 00:51:59,076:INFO:Importing libraries
2025-03-13 00:51:59,076:INFO:Copying training dataset
2025-03-13 00:51:59,082:INFO:Defining folds
2025-03-13 00:51:59,082:INFO:Declaring metric variables
2025-03-13 00:51:59,082:INFO:Importing untrained model
2025-03-13 00:51:59,082:INFO:Declaring custom model
2025-03-13 00:51:59,082:INFO:Elastic Net Imported successfully
2025-03-13 00:51:59,084:INFO:Cross validation set to False
2025-03-13 00:51:59,084:INFO:Fitting Model
2025-03-13 00:51:59,175:INFO:ElasticNet(random_state=123)
2025-03-13 00:51:59,175:INFO:create_model() successfully completed......................................
2025-03-13 00:51:59,235:INFO:Initializing create_model()
2025-03-13 00:51:59,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:59,237:INFO:Checking exceptions
2025-03-13 00:51:59,238:INFO:Importing libraries
2025-03-13 00:51:59,238:INFO:Copying training dataset
2025-03-13 00:51:59,244:INFO:Defining folds
2025-03-13 00:51:59,244:INFO:Declaring metric variables
2025-03-13 00:51:59,244:INFO:Importing untrained model
2025-03-13 00:51:59,244:INFO:Declaring custom model
2025-03-13 00:51:59,244:INFO:Random Forest Regressor Imported successfully
2025-03-13 00:51:59,244:INFO:Cross validation set to False
2025-03-13 00:51:59,244:INFO:Fitting Model
2025-03-13 00:51:59,485:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:51:59,485:INFO:create_model() successfully completed......................................
2025-03-13 00:51:59,544:INFO:Initializing create_model()
2025-03-13 00:51:59,544:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=Ridge(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:59,544:INFO:Checking exceptions
2025-03-13 00:51:59,545:INFO:Importing libraries
2025-03-13 00:51:59,545:INFO:Copying training dataset
2025-03-13 00:51:59,551:INFO:Defining folds
2025-03-13 00:51:59,551:INFO:Declaring metric variables
2025-03-13 00:51:59,551:INFO:Importing untrained model
2025-03-13 00:51:59,551:INFO:Declaring custom model
2025-03-13 00:51:59,551:INFO:Ridge Regression Imported successfully
2025-03-13 00:51:59,551:INFO:Cross validation set to False
2025-03-13 00:51:59,551:INFO:Fitting Model
2025-03-13 00:51:59,646:INFO:Ridge(random_state=123)
2025-03-13 00:51:59,646:INFO:create_model() successfully completed......................................
2025-03-13 00:51:59,716:INFO:Initializing create_model()
2025-03-13 00:51:59,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:59,716:INFO:Checking exceptions
2025-03-13 00:51:59,718:INFO:Importing libraries
2025-03-13 00:51:59,718:INFO:Copying training dataset
2025-03-13 00:51:59,724:INFO:Defining folds
2025-03-13 00:51:59,724:INFO:Declaring metric variables
2025-03-13 00:51:59,724:INFO:Importing untrained model
2025-03-13 00:51:59,724:INFO:Declaring custom model
2025-03-13 00:51:59,724:INFO:Linear Regression Imported successfully
2025-03-13 00:51:59,725:INFO:Cross validation set to False
2025-03-13 00:51:59,725:INFO:Fitting Model
2025-03-13 00:51:59,820:INFO:LinearRegression(n_jobs=-1)
2025-03-13 00:51:59,820:INFO:create_model() successfully completed......................................
2025-03-13 00:51:59,880:INFO:Initializing create_model()
2025-03-13 00:51:59,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:51:59,880:INFO:Checking exceptions
2025-03-13 00:51:59,881:INFO:Importing libraries
2025-03-13 00:51:59,881:INFO:Copying training dataset
2025-03-13 00:51:59,889:INFO:Defining folds
2025-03-13 00:51:59,889:INFO:Declaring metric variables
2025-03-13 00:51:59,889:INFO:Importing untrained model
2025-03-13 00:51:59,889:INFO:Declaring custom model
2025-03-13 00:51:59,889:INFO:K Neighbors Regressor Imported successfully
2025-03-13 00:51:59,890:INFO:Cross validation set to False
2025-03-13 00:51:59,890:INFO:Fitting Model
2025-03-13 00:51:59,983:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-13 00:51:59,983:INFO:create_model() successfully completed......................................
2025-03-13 00:52:00,056:INFO:Initializing create_model()
2025-03-13 00:52:00,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=DummyRegressor(), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:52:00,056:INFO:Checking exceptions
2025-03-13 00:52:00,058:INFO:Importing libraries
2025-03-13 00:52:00,058:INFO:Copying training dataset
2025-03-13 00:52:00,068:INFO:Defining folds
2025-03-13 00:52:00,068:INFO:Declaring metric variables
2025-03-13 00:52:00,068:INFO:Importing untrained model
2025-03-13 00:52:00,068:INFO:Declaring custom model
2025-03-13 00:52:00,068:INFO:Dummy Regressor Imported successfully
2025-03-13 00:52:00,069:INFO:Cross validation set to False
2025-03-13 00:52:00,069:INFO:Fitting Model
2025-03-13 00:52:00,167:INFO:DummyRegressor()
2025-03-13 00:52:00,167:INFO:create_model() successfully completed......................................
2025-03-13 00:52:00,240:INFO:_master_model_container: 18
2025-03-13 00:52:00,240:INFO:_display_container: 2
2025-03-13 00:52:00,241:INFO:[OrthogonalMatchingPursuit(), AdaBoostRegressor(random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123), BayesianRidge(), LassoLars(random_state=123), Lasso(random_state=123), LGBMRegressor(n_jobs=-1, random_state=123), HuberRegressor(), GradientBoostingRegressor(random_state=123), ElasticNet(random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), Ridge(random_state=123), LinearRegression(n_jobs=-1), KNeighborsRegressor(n_jobs=-1), DummyRegressor()]
2025-03-13 00:52:00,241:INFO:compare_models() successfully completed......................................
2025-03-13 00:53:00,283:INFO:Initializing create_model()
2025-03-13 00:53:00,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:00,284:INFO:Checking exceptions
2025-03-13 00:53:00,294:INFO:Importing libraries
2025-03-13 00:53:00,294:INFO:Copying training dataset
2025-03-13 00:53:00,302:INFO:Defining folds
2025-03-13 00:53:00,302:INFO:Declaring metric variables
2025-03-13 00:53:00,305:INFO:Importing untrained model
2025-03-13 00:53:00,307:INFO:Random Forest Regressor Imported successfully
2025-03-13 00:53:00,312:INFO:Starting cross validation
2025-03-13 00:53:00,312:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:01,831:INFO:Calculating mean and std
2025-03-13 00:53:01,831:INFO:Creating metrics dataframe
2025-03-13 00:53:01,835:INFO:Finalizing model
2025-03-13 00:53:02,117:INFO:Uploading results into container
2025-03-13 00:53:02,117:INFO:Uploading model into container now
2025-03-13 00:53:02,125:INFO:_master_model_container: 19
2025-03-13 00:53:02,125:INFO:_display_container: 3
2025-03-13 00:53:02,125:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:53:02,125:INFO:create_model() successfully completed......................................
2025-03-13 00:53:09,187:INFO:Initializing predict_model()
2025-03-13 00:53:09,187:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A761A7890>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026A5C2D5080>)
2025-03-13 00:53:09,187:INFO:Checking exceptions
2025-03-13 00:53:09,187:INFO:Preloading libraries
2025-03-13 00:53:09,188:INFO:Set up data.
2025-03-13 00:53:09,199:INFO:Set up index.
2025-03-13 00:53:28,423:INFO:PyCaret RegressionExperiment
2025-03-13 00:53:28,423:INFO:Logging name: reg-default-name
2025-03-13 00:53:28,423:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-13 00:53:28,423:INFO:version 3.3.2
2025-03-13 00:53:28,423:INFO:Initializing setup()
2025-03-13 00:53:28,423:INFO:self.USI: c87c
2025-03-13 00:53:28,423:INFO:self._variable_keys: {'exp_name_log', 'fold_generator', 'html_param', 'fold_groups_param', '_ml_usecase', 'n_jobs_param', 'X_train', 'fold_shuffle_param', 'X', 'y', 'USI', 'gpu_n_jobs_param', 'seed', 'y_test', 'X_test', 'gpu_param', 'exp_id', '_available_plots', 'y_train', 'idx', 'log_plots_param', 'logging_param', 'data', 'target_param', 'transform_target_param', 'pipeline', 'memory'}
2025-03-13 00:53:28,423:INFO:Checking environment
2025-03-13 00:53:28,423:INFO:python_version: 3.11.9
2025-03-13 00:53:28,423:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-03-13 00:53:28,423:INFO:machine: AMD64
2025-03-13 00:53:28,423:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-13 00:53:28,427:INFO:Memory: svmem(total=34193833984, available=16642449408, percent=51.3, used=17551384576, free=16642449408)
2025-03-13 00:53:28,427:INFO:Physical Core: 6
2025-03-13 00:53:28,427:INFO:Logical Core: 12
2025-03-13 00:53:28,427:INFO:Checking libraries
2025-03-13 00:53:28,427:INFO:System:
2025-03-13 00:53:28,427:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-03-13 00:53:28,427:INFO:executable: d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Scripts\python.exe
2025-03-13 00:53:28,427:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-13 00:53:28,427:INFO:PyCaret required dependencies:
2025-03-13 00:53:28,427:INFO:                 pip: 24.0
2025-03-13 00:53:28,427:INFO:          setuptools: 65.5.0
2025-03-13 00:53:28,427:INFO:             pycaret: 3.3.2
2025-03-13 00:53:28,427:INFO:             IPython: 8.32.0
2025-03-13 00:53:28,427:INFO:          ipywidgets: 8.1.5
2025-03-13 00:53:28,427:INFO:                tqdm: 4.67.1
2025-03-13 00:53:28,427:INFO:               numpy: 1.26.4
2025-03-13 00:53:28,427:INFO:              pandas: 2.1.4
2025-03-13 00:53:28,427:INFO:              jinja2: 3.1.5
2025-03-13 00:53:28,427:INFO:               scipy: 1.11.4
2025-03-13 00:53:28,427:INFO:              joblib: 1.3.2
2025-03-13 00:53:28,427:INFO:             sklearn: 1.4.2
2025-03-13 00:53:28,427:INFO:                pyod: 2.0.3
2025-03-13 00:53:28,427:INFO:            imblearn: 0.13.0
2025-03-13 00:53:28,427:INFO:   category_encoders: 2.7.0
2025-03-13 00:53:28,427:INFO:            lightgbm: 4.6.0
2025-03-13 00:53:28,429:INFO:               numba: 0.61.0
2025-03-13 00:53:28,429:INFO:            requests: 2.32.3
2025-03-13 00:53:28,429:INFO:          matplotlib: 3.7.5
2025-03-13 00:53:28,429:INFO:          scikitplot: 0.3.7
2025-03-13 00:53:28,429:INFO:         yellowbrick: 1.5
2025-03-13 00:53:28,429:INFO:              plotly: 5.24.1
2025-03-13 00:53:28,429:INFO:    plotly-resampler: Not installed
2025-03-13 00:53:28,429:INFO:             kaleido: 0.2.1
2025-03-13 00:53:28,429:INFO:           schemdraw: 0.15
2025-03-13 00:53:28,429:INFO:         statsmodels: 0.14.4
2025-03-13 00:53:28,429:INFO:              sktime: 0.26.0
2025-03-13 00:53:28,429:INFO:               tbats: 1.1.3
2025-03-13 00:53:28,429:INFO:            pmdarima: 2.0.4
2025-03-13 00:53:28,429:INFO:              psutil: 7.0.0
2025-03-13 00:53:28,429:INFO:          markupsafe: 3.0.2
2025-03-13 00:53:28,429:INFO:             pickle5: Not installed
2025-03-13 00:53:28,429:INFO:         cloudpickle: 3.1.1
2025-03-13 00:53:28,429:INFO:         deprecation: 2.1.0
2025-03-13 00:53:28,429:INFO:              xxhash: 3.5.0
2025-03-13 00:53:28,429:INFO:           wurlitzer: Not installed
2025-03-13 00:53:28,429:INFO:PyCaret optional dependencies:
2025-03-13 00:53:28,429:INFO:                shap: Not installed
2025-03-13 00:53:28,429:INFO:           interpret: Not installed
2025-03-13 00:53:28,429:INFO:                umap: Not installed
2025-03-13 00:53:28,429:INFO:     ydata_profiling: Not installed
2025-03-13 00:53:28,429:INFO:  explainerdashboard: Not installed
2025-03-13 00:53:28,429:INFO:             autoviz: Not installed
2025-03-13 00:53:28,429:INFO:           fairlearn: Not installed
2025-03-13 00:53:28,429:INFO:          deepchecks: Not installed
2025-03-13 00:53:28,429:INFO:             xgboost: Not installed
2025-03-13 00:53:28,429:INFO:            catboost: Not installed
2025-03-13 00:53:28,429:INFO:              kmodes: Not installed
2025-03-13 00:53:28,429:INFO:             mlxtend: Not installed
2025-03-13 00:53:28,429:INFO:       statsforecast: Not installed
2025-03-13 00:53:28,429:INFO:        tune_sklearn: Not installed
2025-03-13 00:53:28,429:INFO:                 ray: Not installed
2025-03-13 00:53:28,429:INFO:            hyperopt: Not installed
2025-03-13 00:53:28,429:INFO:              optuna: Not installed
2025-03-13 00:53:28,429:INFO:               skopt: Not installed
2025-03-13 00:53:28,429:INFO:              mlflow: Not installed
2025-03-13 00:53:28,429:INFO:              gradio: Not installed
2025-03-13 00:53:28,429:INFO:             fastapi: Not installed
2025-03-13 00:53:28,429:INFO:             uvicorn: Not installed
2025-03-13 00:53:28,429:INFO:              m2cgen: Not installed
2025-03-13 00:53:28,429:INFO:           evidently: Not installed
2025-03-13 00:53:28,429:INFO:               fugue: Not installed
2025-03-13 00:53:28,429:INFO:           streamlit: Not installed
2025-03-13 00:53:28,429:INFO:             prophet: Not installed
2025-03-13 00:53:28,430:INFO:None
2025-03-13 00:53:28,430:INFO:Set up data.
2025-03-13 00:53:28,437:INFO:Set up folding strategy.
2025-03-13 00:53:28,437:INFO:Set up train/test split.
2025-03-13 00:53:28,443:INFO:Set up index.
2025-03-13 00:53:28,443:INFO:Assigning column types.
2025-03-13 00:53:28,449:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-13 00:53:28,449:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,454:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,457:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,495:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,524:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:28,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:28,524:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,527:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,531:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,568:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,597:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:28,599:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:28,599:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-13 00:53:28,602:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,605:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,644:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,670:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,671:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:28,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:28,677:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,679:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,726:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,755:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:28,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:28,757:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-13 00:53:28,762:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,833:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,833:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:28,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:28,842:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,882:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,910:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,910:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:28,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:28,910:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-13 00:53:28,961:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,986:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:53:28,988:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:28,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,044:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:53:29,073:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:53:29,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,073:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-13 00:53:29,132:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:53:29,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,237:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:53:29,264:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,265:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-13 00:53:29,365:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,365:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,437:INFO:Preparing preprocessing pipeline...
2025-03-13 00:53:29,437:INFO:Set up date feature engineering.
2025-03-13 00:53:29,438:INFO:Set up simple imputation.
2025-03-13 00:53:29,471:INFO:Finished creating preprocessing pipeline.
2025-03-13 00:53:29,474:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Saeb0m\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['humidity', 'temperature', 'year',
                                             'month', 'day', 'day_of_week',
                                             'week_of_year', 'season',
                                             'dew_point', 'is_weekend',
                                             'tem...
                                             'month_cos', 'day_of_week_sin',
                                             'day_of_week_cos', 'pm_2_5_lag_1',
                                             'pm_2_5_lag_2', 'pm_2_5_lag_3',
                                             'pm_2_5_lag_4', 'pm_2_5_lag_5',
                                             'pm_2_5_lag_6', 'pm_2_5_lag_7',
                                             'pm_2_5_lag_8', 'pm_2_5_lag_9',
                                             'pm_2_5_lag_10', 'pm_2_5_lag_11',
                                             'pm_2_5_lag_12', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2025-03-13 00:53:29,474:INFO:Creating final display dataframe.
2025-03-13 00:53:29,589:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            pm_2_5
2                   Target type        Regression
3           Original data shape         (500, 58)
4        Transformed data shape         (500, 60)
5   Transformed train set shape         (350, 60)
6    Transformed test set shape         (150, 60)
7              Numeric features                56
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator             KFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  reg-default-name
19                          USI              c87c
2025-03-13 00:53:29,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,745:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:53:29,747:INFO:setup() successfully completed in 1.34s...............
2025-03-13 00:53:30,963:INFO:Initializing compare_models()
2025-03-13 00:53:30,965:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-03-13 00:53:30,965:INFO:Checking exceptions
2025-03-13 00:53:30,966:INFO:Preparing display monitor
2025-03-13 00:53:30,980:INFO:Initializing Linear Regression
2025-03-13 00:53:30,980:INFO:Total runtime is 0.0 minutes
2025-03-13 00:53:30,984:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:30,984:INFO:Initializing create_model()
2025-03-13 00:53:30,984:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:30,984:INFO:Checking exceptions
2025-03-13 00:53:30,984:INFO:Importing libraries
2025-03-13 00:53:30,984:INFO:Copying training dataset
2025-03-13 00:53:30,992:INFO:Defining folds
2025-03-13 00:53:30,992:INFO:Declaring metric variables
2025-03-13 00:53:30,995:INFO:Importing untrained model
2025-03-13 00:53:30,998:INFO:Linear Regression Imported successfully
2025-03-13 00:53:31,004:INFO:Starting cross validation
2025-03-13 00:53:31,004:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:31,137:INFO:Calculating mean and std
2025-03-13 00:53:31,137:INFO:Creating metrics dataframe
2025-03-13 00:53:31,138:INFO:Uploading results into container
2025-03-13 00:53:31,139:INFO:Uploading model into container now
2025-03-13 00:53:31,139:INFO:_master_model_container: 1
2025-03-13 00:53:31,139:INFO:_display_container: 2
2025-03-13 00:53:31,139:INFO:LinearRegression(n_jobs=-1)
2025-03-13 00:53:31,140:INFO:create_model() successfully completed......................................
2025-03-13 00:53:31,203:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:31,203:INFO:Creating metrics dataframe
2025-03-13 00:53:31,206:INFO:Initializing Lasso Regression
2025-03-13 00:53:31,206:INFO:Total runtime is 0.0037630518277486165 minutes
2025-03-13 00:53:31,209:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:31,209:INFO:Initializing create_model()
2025-03-13 00:53:31,209:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:31,209:INFO:Checking exceptions
2025-03-13 00:53:31,209:INFO:Importing libraries
2025-03-13 00:53:31,209:INFO:Copying training dataset
2025-03-13 00:53:31,214:INFO:Defining folds
2025-03-13 00:53:31,214:INFO:Declaring metric variables
2025-03-13 00:53:31,217:INFO:Importing untrained model
2025-03-13 00:53:31,219:INFO:Lasso Regression Imported successfully
2025-03-13 00:53:31,222:INFO:Starting cross validation
2025-03-13 00:53:31,224:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:31,295:INFO:Calculating mean and std
2025-03-13 00:53:31,296:INFO:Creating metrics dataframe
2025-03-13 00:53:31,297:INFO:Uploading results into container
2025-03-13 00:53:31,297:INFO:Uploading model into container now
2025-03-13 00:53:31,297:INFO:_master_model_container: 2
2025-03-13 00:53:31,297:INFO:_display_container: 2
2025-03-13 00:53:31,298:INFO:Lasso(random_state=123)
2025-03-13 00:53:31,298:INFO:create_model() successfully completed......................................
2025-03-13 00:53:31,357:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:31,357:INFO:Creating metrics dataframe
2025-03-13 00:53:31,360:INFO:Initializing Ridge Regression
2025-03-13 00:53:31,360:INFO:Total runtime is 0.006332667668660481 minutes
2025-03-13 00:53:31,363:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:31,363:INFO:Initializing create_model()
2025-03-13 00:53:31,364:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:31,364:INFO:Checking exceptions
2025-03-13 00:53:31,364:INFO:Importing libraries
2025-03-13 00:53:31,364:INFO:Copying training dataset
2025-03-13 00:53:31,370:INFO:Defining folds
2025-03-13 00:53:31,370:INFO:Declaring metric variables
2025-03-13 00:53:31,373:INFO:Importing untrained model
2025-03-13 00:53:31,376:INFO:Ridge Regression Imported successfully
2025-03-13 00:53:31,383:INFO:Starting cross validation
2025-03-13 00:53:31,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:31,456:INFO:Calculating mean and std
2025-03-13 00:53:31,456:INFO:Creating metrics dataframe
2025-03-13 00:53:31,458:INFO:Uploading results into container
2025-03-13 00:53:31,458:INFO:Uploading model into container now
2025-03-13 00:53:31,458:INFO:_master_model_container: 3
2025-03-13 00:53:31,458:INFO:_display_container: 2
2025-03-13 00:53:31,458:INFO:Ridge(random_state=123)
2025-03-13 00:53:31,458:INFO:create_model() successfully completed......................................
2025-03-13 00:53:31,517:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:31,517:INFO:Creating metrics dataframe
2025-03-13 00:53:31,522:INFO:Initializing Elastic Net
2025-03-13 00:53:31,522:INFO:Total runtime is 0.009032638867696126 minutes
2025-03-13 00:53:31,525:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:31,525:INFO:Initializing create_model()
2025-03-13 00:53:31,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:31,525:INFO:Checking exceptions
2025-03-13 00:53:31,525:INFO:Importing libraries
2025-03-13 00:53:31,525:INFO:Copying training dataset
2025-03-13 00:53:31,532:INFO:Defining folds
2025-03-13 00:53:31,532:INFO:Declaring metric variables
2025-03-13 00:53:31,534:INFO:Importing untrained model
2025-03-13 00:53:31,537:INFO:Elastic Net Imported successfully
2025-03-13 00:53:31,542:INFO:Starting cross validation
2025-03-13 00:53:31,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:31,613:INFO:Calculating mean and std
2025-03-13 00:53:31,613:INFO:Creating metrics dataframe
2025-03-13 00:53:31,614:INFO:Uploading results into container
2025-03-13 00:53:31,614:INFO:Uploading model into container now
2025-03-13 00:53:31,614:INFO:_master_model_container: 4
2025-03-13 00:53:31,614:INFO:_display_container: 2
2025-03-13 00:53:31,614:INFO:ElasticNet(random_state=123)
2025-03-13 00:53:31,614:INFO:create_model() successfully completed......................................
2025-03-13 00:53:31,674:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:31,674:INFO:Creating metrics dataframe
2025-03-13 00:53:31,678:INFO:Initializing Least Angle Regression
2025-03-13 00:53:31,678:INFO:Total runtime is 0.011631921927134196 minutes
2025-03-13 00:53:31,680:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:31,681:INFO:Initializing create_model()
2025-03-13 00:53:31,681:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:31,681:INFO:Checking exceptions
2025-03-13 00:53:31,681:INFO:Importing libraries
2025-03-13 00:53:31,681:INFO:Copying training dataset
2025-03-13 00:53:31,688:INFO:Defining folds
2025-03-13 00:53:31,688:INFO:Declaring metric variables
2025-03-13 00:53:31,689:INFO:Importing untrained model
2025-03-13 00:53:31,694:INFO:Least Angle Regression Imported successfully
2025-03-13 00:53:31,703:INFO:Starting cross validation
2025-03-13 00:53:31,704:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:31,751:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=9.792e-02, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,753:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=9.201e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,753:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.746e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,754:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.370e-01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,754:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=4.852e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,754:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.407e+03, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,754:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.916e+03, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,756:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=1.737e-01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,756:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=1.654e-01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,756:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=3.619e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,756:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.491e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,756:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=3.099e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,757:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=6.443e+05, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,757:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=7.193e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,757:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=6.442e+05, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,757:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.858e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,759:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.421e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,759:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=4.606e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,760:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=8.518e-02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,760:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.554e-02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,760:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=7.289e-02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,761:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.599e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,761:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=1.016e+03, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,763:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.693e+02, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,769:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=5.763e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,769:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=9.394e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,769:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=5.712e+00, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,770:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=4.461e+00, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,770:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=9.393e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,770:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=4.070e-02, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,770:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=4.191e+06, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,771:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.954e+02, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,771:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=3.435e+08, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,774:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=2.081e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,774:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.344e-01, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,775:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.031e-02, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,775:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=7.882e-02, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,777:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=2.119e+06, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,777:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=2.117e+06, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,777:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.494e+03, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,779:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=2.430e+06, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,780:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=2.317e+06, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,780:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=5.384e-02, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,780:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=4.598e-02, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,781:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=5.082e-02, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,781:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=4.614e-02, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,781:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=4.395e-02, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,802:INFO:Calculating mean and std
2025-03-13 00:53:31,802:INFO:Creating metrics dataframe
2025-03-13 00:53:31,802:INFO:Uploading results into container
2025-03-13 00:53:31,802:INFO:Uploading model into container now
2025-03-13 00:53:31,804:INFO:_master_model_container: 5
2025-03-13 00:53:31,804:INFO:_display_container: 2
2025-03-13 00:53:31,804:INFO:Lars(random_state=123)
2025-03-13 00:53:31,804:INFO:create_model() successfully completed......................................
2025-03-13 00:53:31,864:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:31,864:INFO:Creating metrics dataframe
2025-03-13 00:53:31,868:INFO:Initializing Lasso Least Angle Regression
2025-03-13 00:53:31,868:INFO:Total runtime is 0.01479718287785848 minutes
2025-03-13 00:53:31,871:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:31,871:INFO:Initializing create_model()
2025-03-13 00:53:31,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:31,871:INFO:Checking exceptions
2025-03-13 00:53:31,871:INFO:Importing libraries
2025-03-13 00:53:31,871:INFO:Copying training dataset
2025-03-13 00:53:31,877:INFO:Defining folds
2025-03-13 00:53:31,877:INFO:Declaring metric variables
2025-03-13 00:53:31,879:INFO:Importing untrained model
2025-03-13 00:53:31,882:INFO:Lasso Least Angle Regression Imported successfully
2025-03-13 00:53:31,887:INFO:Starting cross validation
2025-03-13 00:53:31,888:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:31,925:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=1.231e+00, previous alpha=1.206e+00, with an active set of 30 regressors.
  warnings.warn(

2025-03-13 00:53:31,928:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.980e+00, previous alpha=2.696e+00, with an active set of 18 regressors.
  warnings.warn(

2025-03-13 00:53:31,941:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.491e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:53:31,985:INFO:Calculating mean and std
2025-03-13 00:53:31,985:INFO:Creating metrics dataframe
2025-03-13 00:53:31,986:INFO:Uploading results into container
2025-03-13 00:53:31,986:INFO:Uploading model into container now
2025-03-13 00:53:31,988:INFO:_master_model_container: 6
2025-03-13 00:53:31,988:INFO:_display_container: 2
2025-03-13 00:53:31,988:INFO:LassoLars(random_state=123)
2025-03-13 00:53:31,988:INFO:create_model() successfully completed......................................
2025-03-13 00:53:32,054:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:32,054:INFO:Creating metrics dataframe
2025-03-13 00:53:32,059:INFO:Initializing Orthogonal Matching Pursuit
2025-03-13 00:53:32,059:INFO:Total runtime is 0.01797985235850016 minutes
2025-03-13 00:53:32,061:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:32,061:INFO:Initializing create_model()
2025-03-13 00:53:32,061:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:32,061:INFO:Checking exceptions
2025-03-13 00:53:32,061:INFO:Importing libraries
2025-03-13 00:53:32,061:INFO:Copying training dataset
2025-03-13 00:53:32,069:INFO:Defining folds
2025-03-13 00:53:32,069:INFO:Declaring metric variables
2025-03-13 00:53:32,071:INFO:Importing untrained model
2025-03-13 00:53:32,072:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-13 00:53:32,077:INFO:Starting cross validation
2025-03-13 00:53:32,078:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:32,163:INFO:Calculating mean and std
2025-03-13 00:53:32,163:INFO:Creating metrics dataframe
2025-03-13 00:53:32,165:INFO:Uploading results into container
2025-03-13 00:53:32,166:INFO:Uploading model into container now
2025-03-13 00:53:32,166:INFO:_master_model_container: 7
2025-03-13 00:53:32,168:INFO:_display_container: 2
2025-03-13 00:53:32,168:INFO:OrthogonalMatchingPursuit()
2025-03-13 00:53:32,168:INFO:create_model() successfully completed......................................
2025-03-13 00:53:32,231:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:32,231:INFO:Creating metrics dataframe
2025-03-13 00:53:32,235:INFO:Initializing Bayesian Ridge
2025-03-13 00:53:32,235:INFO:Total runtime is 0.020917212963104247 minutes
2025-03-13 00:53:32,240:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:32,240:INFO:Initializing create_model()
2025-03-13 00:53:32,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:32,240:INFO:Checking exceptions
2025-03-13 00:53:32,240:INFO:Importing libraries
2025-03-13 00:53:32,240:INFO:Copying training dataset
2025-03-13 00:53:32,246:INFO:Defining folds
2025-03-13 00:53:32,246:INFO:Declaring metric variables
2025-03-13 00:53:32,248:INFO:Importing untrained model
2025-03-13 00:53:32,251:INFO:Bayesian Ridge Imported successfully
2025-03-13 00:53:32,256:INFO:Starting cross validation
2025-03-13 00:53:32,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:32,332:INFO:Calculating mean and std
2025-03-13 00:53:32,333:INFO:Creating metrics dataframe
2025-03-13 00:53:32,333:INFO:Uploading results into container
2025-03-13 00:53:32,334:INFO:Uploading model into container now
2025-03-13 00:53:32,334:INFO:_master_model_container: 8
2025-03-13 00:53:32,334:INFO:_display_container: 2
2025-03-13 00:53:32,334:INFO:BayesianRidge()
2025-03-13 00:53:32,334:INFO:create_model() successfully completed......................................
2025-03-13 00:53:32,393:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:32,395:INFO:Creating metrics dataframe
2025-03-13 00:53:32,400:INFO:Initializing Passive Aggressive Regressor
2025-03-13 00:53:32,400:INFO:Total runtime is 0.023661271731058756 minutes
2025-03-13 00:53:32,404:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:32,404:INFO:Initializing create_model()
2025-03-13 00:53:32,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:32,404:INFO:Checking exceptions
2025-03-13 00:53:32,404:INFO:Importing libraries
2025-03-13 00:53:32,404:INFO:Copying training dataset
2025-03-13 00:53:32,410:INFO:Defining folds
2025-03-13 00:53:32,410:INFO:Declaring metric variables
2025-03-13 00:53:32,412:INFO:Importing untrained model
2025-03-13 00:53:32,414:INFO:Passive Aggressive Regressor Imported successfully
2025-03-13 00:53:32,421:INFO:Starting cross validation
2025-03-13 00:53:32,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:32,507:INFO:Calculating mean and std
2025-03-13 00:53:32,507:INFO:Creating metrics dataframe
2025-03-13 00:53:32,509:INFO:Uploading results into container
2025-03-13 00:53:32,509:INFO:Uploading model into container now
2025-03-13 00:53:32,510:INFO:_master_model_container: 9
2025-03-13 00:53:32,510:INFO:_display_container: 2
2025-03-13 00:53:32,510:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-13 00:53:32,510:INFO:create_model() successfully completed......................................
2025-03-13 00:53:32,585:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:32,585:INFO:Creating metrics dataframe
2025-03-13 00:53:32,591:INFO:Initializing Huber Regressor
2025-03-13 00:53:32,591:INFO:Total runtime is 0.026836156845092773 minutes
2025-03-13 00:53:32,594:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:32,594:INFO:Initializing create_model()
2025-03-13 00:53:32,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:32,594:INFO:Checking exceptions
2025-03-13 00:53:32,594:INFO:Importing libraries
2025-03-13 00:53:32,594:INFO:Copying training dataset
2025-03-13 00:53:32,600:INFO:Defining folds
2025-03-13 00:53:32,600:INFO:Declaring metric variables
2025-03-13 00:53:32,601:INFO:Importing untrained model
2025-03-13 00:53:32,604:INFO:Huber Regressor Imported successfully
2025-03-13 00:53:32,609:INFO:Starting cross validation
2025-03-13 00:53:32,611:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:32,660:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:53:32,665:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:53:32,670:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:53:32,670:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:53:32,678:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:53:32,678:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:53:32,684:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:53:32,689:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:53:32,690:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:53:32,692:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:53:32,704:INFO:Calculating mean and std
2025-03-13 00:53:32,704:INFO:Creating metrics dataframe
2025-03-13 00:53:32,706:INFO:Uploading results into container
2025-03-13 00:53:32,706:INFO:Uploading model into container now
2025-03-13 00:53:32,707:INFO:_master_model_container: 10
2025-03-13 00:53:32,707:INFO:_display_container: 2
2025-03-13 00:53:32,707:INFO:HuberRegressor()
2025-03-13 00:53:32,707:INFO:create_model() successfully completed......................................
2025-03-13 00:53:32,769:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:32,769:INFO:Creating metrics dataframe
2025-03-13 00:53:32,774:INFO:Initializing K Neighbors Regressor
2025-03-13 00:53:32,774:INFO:Total runtime is 0.02988910675048828 minutes
2025-03-13 00:53:32,777:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:32,777:INFO:Initializing create_model()
2025-03-13 00:53:32,777:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:32,777:INFO:Checking exceptions
2025-03-13 00:53:32,777:INFO:Importing libraries
2025-03-13 00:53:32,777:INFO:Copying training dataset
2025-03-13 00:53:32,782:INFO:Defining folds
2025-03-13 00:53:32,782:INFO:Declaring metric variables
2025-03-13 00:53:32,785:INFO:Importing untrained model
2025-03-13 00:53:32,787:INFO:K Neighbors Regressor Imported successfully
2025-03-13 00:53:32,790:INFO:Starting cross validation
2025-03-13 00:53:32,792:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:32,926:INFO:Calculating mean and std
2025-03-13 00:53:32,927:INFO:Creating metrics dataframe
2025-03-13 00:53:32,928:INFO:Uploading results into container
2025-03-13 00:53:32,929:INFO:Uploading model into container now
2025-03-13 00:53:32,930:INFO:_master_model_container: 11
2025-03-13 00:53:32,930:INFO:_display_container: 2
2025-03-13 00:53:32,930:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-13 00:53:32,930:INFO:create_model() successfully completed......................................
2025-03-13 00:53:32,990:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:32,990:INFO:Creating metrics dataframe
2025-03-13 00:53:32,995:INFO:Initializing Decision Tree Regressor
2025-03-13 00:53:32,995:INFO:Total runtime is 0.033583295345306394 minutes
2025-03-13 00:53:32,997:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:32,997:INFO:Initializing create_model()
2025-03-13 00:53:32,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:32,997:INFO:Checking exceptions
2025-03-13 00:53:32,997:INFO:Importing libraries
2025-03-13 00:53:32,997:INFO:Copying training dataset
2025-03-13 00:53:33,004:INFO:Defining folds
2025-03-13 00:53:33,004:INFO:Declaring metric variables
2025-03-13 00:53:33,005:INFO:Importing untrained model
2025-03-13 00:53:33,008:INFO:Decision Tree Regressor Imported successfully
2025-03-13 00:53:33,013:INFO:Starting cross validation
2025-03-13 00:53:33,013:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:33,109:INFO:Calculating mean and std
2025-03-13 00:53:33,109:INFO:Creating metrics dataframe
2025-03-13 00:53:33,112:INFO:Uploading results into container
2025-03-13 00:53:33,113:INFO:Uploading model into container now
2025-03-13 00:53:33,113:INFO:_master_model_container: 12
2025-03-13 00:53:33,113:INFO:_display_container: 2
2025-03-13 00:53:33,113:INFO:DecisionTreeRegressor(random_state=123)
2025-03-13 00:53:33,113:INFO:create_model() successfully completed......................................
2025-03-13 00:53:33,177:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:33,177:INFO:Creating metrics dataframe
2025-03-13 00:53:33,184:INFO:Initializing Random Forest Regressor
2025-03-13 00:53:33,184:INFO:Total runtime is 0.036718936761220296 minutes
2025-03-13 00:53:33,185:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:33,185:INFO:Initializing create_model()
2025-03-13 00:53:33,187:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:33,187:INFO:Checking exceptions
2025-03-13 00:53:33,187:INFO:Importing libraries
2025-03-13 00:53:33,187:INFO:Copying training dataset
2025-03-13 00:53:33,193:INFO:Defining folds
2025-03-13 00:53:33,193:INFO:Declaring metric variables
2025-03-13 00:53:33,194:INFO:Importing untrained model
2025-03-13 00:53:33,196:INFO:Random Forest Regressor Imported successfully
2025-03-13 00:53:33,202:INFO:Starting cross validation
2025-03-13 00:53:33,203:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:34,421:INFO:Calculating mean and std
2025-03-13 00:53:34,422:INFO:Creating metrics dataframe
2025-03-13 00:53:34,424:INFO:Uploading results into container
2025-03-13 00:53:34,424:INFO:Uploading model into container now
2025-03-13 00:53:34,425:INFO:_master_model_container: 13
2025-03-13 00:53:34,425:INFO:_display_container: 2
2025-03-13 00:53:34,425:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:53:34,425:INFO:create_model() successfully completed......................................
2025-03-13 00:53:34,491:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:34,491:INFO:Creating metrics dataframe
2025-03-13 00:53:34,498:INFO:Initializing Extra Trees Regressor
2025-03-13 00:53:34,498:INFO:Total runtime is 0.05862345695495605 minutes
2025-03-13 00:53:34,501:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:34,501:INFO:Initializing create_model()
2025-03-13 00:53:34,501:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:34,501:INFO:Checking exceptions
2025-03-13 00:53:34,501:INFO:Importing libraries
2025-03-13 00:53:34,501:INFO:Copying training dataset
2025-03-13 00:53:34,507:INFO:Defining folds
2025-03-13 00:53:34,507:INFO:Declaring metric variables
2025-03-13 00:53:34,510:INFO:Importing untrained model
2025-03-13 00:53:34,511:INFO:Extra Trees Regressor Imported successfully
2025-03-13 00:53:34,515:INFO:Starting cross validation
2025-03-13 00:53:34,515:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:35,099:INFO:Calculating mean and std
2025-03-13 00:53:35,100:INFO:Creating metrics dataframe
2025-03-13 00:53:35,101:INFO:Uploading results into container
2025-03-13 00:53:35,101:INFO:Uploading model into container now
2025-03-13 00:53:35,102:INFO:_master_model_container: 14
2025-03-13 00:53:35,102:INFO:_display_container: 2
2025-03-13 00:53:35,102:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:53:35,102:INFO:create_model() successfully completed......................................
2025-03-13 00:53:35,162:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:35,162:INFO:Creating metrics dataframe
2025-03-13 00:53:35,166:INFO:Initializing AdaBoost Regressor
2025-03-13 00:53:35,168:INFO:Total runtime is 0.06978747844696044 minutes
2025-03-13 00:53:35,169:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:35,169:INFO:Initializing create_model()
2025-03-13 00:53:35,169:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:35,170:INFO:Checking exceptions
2025-03-13 00:53:35,170:INFO:Importing libraries
2025-03-13 00:53:35,170:INFO:Copying training dataset
2025-03-13 00:53:35,175:INFO:Defining folds
2025-03-13 00:53:35,175:INFO:Declaring metric variables
2025-03-13 00:53:35,177:INFO:Importing untrained model
2025-03-13 00:53:35,179:INFO:AdaBoost Regressor Imported successfully
2025-03-13 00:53:35,184:INFO:Starting cross validation
2025-03-13 00:53:35,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:35,463:INFO:Calculating mean and std
2025-03-13 00:53:35,463:INFO:Creating metrics dataframe
2025-03-13 00:53:35,465:INFO:Uploading results into container
2025-03-13 00:53:35,465:INFO:Uploading model into container now
2025-03-13 00:53:35,465:INFO:_master_model_container: 15
2025-03-13 00:53:35,465:INFO:_display_container: 2
2025-03-13 00:53:35,466:INFO:AdaBoostRegressor(random_state=123)
2025-03-13 00:53:35,466:INFO:create_model() successfully completed......................................
2025-03-13 00:53:35,527:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:35,527:INFO:Creating metrics dataframe
2025-03-13 00:53:35,533:INFO:Initializing Gradient Boosting Regressor
2025-03-13 00:53:35,533:INFO:Total runtime is 0.07586904764175414 minutes
2025-03-13 00:53:35,534:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:35,536:INFO:Initializing create_model()
2025-03-13 00:53:35,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:35,536:INFO:Checking exceptions
2025-03-13 00:53:35,536:INFO:Importing libraries
2025-03-13 00:53:35,536:INFO:Copying training dataset
2025-03-13 00:53:35,541:INFO:Defining folds
2025-03-13 00:53:35,541:INFO:Declaring metric variables
2025-03-13 00:53:35,544:INFO:Importing untrained model
2025-03-13 00:53:35,546:INFO:Gradient Boosting Regressor Imported successfully
2025-03-13 00:53:35,551:INFO:Starting cross validation
2025-03-13 00:53:35,551:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:36,184:INFO:Calculating mean and std
2025-03-13 00:53:36,184:INFO:Creating metrics dataframe
2025-03-13 00:53:36,185:INFO:Uploading results into container
2025-03-13 00:53:36,185:INFO:Uploading model into container now
2025-03-13 00:53:36,187:INFO:_master_model_container: 16
2025-03-13 00:53:36,187:INFO:_display_container: 2
2025-03-13 00:53:36,187:INFO:GradientBoostingRegressor(random_state=123)
2025-03-13 00:53:36,187:INFO:create_model() successfully completed......................................
2025-03-13 00:53:36,246:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:36,246:INFO:Creating metrics dataframe
2025-03-13 00:53:36,252:INFO:Initializing Light Gradient Boosting Machine
2025-03-13 00:53:36,252:INFO:Total runtime is 0.08786751826604207 minutes
2025-03-13 00:53:36,254:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:36,256:INFO:Initializing create_model()
2025-03-13 00:53:36,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:36,256:INFO:Checking exceptions
2025-03-13 00:53:36,256:INFO:Importing libraries
2025-03-13 00:53:36,256:INFO:Copying training dataset
2025-03-13 00:53:36,261:INFO:Defining folds
2025-03-13 00:53:36,261:INFO:Declaring metric variables
2025-03-13 00:53:36,264:INFO:Importing untrained model
2025-03-13 00:53:36,265:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-13 00:53:36,270:INFO:Starting cross validation
2025-03-13 00:53:36,270:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:36,729:INFO:Calculating mean and std
2025-03-13 00:53:36,730:INFO:Creating metrics dataframe
2025-03-13 00:53:36,732:INFO:Uploading results into container
2025-03-13 00:53:36,732:INFO:Uploading model into container now
2025-03-13 00:53:36,733:INFO:_master_model_container: 17
2025-03-13 00:53:36,733:INFO:_display_container: 2
2025-03-13 00:53:36,733:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:53:36,733:INFO:create_model() successfully completed......................................
2025-03-13 00:53:36,804:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:36,804:INFO:Creating metrics dataframe
2025-03-13 00:53:36,813:INFO:Initializing Dummy Regressor
2025-03-13 00:53:36,813:INFO:Total runtime is 0.09721670548121134 minutes
2025-03-13 00:53:36,816:INFO:SubProcess create_model() called ==================================
2025-03-13 00:53:36,816:INFO:Initializing create_model()
2025-03-13 00:53:36,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A787B1390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:36,816:INFO:Checking exceptions
2025-03-13 00:53:36,816:INFO:Importing libraries
2025-03-13 00:53:36,816:INFO:Copying training dataset
2025-03-13 00:53:36,826:INFO:Defining folds
2025-03-13 00:53:36,826:INFO:Declaring metric variables
2025-03-13 00:53:36,828:INFO:Importing untrained model
2025-03-13 00:53:36,830:INFO:Dummy Regressor Imported successfully
2025-03-13 00:53:36,835:INFO:Starting cross validation
2025-03-13 00:53:36,835:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:36,907:INFO:Calculating mean and std
2025-03-13 00:53:36,907:INFO:Creating metrics dataframe
2025-03-13 00:53:36,908:INFO:Uploading results into container
2025-03-13 00:53:36,908:INFO:Uploading model into container now
2025-03-13 00:53:36,908:INFO:_master_model_container: 18
2025-03-13 00:53:36,908:INFO:_display_container: 2
2025-03-13 00:53:36,908:INFO:DummyRegressor()
2025-03-13 00:53:36,908:INFO:create_model() successfully completed......................................
2025-03-13 00:53:36,970:INFO:SubProcess create_model() end ==================================
2025-03-13 00:53:36,970:INFO:Creating metrics dataframe
2025-03-13 00:53:36,976:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-03-13 00:53:36,984:INFO:Initializing create_model()
2025-03-13 00:53:36,984:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:36,984:INFO:Checking exceptions
2025-03-13 00:53:36,985:INFO:Importing libraries
2025-03-13 00:53:36,985:INFO:Copying training dataset
2025-03-13 00:53:36,993:INFO:Defining folds
2025-03-13 00:53:36,993:INFO:Declaring metric variables
2025-03-13 00:53:36,993:INFO:Importing untrained model
2025-03-13 00:53:36,993:INFO:Declaring custom model
2025-03-13 00:53:36,993:INFO:Extra Trees Regressor Imported successfully
2025-03-13 00:53:36,993:INFO:Cross validation set to False
2025-03-13 00:53:36,993:INFO:Fitting Model
2025-03-13 00:53:37,092:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:53:37,092:INFO:create_model() successfully completed......................................
2025-03-13 00:53:37,163:INFO:Initializing create_model()
2025-03-13 00:53:37,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:37,163:INFO:Checking exceptions
2025-03-13 00:53:37,165:INFO:Importing libraries
2025-03-13 00:53:37,165:INFO:Copying training dataset
2025-03-13 00:53:37,172:INFO:Defining folds
2025-03-13 00:53:37,172:INFO:Declaring metric variables
2025-03-13 00:53:37,172:INFO:Importing untrained model
2025-03-13 00:53:37,172:INFO:Declaring custom model
2025-03-13 00:53:37,172:INFO:AdaBoost Regressor Imported successfully
2025-03-13 00:53:37,172:INFO:Cross validation set to False
2025-03-13 00:53:37,172:INFO:Fitting Model
2025-03-13 00:53:37,347:INFO:AdaBoostRegressor(random_state=123)
2025-03-13 00:53:37,347:INFO:create_model() successfully completed......................................
2025-03-13 00:53:37,416:INFO:Initializing create_model()
2025-03-13 00:53:37,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:37,416:INFO:Checking exceptions
2025-03-13 00:53:37,416:INFO:Importing libraries
2025-03-13 00:53:37,418:INFO:Copying training dataset
2025-03-13 00:53:37,422:INFO:Defining folds
2025-03-13 00:53:37,424:INFO:Declaring metric variables
2025-03-13 00:53:37,424:INFO:Importing untrained model
2025-03-13 00:53:37,424:INFO:Declaring custom model
2025-03-13 00:53:37,424:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-13 00:53:37,424:INFO:Cross validation set to False
2025-03-13 00:53:37,424:INFO:Fitting Model
2025-03-13 00:53:37,441:INFO:OrthogonalMatchingPursuit()
2025-03-13 00:53:37,441:INFO:create_model() successfully completed......................................
2025-03-13 00:53:37,512:INFO:Initializing create_model()
2025-03-13 00:53:37,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:37,512:INFO:Checking exceptions
2025-03-13 00:53:37,512:INFO:Importing libraries
2025-03-13 00:53:37,512:INFO:Copying training dataset
2025-03-13 00:53:37,520:INFO:Defining folds
2025-03-13 00:53:37,520:INFO:Declaring metric variables
2025-03-13 00:53:37,520:INFO:Importing untrained model
2025-03-13 00:53:37,520:INFO:Declaring custom model
2025-03-13 00:53:37,520:INFO:Bayesian Ridge Imported successfully
2025-03-13 00:53:37,521:INFO:Cross validation set to False
2025-03-13 00:53:37,521:INFO:Fitting Model
2025-03-13 00:53:37,544:INFO:BayesianRidge()
2025-03-13 00:53:37,544:INFO:create_model() successfully completed......................................
2025-03-13 00:53:37,615:INFO:Initializing create_model()
2025-03-13 00:53:37,615:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=Lasso(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:37,615:INFO:Checking exceptions
2025-03-13 00:53:37,617:INFO:Importing libraries
2025-03-13 00:53:37,617:INFO:Copying training dataset
2025-03-13 00:53:37,622:INFO:Defining folds
2025-03-13 00:53:37,622:INFO:Declaring metric variables
2025-03-13 00:53:37,622:INFO:Importing untrained model
2025-03-13 00:53:37,622:INFO:Declaring custom model
2025-03-13 00:53:37,622:INFO:Lasso Regression Imported successfully
2025-03-13 00:53:37,622:INFO:Cross validation set to False
2025-03-13 00:53:37,622:INFO:Fitting Model
2025-03-13 00:53:37,634:INFO:Lasso(random_state=123)
2025-03-13 00:53:37,635:INFO:create_model() successfully completed......................................
2025-03-13 00:53:37,707:INFO:Initializing create_model()
2025-03-13 00:53:37,707:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=LassoLars(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:37,707:INFO:Checking exceptions
2025-03-13 00:53:37,709:INFO:Importing libraries
2025-03-13 00:53:37,709:INFO:Copying training dataset
2025-03-13 00:53:37,715:INFO:Defining folds
2025-03-13 00:53:37,715:INFO:Declaring metric variables
2025-03-13 00:53:37,716:INFO:Importing untrained model
2025-03-13 00:53:37,716:INFO:Declaring custom model
2025-03-13 00:53:37,716:INFO:Lasso Least Angle Regression Imported successfully
2025-03-13 00:53:37,716:INFO:Cross validation set to False
2025-03-13 00:53:37,716:INFO:Fitting Model
2025-03-13 00:53:37,732:INFO:LassoLars(random_state=123)
2025-03-13 00:53:37,732:INFO:create_model() successfully completed......................................
2025-03-13 00:53:37,804:INFO:Initializing create_model()
2025-03-13 00:53:37,804:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:37,804:INFO:Checking exceptions
2025-03-13 00:53:37,804:INFO:Importing libraries
2025-03-13 00:53:37,805:INFO:Copying training dataset
2025-03-13 00:53:37,811:INFO:Defining folds
2025-03-13 00:53:37,811:INFO:Declaring metric variables
2025-03-13 00:53:37,811:INFO:Importing untrained model
2025-03-13 00:53:37,811:INFO:Declaring custom model
2025-03-13 00:53:37,811:INFO:Random Forest Regressor Imported successfully
2025-03-13 00:53:37,812:INFO:Cross validation set to False
2025-03-13 00:53:37,812:INFO:Fitting Model
2025-03-13 00:53:37,981:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:53:37,981:INFO:create_model() successfully completed......................................
2025-03-13 00:53:38,049:INFO:Initializing create_model()
2025-03-13 00:53:38,049:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=ElasticNet(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:38,049:INFO:Checking exceptions
2025-03-13 00:53:38,050:INFO:Importing libraries
2025-03-13 00:53:38,050:INFO:Copying training dataset
2025-03-13 00:53:38,056:INFO:Defining folds
2025-03-13 00:53:38,056:INFO:Declaring metric variables
2025-03-13 00:53:38,057:INFO:Importing untrained model
2025-03-13 00:53:38,057:INFO:Declaring custom model
2025-03-13 00:53:38,057:INFO:Elastic Net Imported successfully
2025-03-13 00:53:38,057:INFO:Cross validation set to False
2025-03-13 00:53:38,057:INFO:Fitting Model
2025-03-13 00:53:38,071:INFO:ElasticNet(random_state=123)
2025-03-13 00:53:38,071:INFO:create_model() successfully completed......................................
2025-03-13 00:53:38,135:INFO:Initializing create_model()
2025-03-13 00:53:38,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:38,135:INFO:Checking exceptions
2025-03-13 00:53:38,135:INFO:Importing libraries
2025-03-13 00:53:38,135:INFO:Copying training dataset
2025-03-13 00:53:38,140:INFO:Defining folds
2025-03-13 00:53:38,140:INFO:Declaring metric variables
2025-03-13 00:53:38,142:INFO:Importing untrained model
2025-03-13 00:53:38,142:INFO:Declaring custom model
2025-03-13 00:53:38,142:INFO:Gradient Boosting Regressor Imported successfully
2025-03-13 00:53:38,142:INFO:Cross validation set to False
2025-03-13 00:53:38,142:INFO:Fitting Model
2025-03-13 00:53:38,686:INFO:GradientBoostingRegressor(random_state=123)
2025-03-13 00:53:38,686:INFO:create_model() successfully completed......................................
2025-03-13 00:53:38,756:INFO:Initializing create_model()
2025-03-13 00:53:38,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:38,756:INFO:Checking exceptions
2025-03-13 00:53:38,757:INFO:Importing libraries
2025-03-13 00:53:38,757:INFO:Copying training dataset
2025-03-13 00:53:38,764:INFO:Defining folds
2025-03-13 00:53:38,764:INFO:Declaring metric variables
2025-03-13 00:53:38,764:INFO:Importing untrained model
2025-03-13 00:53:38,764:INFO:Declaring custom model
2025-03-13 00:53:38,764:INFO:Huber Regressor Imported successfully
2025-03-13 00:53:38,765:INFO:Cross validation set to False
2025-03-13 00:53:38,765:INFO:Fitting Model
2025-03-13 00:53:38,812:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:53:38,813:INFO:HuberRegressor()
2025-03-13 00:53:38,813:INFO:create_model() successfully completed......................................
2025-03-13 00:53:38,892:INFO:Initializing create_model()
2025-03-13 00:53:38,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:38,892:INFO:Checking exceptions
2025-03-13 00:53:38,894:INFO:Importing libraries
2025-03-13 00:53:38,894:INFO:Copying training dataset
2025-03-13 00:53:38,901:INFO:Defining folds
2025-03-13 00:53:38,901:INFO:Declaring metric variables
2025-03-13 00:53:38,901:INFO:Importing untrained model
2025-03-13 00:53:38,901:INFO:Declaring custom model
2025-03-13 00:53:38,901:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-13 00:53:38,902:INFO:Cross validation set to False
2025-03-13 00:53:38,902:INFO:Fitting Model
2025-03-13 00:53:38,918:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000585 seconds.
2025-03-13 00:53:38,918:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-13 00:53:38,918:INFO:[LightGBM] [Info] Total Bins 5456
2025-03-13 00:53:38,918:INFO:[LightGBM] [Info] Number of data points in the train set: 350, number of used features: 59
2025-03-13 00:53:38,918:INFO:[LightGBM] [Info] Start training from score 20.591016
2025-03-13 00:53:38,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:53:38,973:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:53:38,973:INFO:create_model() successfully completed......................................
2025-03-13 00:53:39,047:INFO:Initializing create_model()
2025-03-13 00:53:39,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=Ridge(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:39,047:INFO:Checking exceptions
2025-03-13 00:53:39,050:INFO:Importing libraries
2025-03-13 00:53:39,050:INFO:Copying training dataset
2025-03-13 00:53:39,058:INFO:Defining folds
2025-03-13 00:53:39,058:INFO:Declaring metric variables
2025-03-13 00:53:39,058:INFO:Importing untrained model
2025-03-13 00:53:39,058:INFO:Declaring custom model
2025-03-13 00:53:39,058:INFO:Ridge Regression Imported successfully
2025-03-13 00:53:39,058:INFO:Cross validation set to False
2025-03-13 00:53:39,058:INFO:Fitting Model
2025-03-13 00:53:39,076:INFO:Ridge(random_state=123)
2025-03-13 00:53:39,076:INFO:create_model() successfully completed......................................
2025-03-13 00:53:39,141:INFO:Initializing create_model()
2025-03-13 00:53:39,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:39,141:INFO:Checking exceptions
2025-03-13 00:53:39,142:INFO:Importing libraries
2025-03-13 00:53:39,142:INFO:Copying training dataset
2025-03-13 00:53:39,149:INFO:Defining folds
2025-03-13 00:53:39,149:INFO:Declaring metric variables
2025-03-13 00:53:39,149:INFO:Importing untrained model
2025-03-13 00:53:39,149:INFO:Declaring custom model
2025-03-13 00:53:39,150:INFO:Linear Regression Imported successfully
2025-03-13 00:53:39,150:INFO:Cross validation set to False
2025-03-13 00:53:39,150:INFO:Fitting Model
2025-03-13 00:53:39,169:INFO:LinearRegression(n_jobs=-1)
2025-03-13 00:53:39,170:INFO:create_model() successfully completed......................................
2025-03-13 00:53:39,243:INFO:Initializing create_model()
2025-03-13 00:53:39,243:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:39,243:INFO:Checking exceptions
2025-03-13 00:53:39,244:INFO:Importing libraries
2025-03-13 00:53:39,244:INFO:Copying training dataset
2025-03-13 00:53:39,250:INFO:Defining folds
2025-03-13 00:53:39,250:INFO:Declaring metric variables
2025-03-13 00:53:39,250:INFO:Importing untrained model
2025-03-13 00:53:39,250:INFO:Declaring custom model
2025-03-13 00:53:39,250:INFO:K Neighbors Regressor Imported successfully
2025-03-13 00:53:39,250:INFO:Cross validation set to False
2025-03-13 00:53:39,250:INFO:Fitting Model
2025-03-13 00:53:39,261:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-13 00:53:39,261:INFO:create_model() successfully completed......................................
2025-03-13 00:53:39,339:INFO:Initializing create_model()
2025-03-13 00:53:39,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=DecisionTreeRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:39,339:INFO:Checking exceptions
2025-03-13 00:53:39,341:INFO:Importing libraries
2025-03-13 00:53:39,341:INFO:Copying training dataset
2025-03-13 00:53:39,350:INFO:Defining folds
2025-03-13 00:53:39,350:INFO:Declaring metric variables
2025-03-13 00:53:39,352:INFO:Importing untrained model
2025-03-13 00:53:39,352:INFO:Declaring custom model
2025-03-13 00:53:39,352:INFO:Decision Tree Regressor Imported successfully
2025-03-13 00:53:39,353:INFO:Cross validation set to False
2025-03-13 00:53:39,353:INFO:Fitting Model
2025-03-13 00:53:39,380:INFO:DecisionTreeRegressor(random_state=123)
2025-03-13 00:53:39,380:INFO:create_model() successfully completed......................................
2025-03-13 00:53:39,453:INFO:_master_model_container: 18
2025-03-13 00:53:39,453:INFO:_display_container: 2
2025-03-13 00:53:39,455:INFO:[ExtraTreesRegressor(n_jobs=-1, random_state=123), AdaBoostRegressor(random_state=123), OrthogonalMatchingPursuit(), BayesianRidge(), Lasso(random_state=123), LassoLars(random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), ElasticNet(random_state=123), GradientBoostingRegressor(random_state=123), HuberRegressor(), LGBMRegressor(n_jobs=-1, random_state=123), Ridge(random_state=123), LinearRegression(n_jobs=-1), KNeighborsRegressor(n_jobs=-1), DecisionTreeRegressor(random_state=123)]
2025-03-13 00:53:39,455:INFO:compare_models() successfully completed......................................
2025-03-13 00:53:41,717:INFO:Initializing create_model()
2025-03-13 00:53:41,717:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:53:41,717:INFO:Checking exceptions
2025-03-13 00:53:41,727:INFO:Importing libraries
2025-03-13 00:53:41,727:INFO:Copying training dataset
2025-03-13 00:53:41,734:INFO:Defining folds
2025-03-13 00:53:41,734:INFO:Declaring metric variables
2025-03-13 00:53:41,737:INFO:Importing untrained model
2025-03-13 00:53:41,741:INFO:Random Forest Regressor Imported successfully
2025-03-13 00:53:41,747:INFO:Starting cross validation
2025-03-13 00:53:41,747:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:53:43,051:INFO:Calculating mean and std
2025-03-13 00:53:43,052:INFO:Creating metrics dataframe
2025-03-13 00:53:43,056:INFO:Finalizing model
2025-03-13 00:53:43,229:INFO:Uploading results into container
2025-03-13 00:53:43,230:INFO:Uploading model into container now
2025-03-13 00:53:43,236:INFO:_master_model_container: 19
2025-03-13 00:53:43,237:INFO:_display_container: 3
2025-03-13 00:53:43,237:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-13 00:53:43,237:INFO:create_model() successfully completed......................................
2025-03-13 00:53:46,580:INFO:Initializing predict_model()
2025-03-13 00:53:46,580:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A7A00B810>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026A7C2AF2E0>)
2025-03-13 00:53:46,580:INFO:Checking exceptions
2025-03-13 00:53:46,580:INFO:Preloading libraries
2025-03-13 00:53:46,581:INFO:Set up data.
2025-03-13 00:53:46,589:INFO:Set up index.
2025-03-13 00:54:03,174:INFO:PyCaret RegressionExperiment
2025-03-13 00:54:03,174:INFO:Logging name: reg-default-name
2025-03-13 00:54:03,174:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-13 00:54:03,174:INFO:version 3.3.2
2025-03-13 00:54:03,174:INFO:Initializing setup()
2025-03-13 00:54:03,174:INFO:self.USI: 6d2a
2025-03-13 00:54:03,174:INFO:self._variable_keys: {'exp_name_log', 'fold_generator', 'html_param', 'fold_groups_param', '_ml_usecase', 'n_jobs_param', 'X_train', 'fold_shuffle_param', 'X', 'y', 'USI', 'gpu_n_jobs_param', 'seed', 'y_test', 'X_test', 'gpu_param', 'exp_id', '_available_plots', 'y_train', 'idx', 'log_plots_param', 'logging_param', 'data', 'target_param', 'transform_target_param', 'pipeline', 'memory'}
2025-03-13 00:54:03,174:INFO:Checking environment
2025-03-13 00:54:03,174:INFO:python_version: 3.11.9
2025-03-13 00:54:03,174:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-03-13 00:54:03,174:INFO:machine: AMD64
2025-03-13 00:54:03,174:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-13 00:54:03,178:INFO:Memory: svmem(total=34193833984, available=16964272128, percent=50.4, used=17229561856, free=16964272128)
2025-03-13 00:54:03,179:INFO:Physical Core: 6
2025-03-13 00:54:03,179:INFO:Logical Core: 12
2025-03-13 00:54:03,179:INFO:Checking libraries
2025-03-13 00:54:03,179:INFO:System:
2025-03-13 00:54:03,179:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-03-13 00:54:03,179:INFO:executable: d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Scripts\python.exe
2025-03-13 00:54:03,179:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-13 00:54:03,179:INFO:PyCaret required dependencies:
2025-03-13 00:54:03,179:INFO:                 pip: 24.0
2025-03-13 00:54:03,179:INFO:          setuptools: 65.5.0
2025-03-13 00:54:03,179:INFO:             pycaret: 3.3.2
2025-03-13 00:54:03,179:INFO:             IPython: 8.32.0
2025-03-13 00:54:03,179:INFO:          ipywidgets: 8.1.5
2025-03-13 00:54:03,180:INFO:                tqdm: 4.67.1
2025-03-13 00:54:03,180:INFO:               numpy: 1.26.4
2025-03-13 00:54:03,180:INFO:              pandas: 2.1.4
2025-03-13 00:54:03,180:INFO:              jinja2: 3.1.5
2025-03-13 00:54:03,180:INFO:               scipy: 1.11.4
2025-03-13 00:54:03,180:INFO:              joblib: 1.3.2
2025-03-13 00:54:03,180:INFO:             sklearn: 1.4.2
2025-03-13 00:54:03,180:INFO:                pyod: 2.0.3
2025-03-13 00:54:03,180:INFO:            imblearn: 0.13.0
2025-03-13 00:54:03,180:INFO:   category_encoders: 2.7.0
2025-03-13 00:54:03,180:INFO:            lightgbm: 4.6.0
2025-03-13 00:54:03,180:INFO:               numba: 0.61.0
2025-03-13 00:54:03,180:INFO:            requests: 2.32.3
2025-03-13 00:54:03,180:INFO:          matplotlib: 3.7.5
2025-03-13 00:54:03,180:INFO:          scikitplot: 0.3.7
2025-03-13 00:54:03,180:INFO:         yellowbrick: 1.5
2025-03-13 00:54:03,180:INFO:              plotly: 5.24.1
2025-03-13 00:54:03,180:INFO:    plotly-resampler: Not installed
2025-03-13 00:54:03,180:INFO:             kaleido: 0.2.1
2025-03-13 00:54:03,180:INFO:           schemdraw: 0.15
2025-03-13 00:54:03,180:INFO:         statsmodels: 0.14.4
2025-03-13 00:54:03,180:INFO:              sktime: 0.26.0
2025-03-13 00:54:03,180:INFO:               tbats: 1.1.3
2025-03-13 00:54:03,180:INFO:            pmdarima: 2.0.4
2025-03-13 00:54:03,180:INFO:              psutil: 7.0.0
2025-03-13 00:54:03,180:INFO:          markupsafe: 3.0.2
2025-03-13 00:54:03,180:INFO:             pickle5: Not installed
2025-03-13 00:54:03,180:INFO:         cloudpickle: 3.1.1
2025-03-13 00:54:03,180:INFO:         deprecation: 2.1.0
2025-03-13 00:54:03,180:INFO:              xxhash: 3.5.0
2025-03-13 00:54:03,180:INFO:           wurlitzer: Not installed
2025-03-13 00:54:03,180:INFO:PyCaret optional dependencies:
2025-03-13 00:54:03,180:INFO:                shap: Not installed
2025-03-13 00:54:03,180:INFO:           interpret: Not installed
2025-03-13 00:54:03,180:INFO:                umap: Not installed
2025-03-13 00:54:03,180:INFO:     ydata_profiling: Not installed
2025-03-13 00:54:03,180:INFO:  explainerdashboard: Not installed
2025-03-13 00:54:03,180:INFO:             autoviz: Not installed
2025-03-13 00:54:03,181:INFO:           fairlearn: Not installed
2025-03-13 00:54:03,181:INFO:          deepchecks: Not installed
2025-03-13 00:54:03,181:INFO:             xgboost: Not installed
2025-03-13 00:54:03,181:INFO:            catboost: Not installed
2025-03-13 00:54:03,181:INFO:              kmodes: Not installed
2025-03-13 00:54:03,181:INFO:             mlxtend: Not installed
2025-03-13 00:54:03,181:INFO:       statsforecast: Not installed
2025-03-13 00:54:03,181:INFO:        tune_sklearn: Not installed
2025-03-13 00:54:03,181:INFO:                 ray: Not installed
2025-03-13 00:54:03,181:INFO:            hyperopt: Not installed
2025-03-13 00:54:03,181:INFO:              optuna: Not installed
2025-03-13 00:54:03,181:INFO:               skopt: Not installed
2025-03-13 00:54:03,181:INFO:              mlflow: Not installed
2025-03-13 00:54:03,181:INFO:              gradio: Not installed
2025-03-13 00:54:03,181:INFO:             fastapi: Not installed
2025-03-13 00:54:03,181:INFO:             uvicorn: Not installed
2025-03-13 00:54:03,181:INFO:              m2cgen: Not installed
2025-03-13 00:54:03,181:INFO:           evidently: Not installed
2025-03-13 00:54:03,181:INFO:               fugue: Not installed
2025-03-13 00:54:03,181:INFO:           streamlit: Not installed
2025-03-13 00:54:03,181:INFO:             prophet: Not installed
2025-03-13 00:54:03,181:INFO:None
2025-03-13 00:54:03,181:INFO:Set up data.
2025-03-13 00:54:03,191:INFO:Set up folding strategy.
2025-03-13 00:54:03,191:INFO:Set up train/test split.
2025-03-13 00:54:03,202:INFO:Set up index.
2025-03-13 00:54:03,202:INFO:Assigning column types.
2025-03-13 00:54:03,210:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-13 00:54:03,210:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,214:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,218:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,258:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,284:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,284:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,287:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,291:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,328:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,355:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,355:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-13 00:54:03,358:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,361:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,404:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,432:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,432:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,435:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,438:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,479:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,509:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,509:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-13 00:54:03,514:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,552:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,581:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,581:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,587:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,624:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,654:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,654:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-13 00:54:03,700:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,732:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,777:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,808:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,808:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-13 00:54:03,855:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 00:54:03,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:03,955:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-13 00:54:04,032:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:04,032:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:04,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:04,101:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:04,101:INFO:Preparing preprocessing pipeline...
2025-03-13 00:54:04,101:INFO:Set up date feature engineering.
2025-03-13 00:54:04,101:INFO:Set up simple imputation.
2025-03-13 00:54:04,135:INFO:Finished creating preprocessing pipeline.
2025-03-13 00:54:04,138:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Saeb0m\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['humidity', 'temperature', 'year',
                                             'month', 'day', 'day_of_week',
                                             'week_of_year', 'season',
                                             'dew_point', 'is_weekend',
                                             'tem...
                                             'month_cos', 'day_of_week_sin',
                                             'day_of_week_cos', 'pm_2_5_lag_1',
                                             'pm_2_5_lag_2', 'pm_2_5_lag_3',
                                             'pm_2_5_lag_4', 'pm_2_5_lag_5',
                                             'pm_2_5_lag_6', 'pm_2_5_lag_7',
                                             'pm_2_5_lag_8', 'pm_2_5_lag_9',
                                             'pm_2_5_lag_10', 'pm_2_5_lag_11',
                                             'pm_2_5_lag_12', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2025-03-13 00:54:04,138:INFO:Creating final display dataframe.
2025-03-13 00:54:04,276:INFO:Setup _display_container:                     Description             Value
0                    Session id              6896
1                        Target            pm_2_5
2                   Target type        Regression
3           Original data shape         (500, 58)
4        Transformed data shape         (500, 60)
5   Transformed train set shape         (350, 60)
6    Transformed test set shape         (150, 60)
7              Numeric features                56
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13               Fold Generator             KFold
14                  Fold Number                10
15                     CPU Jobs                -1
16                      Use GPU             False
17               Log Experiment             False
18              Experiment Name  reg-default-name
19                          USI              6d2a
2025-03-13 00:54:04,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:04,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:04,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:04,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 00:54:04,457:INFO:setup() successfully completed in 1.3s...............
2025-03-13 00:54:06,225:INFO:Initializing compare_models()
2025-03-13 00:54:06,225:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-03-13 00:54:06,225:INFO:Checking exceptions
2025-03-13 00:54:06,229:INFO:Preparing display monitor
2025-03-13 00:54:06,243:INFO:Initializing Linear Regression
2025-03-13 00:54:06,243:INFO:Total runtime is 0.0 minutes
2025-03-13 00:54:06,246:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:06,246:INFO:Initializing create_model()
2025-03-13 00:54:06,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:06,246:INFO:Checking exceptions
2025-03-13 00:54:06,246:INFO:Importing libraries
2025-03-13 00:54:06,246:INFO:Copying training dataset
2025-03-13 00:54:06,254:INFO:Defining folds
2025-03-13 00:54:06,254:INFO:Declaring metric variables
2025-03-13 00:54:06,257:INFO:Importing untrained model
2025-03-13 00:54:06,260:INFO:Linear Regression Imported successfully
2025-03-13 00:54:06,263:INFO:Starting cross validation
2025-03-13 00:54:06,265:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:06,350:INFO:Calculating mean and std
2025-03-13 00:54:06,351:INFO:Creating metrics dataframe
2025-03-13 00:54:06,351:INFO:Uploading results into container
2025-03-13 00:54:06,352:INFO:Uploading model into container now
2025-03-13 00:54:06,352:INFO:_master_model_container: 1
2025-03-13 00:54:06,352:INFO:_display_container: 2
2025-03-13 00:54:06,352:INFO:LinearRegression(n_jobs=-1)
2025-03-13 00:54:06,352:INFO:create_model() successfully completed......................................
2025-03-13 00:54:06,414:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:06,415:INFO:Creating metrics dataframe
2025-03-13 00:54:06,418:INFO:Initializing Lasso Regression
2025-03-13 00:54:06,419:INFO:Total runtime is 0.0029350678126017255 minutes
2025-03-13 00:54:06,421:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:06,422:INFO:Initializing create_model()
2025-03-13 00:54:06,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:06,422:INFO:Checking exceptions
2025-03-13 00:54:06,422:INFO:Importing libraries
2025-03-13 00:54:06,422:INFO:Copying training dataset
2025-03-13 00:54:06,428:INFO:Defining folds
2025-03-13 00:54:06,428:INFO:Declaring metric variables
2025-03-13 00:54:06,431:INFO:Importing untrained model
2025-03-13 00:54:06,433:INFO:Lasso Regression Imported successfully
2025-03-13 00:54:06,439:INFO:Starting cross validation
2025-03-13 00:54:06,440:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:06,523:INFO:Calculating mean and std
2025-03-13 00:54:06,523:INFO:Creating metrics dataframe
2025-03-13 00:54:06,523:INFO:Uploading results into container
2025-03-13 00:54:06,523:INFO:Uploading model into container now
2025-03-13 00:54:06,525:INFO:_master_model_container: 2
2025-03-13 00:54:06,525:INFO:_display_container: 2
2025-03-13 00:54:06,525:INFO:Lasso(random_state=6896)
2025-03-13 00:54:06,525:INFO:create_model() successfully completed......................................
2025-03-13 00:54:06,583:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:06,583:INFO:Creating metrics dataframe
2025-03-13 00:54:06,587:INFO:Initializing Ridge Regression
2025-03-13 00:54:06,587:INFO:Total runtime is 0.0057349920272827155 minutes
2025-03-13 00:54:06,590:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:06,591:INFO:Initializing create_model()
2025-03-13 00:54:06,591:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:06,591:INFO:Checking exceptions
2025-03-13 00:54:06,591:INFO:Importing libraries
2025-03-13 00:54:06,591:INFO:Copying training dataset
2025-03-13 00:54:06,599:INFO:Defining folds
2025-03-13 00:54:06,599:INFO:Declaring metric variables
2025-03-13 00:54:06,600:INFO:Importing untrained model
2025-03-13 00:54:06,604:INFO:Ridge Regression Imported successfully
2025-03-13 00:54:06,608:INFO:Starting cross validation
2025-03-13 00:54:06,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:06,699:INFO:Calculating mean and std
2025-03-13 00:54:06,700:INFO:Creating metrics dataframe
2025-03-13 00:54:06,701:INFO:Uploading results into container
2025-03-13 00:54:06,701:INFO:Uploading model into container now
2025-03-13 00:54:06,701:INFO:_master_model_container: 3
2025-03-13 00:54:06,701:INFO:_display_container: 2
2025-03-13 00:54:06,701:INFO:Ridge(random_state=6896)
2025-03-13 00:54:06,701:INFO:create_model() successfully completed......................................
2025-03-13 00:54:06,765:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:06,765:INFO:Creating metrics dataframe
2025-03-13 00:54:06,770:INFO:Initializing Elastic Net
2025-03-13 00:54:06,770:INFO:Total runtime is 0.008775838216145835 minutes
2025-03-13 00:54:06,771:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:06,773:INFO:Initializing create_model()
2025-03-13 00:54:06,773:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:06,773:INFO:Checking exceptions
2025-03-13 00:54:06,773:INFO:Importing libraries
2025-03-13 00:54:06,773:INFO:Copying training dataset
2025-03-13 00:54:06,777:INFO:Defining folds
2025-03-13 00:54:06,777:INFO:Declaring metric variables
2025-03-13 00:54:06,780:INFO:Importing untrained model
2025-03-13 00:54:06,781:INFO:Elastic Net Imported successfully
2025-03-13 00:54:06,786:INFO:Starting cross validation
2025-03-13 00:54:06,787:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:06,867:INFO:Calculating mean and std
2025-03-13 00:54:06,867:INFO:Creating metrics dataframe
2025-03-13 00:54:06,869:INFO:Uploading results into container
2025-03-13 00:54:06,869:INFO:Uploading model into container now
2025-03-13 00:54:06,869:INFO:_master_model_container: 4
2025-03-13 00:54:06,869:INFO:_display_container: 2
2025-03-13 00:54:06,870:INFO:ElasticNet(random_state=6896)
2025-03-13 00:54:06,870:INFO:create_model() successfully completed......................................
2025-03-13 00:54:06,931:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:06,931:INFO:Creating metrics dataframe
2025-03-13 00:54:06,935:INFO:Initializing Least Angle Regression
2025-03-13 00:54:06,935:INFO:Total runtime is 0.011536268393198651 minutes
2025-03-13 00:54:06,937:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:06,937:INFO:Initializing create_model()
2025-03-13 00:54:06,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:06,937:INFO:Checking exceptions
2025-03-13 00:54:06,937:INFO:Importing libraries
2025-03-13 00:54:06,937:INFO:Copying training dataset
2025-03-13 00:54:06,943:INFO:Defining folds
2025-03-13 00:54:06,943:INFO:Declaring metric variables
2025-03-13 00:54:06,944:INFO:Importing untrained model
2025-03-13 00:54:06,949:INFO:Least Angle Regression Imported successfully
2025-03-13 00:54:06,955:INFO:Starting cross validation
2025-03-13 00:54:06,956:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:06,992:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=4.911e+00, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:06,992:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=4.382e+00, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:06,994:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.320e+00, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:06,995:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.886e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:06,997:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=8.732e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:06,997:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.721e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:06,997:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=6.656e-02, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:06,998:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.018e-01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:06,998:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=6.635e+01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:06,999:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.793e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:06,999:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=6.285e+01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,000:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=1.066e+09, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,000:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=1.060e+09, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,000:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.989e+10, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,000:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=9.410e-01, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,000:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.833e+10, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,000:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=5.730e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,000:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=6.238e-01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,000:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=4.286e-01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,002:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.583e-01, with an active set of 48 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,002:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.421e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,004:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=8.671e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,004:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=8.670e+02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,005:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.103e+08, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,005:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.102e+08, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,005:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.101e+08, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,005:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=7.314e+06, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,005:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=7.313e+06, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,011:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.565e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,012:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.330e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,012:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=5.595e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,013:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=5.731e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,013:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=5.689e-02, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,013:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=9.091e-02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,013:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=2.347e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,015:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.142e+01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,015:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=4.732e+07, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,015:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.138e+01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,015:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=4.158e+07, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,015:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.381e+06, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,015:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.569e+06, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,016:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.267e+09, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,021:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=3.249e+00, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,026:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=5.831e-02, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,026:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.668e+01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,028:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.427e+01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,028:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=9.653e+04, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,028:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=7.974e+04, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,042:INFO:Calculating mean and std
2025-03-13 00:54:07,042:INFO:Creating metrics dataframe
2025-03-13 00:54:07,044:INFO:Uploading results into container
2025-03-13 00:54:07,044:INFO:Uploading model into container now
2025-03-13 00:54:07,044:INFO:_master_model_container: 5
2025-03-13 00:54:07,044:INFO:_display_container: 2
2025-03-13 00:54:07,044:INFO:Lars(random_state=6896)
2025-03-13 00:54:07,044:INFO:create_model() successfully completed......................................
2025-03-13 00:54:07,104:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:07,105:INFO:Creating metrics dataframe
2025-03-13 00:54:07,111:INFO:Initializing Lasso Least Angle Regression
2025-03-13 00:54:07,111:INFO:Total runtime is 0.014460933208465579 minutes
2025-03-13 00:54:07,112:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:07,112:INFO:Initializing create_model()
2025-03-13 00:54:07,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:07,112:INFO:Checking exceptions
2025-03-13 00:54:07,114:INFO:Importing libraries
2025-03-13 00:54:07,114:INFO:Copying training dataset
2025-03-13 00:54:07,120:INFO:Defining folds
2025-03-13 00:54:07,120:INFO:Declaring metric variables
2025-03-13 00:54:07,121:INFO:Importing untrained model
2025-03-13 00:54:07,124:INFO:Lasso Least Angle Regression Imported successfully
2025-03-13 00:54:07,128:INFO:Starting cross validation
2025-03-13 00:54:07,128:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:07,163:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=1.473e+00, previous alpha=1.464e+00, with an active set of 22 regressors.
  warnings.warn(

2025-03-13 00:54:07,166:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=5.320e+00, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,166:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.886e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,172:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.721e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,175:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.793e+00, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,175:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 31 iterations, alpha=1.472e+00, previous alpha=1.329e+00, with an active set of 30 regressors.
  warnings.warn(

2025-03-13 00:54:07,184:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=2.565e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,185:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.330e+00, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 00:54:07,190:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.981e+00, previous alpha=1.970e+00, with an active set of 18 regressors.
  warnings.warn(

2025-03-13 00:54:07,204:INFO:Calculating mean and std
2025-03-13 00:54:07,204:INFO:Creating metrics dataframe
2025-03-13 00:54:07,205:INFO:Uploading results into container
2025-03-13 00:54:07,205:INFO:Uploading model into container now
2025-03-13 00:54:07,205:INFO:_master_model_container: 6
2025-03-13 00:54:07,205:INFO:_display_container: 2
2025-03-13 00:54:07,205:INFO:LassoLars(random_state=6896)
2025-03-13 00:54:07,205:INFO:create_model() successfully completed......................................
2025-03-13 00:54:07,269:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:07,269:INFO:Creating metrics dataframe
2025-03-13 00:54:07,273:INFO:Initializing Orthogonal Matching Pursuit
2025-03-13 00:54:07,275:INFO:Total runtime is 0.01719694534937541 minutes
2025-03-13 00:54:07,278:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:07,278:INFO:Initializing create_model()
2025-03-13 00:54:07,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:07,278:INFO:Checking exceptions
2025-03-13 00:54:07,278:INFO:Importing libraries
2025-03-13 00:54:07,278:INFO:Copying training dataset
2025-03-13 00:54:07,285:INFO:Defining folds
2025-03-13 00:54:07,285:INFO:Declaring metric variables
2025-03-13 00:54:07,288:INFO:Importing untrained model
2025-03-13 00:54:07,292:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-13 00:54:07,298:INFO:Starting cross validation
2025-03-13 00:54:07,299:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:07,373:INFO:Calculating mean and std
2025-03-13 00:54:07,373:INFO:Creating metrics dataframe
2025-03-13 00:54:07,374:INFO:Uploading results into container
2025-03-13 00:54:07,374:INFO:Uploading model into container now
2025-03-13 00:54:07,375:INFO:_master_model_container: 7
2025-03-13 00:54:07,375:INFO:_display_container: 2
2025-03-13 00:54:07,375:INFO:OrthogonalMatchingPursuit()
2025-03-13 00:54:07,375:INFO:create_model() successfully completed......................................
2025-03-13 00:54:07,436:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:07,436:INFO:Creating metrics dataframe
2025-03-13 00:54:07,441:INFO:Initializing Bayesian Ridge
2025-03-13 00:54:07,441:INFO:Total runtime is 0.01995919545491537 minutes
2025-03-13 00:54:07,444:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:07,444:INFO:Initializing create_model()
2025-03-13 00:54:07,444:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:07,444:INFO:Checking exceptions
2025-03-13 00:54:07,444:INFO:Importing libraries
2025-03-13 00:54:07,444:INFO:Copying training dataset
2025-03-13 00:54:07,450:INFO:Defining folds
2025-03-13 00:54:07,450:INFO:Declaring metric variables
2025-03-13 00:54:07,452:INFO:Importing untrained model
2025-03-13 00:54:07,455:INFO:Bayesian Ridge Imported successfully
2025-03-13 00:54:07,462:INFO:Starting cross validation
2025-03-13 00:54:07,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:07,545:INFO:Calculating mean and std
2025-03-13 00:54:07,545:INFO:Creating metrics dataframe
2025-03-13 00:54:07,545:INFO:Uploading results into container
2025-03-13 00:54:07,547:INFO:Uploading model into container now
2025-03-13 00:54:07,547:INFO:_master_model_container: 8
2025-03-13 00:54:07,547:INFO:_display_container: 2
2025-03-13 00:54:07,547:INFO:BayesianRidge()
2025-03-13 00:54:07,547:INFO:create_model() successfully completed......................................
2025-03-13 00:54:07,607:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:07,608:INFO:Creating metrics dataframe
2025-03-13 00:54:07,613:INFO:Initializing Passive Aggressive Regressor
2025-03-13 00:54:07,613:INFO:Total runtime is 0.022822169462839766 minutes
2025-03-13 00:54:07,614:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:07,616:INFO:Initializing create_model()
2025-03-13 00:54:07,616:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:07,616:INFO:Checking exceptions
2025-03-13 00:54:07,616:INFO:Importing libraries
2025-03-13 00:54:07,616:INFO:Copying training dataset
2025-03-13 00:54:07,622:INFO:Defining folds
2025-03-13 00:54:07,622:INFO:Declaring metric variables
2025-03-13 00:54:07,625:INFO:Importing untrained model
2025-03-13 00:54:07,628:INFO:Passive Aggressive Regressor Imported successfully
2025-03-13 00:54:07,633:INFO:Starting cross validation
2025-03-13 00:54:07,634:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:07,707:INFO:Calculating mean and std
2025-03-13 00:54:07,708:INFO:Creating metrics dataframe
2025-03-13 00:54:07,708:INFO:Uploading results into container
2025-03-13 00:54:07,708:INFO:Uploading model into container now
2025-03-13 00:54:07,709:INFO:_master_model_container: 9
2025-03-13 00:54:07,709:INFO:_display_container: 2
2025-03-13 00:54:07,709:INFO:PassiveAggressiveRegressor(random_state=6896)
2025-03-13 00:54:07,709:INFO:create_model() successfully completed......................................
2025-03-13 00:54:07,771:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:07,771:INFO:Creating metrics dataframe
2025-03-13 00:54:07,777:INFO:Initializing Huber Regressor
2025-03-13 00:54:07,777:INFO:Total runtime is 0.025565846761067712 minutes
2025-03-13 00:54:07,780:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:07,780:INFO:Initializing create_model()
2025-03-13 00:54:07,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:07,781:INFO:Checking exceptions
2025-03-13 00:54:07,781:INFO:Importing libraries
2025-03-13 00:54:07,781:INFO:Copying training dataset
2025-03-13 00:54:07,787:INFO:Defining folds
2025-03-13 00:54:07,787:INFO:Declaring metric variables
2025-03-13 00:54:07,789:INFO:Importing untrained model
2025-03-13 00:54:07,792:INFO:Huber Regressor Imported successfully
2025-03-13 00:54:07,797:INFO:Starting cross validation
2025-03-13 00:54:07,798:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:07,846:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:54:07,848:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:54:07,849:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:54:07,854:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:54:07,860:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:54:07,861:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:54:07,863:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:54:07,868:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:54:07,870:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:54:07,872:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:54:07,887:INFO:Calculating mean and std
2025-03-13 00:54:07,887:INFO:Creating metrics dataframe
2025-03-13 00:54:07,889:INFO:Uploading results into container
2025-03-13 00:54:07,890:INFO:Uploading model into container now
2025-03-13 00:54:07,890:INFO:_master_model_container: 10
2025-03-13 00:54:07,890:INFO:_display_container: 2
2025-03-13 00:54:07,890:INFO:HuberRegressor()
2025-03-13 00:54:07,890:INFO:create_model() successfully completed......................................
2025-03-13 00:54:07,952:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:07,952:INFO:Creating metrics dataframe
2025-03-13 00:54:07,956:INFO:Initializing K Neighbors Regressor
2025-03-13 00:54:07,956:INFO:Total runtime is 0.028549619515736903 minutes
2025-03-13 00:54:07,959:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:07,959:INFO:Initializing create_model()
2025-03-13 00:54:07,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:07,960:INFO:Checking exceptions
2025-03-13 00:54:07,960:INFO:Importing libraries
2025-03-13 00:54:07,960:INFO:Copying training dataset
2025-03-13 00:54:07,967:INFO:Defining folds
2025-03-13 00:54:07,967:INFO:Declaring metric variables
2025-03-13 00:54:07,968:INFO:Importing untrained model
2025-03-13 00:54:07,971:INFO:K Neighbors Regressor Imported successfully
2025-03-13 00:54:07,977:INFO:Starting cross validation
2025-03-13 00:54:07,979:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:08,051:INFO:Calculating mean and std
2025-03-13 00:54:08,051:INFO:Creating metrics dataframe
2025-03-13 00:54:08,052:INFO:Uploading results into container
2025-03-13 00:54:08,052:INFO:Uploading model into container now
2025-03-13 00:54:08,052:INFO:_master_model_container: 11
2025-03-13 00:54:08,054:INFO:_display_container: 2
2025-03-13 00:54:08,054:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-13 00:54:08,054:INFO:create_model() successfully completed......................................
2025-03-13 00:54:08,134:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:08,134:INFO:Creating metrics dataframe
2025-03-13 00:54:08,143:INFO:Initializing Decision Tree Regressor
2025-03-13 00:54:08,143:INFO:Total runtime is 0.031665686766306565 minutes
2025-03-13 00:54:08,146:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:08,148:INFO:Initializing create_model()
2025-03-13 00:54:08,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:08,148:INFO:Checking exceptions
2025-03-13 00:54:08,148:INFO:Importing libraries
2025-03-13 00:54:08,148:INFO:Copying training dataset
2025-03-13 00:54:08,157:INFO:Defining folds
2025-03-13 00:54:08,157:INFO:Declaring metric variables
2025-03-13 00:54:08,159:INFO:Importing untrained model
2025-03-13 00:54:08,161:INFO:Decision Tree Regressor Imported successfully
2025-03-13 00:54:08,165:INFO:Starting cross validation
2025-03-13 00:54:08,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:08,261:INFO:Calculating mean and std
2025-03-13 00:54:08,261:INFO:Creating metrics dataframe
2025-03-13 00:54:08,261:INFO:Uploading results into container
2025-03-13 00:54:08,261:INFO:Uploading model into container now
2025-03-13 00:54:08,263:INFO:_master_model_container: 12
2025-03-13 00:54:08,263:INFO:_display_container: 2
2025-03-13 00:54:08,263:INFO:DecisionTreeRegressor(random_state=6896)
2025-03-13 00:54:08,263:INFO:create_model() successfully completed......................................
2025-03-13 00:54:08,327:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:08,328:INFO:Creating metrics dataframe
2025-03-13 00:54:08,332:INFO:Initializing Random Forest Regressor
2025-03-13 00:54:08,332:INFO:Total runtime is 0.03481788237889608 minutes
2025-03-13 00:54:08,336:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:08,336:INFO:Initializing create_model()
2025-03-13 00:54:08,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:08,336:INFO:Checking exceptions
2025-03-13 00:54:08,336:INFO:Importing libraries
2025-03-13 00:54:08,336:INFO:Copying training dataset
2025-03-13 00:54:08,344:INFO:Defining folds
2025-03-13 00:54:08,344:INFO:Declaring metric variables
2025-03-13 00:54:08,349:INFO:Importing untrained model
2025-03-13 00:54:08,355:INFO:Random Forest Regressor Imported successfully
2025-03-13 00:54:08,366:INFO:Starting cross validation
2025-03-13 00:54:08,367:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:09,562:INFO:Calculating mean and std
2025-03-13 00:54:09,563:INFO:Creating metrics dataframe
2025-03-13 00:54:09,564:INFO:Uploading results into container
2025-03-13 00:54:09,566:INFO:Uploading model into container now
2025-03-13 00:54:09,566:INFO:_master_model_container: 13
2025-03-13 00:54:09,566:INFO:_display_container: 2
2025-03-13 00:54:09,566:INFO:RandomForestRegressor(n_jobs=-1, random_state=6896)
2025-03-13 00:54:09,566:INFO:create_model() successfully completed......................................
2025-03-13 00:54:09,645:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:09,645:INFO:Creating metrics dataframe
2025-03-13 00:54:09,651:INFO:Initializing Extra Trees Regressor
2025-03-13 00:54:09,651:INFO:Total runtime is 0.05680207411448161 minutes
2025-03-13 00:54:09,653:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:09,653:INFO:Initializing create_model()
2025-03-13 00:54:09,654:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:09,654:INFO:Checking exceptions
2025-03-13 00:54:09,654:INFO:Importing libraries
2025-03-13 00:54:09,654:INFO:Copying training dataset
2025-03-13 00:54:09,663:INFO:Defining folds
2025-03-13 00:54:09,663:INFO:Declaring metric variables
2025-03-13 00:54:09,666:INFO:Importing untrained model
2025-03-13 00:54:09,668:INFO:Extra Trees Regressor Imported successfully
2025-03-13 00:54:09,672:INFO:Starting cross validation
2025-03-13 00:54:09,674:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:10,253:INFO:Calculating mean and std
2025-03-13 00:54:10,253:INFO:Creating metrics dataframe
2025-03-13 00:54:10,254:INFO:Uploading results into container
2025-03-13 00:54:10,255:INFO:Uploading model into container now
2025-03-13 00:54:10,255:INFO:_master_model_container: 14
2025-03-13 00:54:10,255:INFO:_display_container: 2
2025-03-13 00:54:10,255:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6896)
2025-03-13 00:54:10,255:INFO:create_model() successfully completed......................................
2025-03-13 00:54:10,316:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:10,316:INFO:Creating metrics dataframe
2025-03-13 00:54:10,322:INFO:Initializing AdaBoost Regressor
2025-03-13 00:54:10,322:INFO:Total runtime is 0.06798603534698487 minutes
2025-03-13 00:54:10,324:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:10,324:INFO:Initializing create_model()
2025-03-13 00:54:10,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:10,324:INFO:Checking exceptions
2025-03-13 00:54:10,324:INFO:Importing libraries
2025-03-13 00:54:10,324:INFO:Copying training dataset
2025-03-13 00:54:10,331:INFO:Defining folds
2025-03-13 00:54:10,331:INFO:Declaring metric variables
2025-03-13 00:54:10,334:INFO:Importing untrained model
2025-03-13 00:54:10,337:INFO:AdaBoost Regressor Imported successfully
2025-03-13 00:54:10,341:INFO:Starting cross validation
2025-03-13 00:54:10,341:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:10,618:INFO:Calculating mean and std
2025-03-13 00:54:10,618:INFO:Creating metrics dataframe
2025-03-13 00:54:10,620:INFO:Uploading results into container
2025-03-13 00:54:10,621:INFO:Uploading model into container now
2025-03-13 00:54:10,621:INFO:_master_model_container: 15
2025-03-13 00:54:10,621:INFO:_display_container: 2
2025-03-13 00:54:10,621:INFO:AdaBoostRegressor(random_state=6896)
2025-03-13 00:54:10,621:INFO:create_model() successfully completed......................................
2025-03-13 00:54:10,683:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:10,683:INFO:Creating metrics dataframe
2025-03-13 00:54:10,689:INFO:Initializing Gradient Boosting Regressor
2025-03-13 00:54:10,689:INFO:Total runtime is 0.07408967018127442 minutes
2025-03-13 00:54:10,690:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:10,690:INFO:Initializing create_model()
2025-03-13 00:54:10,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:10,690:INFO:Checking exceptions
2025-03-13 00:54:10,690:INFO:Importing libraries
2025-03-13 00:54:10,690:INFO:Copying training dataset
2025-03-13 00:54:10,696:INFO:Defining folds
2025-03-13 00:54:10,696:INFO:Declaring metric variables
2025-03-13 00:54:10,699:INFO:Importing untrained model
2025-03-13 00:54:10,701:INFO:Gradient Boosting Regressor Imported successfully
2025-03-13 00:54:10,708:INFO:Starting cross validation
2025-03-13 00:54:10,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:11,361:INFO:Calculating mean and std
2025-03-13 00:54:11,362:INFO:Creating metrics dataframe
2025-03-13 00:54:11,363:INFO:Uploading results into container
2025-03-13 00:54:11,363:INFO:Uploading model into container now
2025-03-13 00:54:11,364:INFO:_master_model_container: 16
2025-03-13 00:54:11,364:INFO:_display_container: 2
2025-03-13 00:54:11,364:INFO:GradientBoostingRegressor(random_state=6896)
2025-03-13 00:54:11,364:INFO:create_model() successfully completed......................................
2025-03-13 00:54:11,433:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:11,433:INFO:Creating metrics dataframe
2025-03-13 00:54:11,438:INFO:Initializing Light Gradient Boosting Machine
2025-03-13 00:54:11,438:INFO:Total runtime is 0.08657821416854859 minutes
2025-03-13 00:54:11,440:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:11,440:INFO:Initializing create_model()
2025-03-13 00:54:11,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:11,440:INFO:Checking exceptions
2025-03-13 00:54:11,440:INFO:Importing libraries
2025-03-13 00:54:11,440:INFO:Copying training dataset
2025-03-13 00:54:11,450:INFO:Defining folds
2025-03-13 00:54:11,450:INFO:Declaring metric variables
2025-03-13 00:54:11,453:INFO:Importing untrained model
2025-03-13 00:54:11,454:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-13 00:54:11,459:INFO:Starting cross validation
2025-03-13 00:54:11,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:12,147:INFO:Calculating mean and std
2025-03-13 00:54:12,148:INFO:Creating metrics dataframe
2025-03-13 00:54:12,150:INFO:Uploading results into container
2025-03-13 00:54:12,151:INFO:Uploading model into container now
2025-03-13 00:54:12,151:INFO:_master_model_container: 17
2025-03-13 00:54:12,151:INFO:_display_container: 2
2025-03-13 00:54:12,152:INFO:LGBMRegressor(n_jobs=-1, random_state=6896)
2025-03-13 00:54:12,152:INFO:create_model() successfully completed......................................
2025-03-13 00:54:12,233:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:12,233:INFO:Creating metrics dataframe
2025-03-13 00:54:12,240:INFO:Initializing Dummy Regressor
2025-03-13 00:54:12,240:INFO:Total runtime is 0.0999386747678121 minutes
2025-03-13 00:54:12,243:INFO:SubProcess create_model() called ==================================
2025-03-13 00:54:12,243:INFO:Initializing create_model()
2025-03-13 00:54:12,243:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000026A7C2E67D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:12,243:INFO:Checking exceptions
2025-03-13 00:54:12,243:INFO:Importing libraries
2025-03-13 00:54:12,243:INFO:Copying training dataset
2025-03-13 00:54:12,250:INFO:Defining folds
2025-03-13 00:54:12,250:INFO:Declaring metric variables
2025-03-13 00:54:12,252:INFO:Importing untrained model
2025-03-13 00:54:12,254:INFO:Dummy Regressor Imported successfully
2025-03-13 00:54:12,258:INFO:Starting cross validation
2025-03-13 00:54:12,259:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:12,333:INFO:Calculating mean and std
2025-03-13 00:54:12,334:INFO:Creating metrics dataframe
2025-03-13 00:54:12,334:INFO:Uploading results into container
2025-03-13 00:54:12,334:INFO:Uploading model into container now
2025-03-13 00:54:12,335:INFO:_master_model_container: 18
2025-03-13 00:54:12,335:INFO:_display_container: 2
2025-03-13 00:54:12,335:INFO:DummyRegressor()
2025-03-13 00:54:12,335:INFO:create_model() successfully completed......................................
2025-03-13 00:54:12,398:INFO:SubProcess create_model() end ==================================
2025-03-13 00:54:12,399:INFO:Creating metrics dataframe
2025-03-13 00:54:12,405:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-03-13 00:54:12,411:INFO:Initializing create_model()
2025-03-13 00:54:12,412:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:12,412:INFO:Checking exceptions
2025-03-13 00:54:12,412:INFO:Importing libraries
2025-03-13 00:54:12,414:INFO:Copying training dataset
2025-03-13 00:54:12,420:INFO:Defining folds
2025-03-13 00:54:12,420:INFO:Declaring metric variables
2025-03-13 00:54:12,420:INFO:Importing untrained model
2025-03-13 00:54:12,420:INFO:Declaring custom model
2025-03-13 00:54:12,420:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-13 00:54:12,421:INFO:Cross validation set to False
2025-03-13 00:54:12,421:INFO:Fitting Model
2025-03-13 00:54:12,434:INFO:OrthogonalMatchingPursuit()
2025-03-13 00:54:12,434:INFO:create_model() successfully completed......................................
2025-03-13 00:54:12,511:INFO:Initializing create_model()
2025-03-13 00:54:12,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=6896), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:12,511:INFO:Checking exceptions
2025-03-13 00:54:12,513:INFO:Importing libraries
2025-03-13 00:54:12,513:INFO:Copying training dataset
2025-03-13 00:54:12,519:INFO:Defining folds
2025-03-13 00:54:12,519:INFO:Declaring metric variables
2025-03-13 00:54:12,519:INFO:Importing untrained model
2025-03-13 00:54:12,519:INFO:Declaring custom model
2025-03-13 00:54:12,520:INFO:Extra Trees Regressor Imported successfully
2025-03-13 00:54:12,521:INFO:Cross validation set to False
2025-03-13 00:54:12,521:INFO:Fitting Model
2025-03-13 00:54:12,621:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6896)
2025-03-13 00:54:12,621:INFO:create_model() successfully completed......................................
2025-03-13 00:54:12,691:INFO:Initializing create_model()
2025-03-13 00:54:12,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=LassoLars(random_state=6896), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:12,691:INFO:Checking exceptions
2025-03-13 00:54:12,693:INFO:Importing libraries
2025-03-13 00:54:12,693:INFO:Copying training dataset
2025-03-13 00:54:12,699:INFO:Defining folds
2025-03-13 00:54:12,699:INFO:Declaring metric variables
2025-03-13 00:54:12,699:INFO:Importing untrained model
2025-03-13 00:54:12,699:INFO:Declaring custom model
2025-03-13 00:54:12,700:INFO:Lasso Least Angle Regression Imported successfully
2025-03-13 00:54:12,700:INFO:Cross validation set to False
2025-03-13 00:54:12,700:INFO:Fitting Model
2025-03-13 00:54:12,714:INFO:LassoLars(random_state=6896)
2025-03-13 00:54:12,714:INFO:create_model() successfully completed......................................
2025-03-13 00:54:12,785:INFO:Initializing create_model()
2025-03-13 00:54:12,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=Lasso(random_state=6896), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:12,785:INFO:Checking exceptions
2025-03-13 00:54:12,785:INFO:Importing libraries
2025-03-13 00:54:12,785:INFO:Copying training dataset
2025-03-13 00:54:12,793:INFO:Defining folds
2025-03-13 00:54:12,793:INFO:Declaring metric variables
2025-03-13 00:54:12,793:INFO:Importing untrained model
2025-03-13 00:54:12,793:INFO:Declaring custom model
2025-03-13 00:54:12,793:INFO:Lasso Regression Imported successfully
2025-03-13 00:54:12,794:INFO:Cross validation set to False
2025-03-13 00:54:12,794:INFO:Fitting Model
2025-03-13 00:54:12,807:INFO:Lasso(random_state=6896)
2025-03-13 00:54:12,807:INFO:create_model() successfully completed......................................
2025-03-13 00:54:12,879:INFO:Initializing create_model()
2025-03-13 00:54:12,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=ElasticNet(random_state=6896), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:12,879:INFO:Checking exceptions
2025-03-13 00:54:12,881:INFO:Importing libraries
2025-03-13 00:54:12,881:INFO:Copying training dataset
2025-03-13 00:54:12,887:INFO:Defining folds
2025-03-13 00:54:12,887:INFO:Declaring metric variables
2025-03-13 00:54:12,887:INFO:Importing untrained model
2025-03-13 00:54:12,887:INFO:Declaring custom model
2025-03-13 00:54:12,888:INFO:Elastic Net Imported successfully
2025-03-13 00:54:12,888:INFO:Cross validation set to False
2025-03-13 00:54:12,888:INFO:Fitting Model
2025-03-13 00:54:12,904:INFO:ElasticNet(random_state=6896)
2025-03-13 00:54:12,904:INFO:create_model() successfully completed......................................
2025-03-13 00:54:12,977:INFO:Initializing create_model()
2025-03-13 00:54:12,977:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=Ridge(random_state=6896), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:12,977:INFO:Checking exceptions
2025-03-13 00:54:12,977:INFO:Importing libraries
2025-03-13 00:54:12,978:INFO:Copying training dataset
2025-03-13 00:54:12,986:INFO:Defining folds
2025-03-13 00:54:12,986:INFO:Declaring metric variables
2025-03-13 00:54:12,986:INFO:Importing untrained model
2025-03-13 00:54:12,986:INFO:Declaring custom model
2025-03-13 00:54:12,986:INFO:Ridge Regression Imported successfully
2025-03-13 00:54:12,987:INFO:Cross validation set to False
2025-03-13 00:54:12,987:INFO:Fitting Model
2025-03-13 00:54:13,003:INFO:Ridge(random_state=6896)
2025-03-13 00:54:13,003:INFO:create_model() successfully completed......................................
2025-03-13 00:54:13,075:INFO:Initializing create_model()
2025-03-13 00:54:13,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:13,077:INFO:Checking exceptions
2025-03-13 00:54:13,077:INFO:Importing libraries
2025-03-13 00:54:13,077:INFO:Copying training dataset
2025-03-13 00:54:13,084:INFO:Defining folds
2025-03-13 00:54:13,084:INFO:Declaring metric variables
2025-03-13 00:54:13,084:INFO:Importing untrained model
2025-03-13 00:54:13,084:INFO:Declaring custom model
2025-03-13 00:54:13,086:INFO:Bayesian Ridge Imported successfully
2025-03-13 00:54:13,086:INFO:Cross validation set to False
2025-03-13 00:54:13,086:INFO:Fitting Model
2025-03-13 00:54:13,109:INFO:BayesianRidge()
2025-03-13 00:54:13,109:INFO:create_model() successfully completed......................................
2025-03-13 00:54:13,178:INFO:Initializing create_model()
2025-03-13 00:54:13,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=6896), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:13,178:INFO:Checking exceptions
2025-03-13 00:54:13,179:INFO:Importing libraries
2025-03-13 00:54:13,180:INFO:Copying training dataset
2025-03-13 00:54:13,188:INFO:Defining folds
2025-03-13 00:54:13,188:INFO:Declaring metric variables
2025-03-13 00:54:13,188:INFO:Importing untrained model
2025-03-13 00:54:13,188:INFO:Declaring custom model
2025-03-13 00:54:13,189:INFO:Random Forest Regressor Imported successfully
2025-03-13 00:54:13,189:INFO:Cross validation set to False
2025-03-13 00:54:13,189:INFO:Fitting Model
2025-03-13 00:54:13,354:INFO:RandomForestRegressor(n_jobs=-1, random_state=6896)
2025-03-13 00:54:13,355:INFO:create_model() successfully completed......................................
2025-03-13 00:54:13,418:INFO:Initializing create_model()
2025-03-13 00:54:13,418:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:13,418:INFO:Checking exceptions
2025-03-13 00:54:13,419:INFO:Importing libraries
2025-03-13 00:54:13,419:INFO:Copying training dataset
2025-03-13 00:54:13,425:INFO:Defining folds
2025-03-13 00:54:13,425:INFO:Declaring metric variables
2025-03-13 00:54:13,425:INFO:Importing untrained model
2025-03-13 00:54:13,425:INFO:Declaring custom model
2025-03-13 00:54:13,425:INFO:Linear Regression Imported successfully
2025-03-13 00:54:13,425:INFO:Cross validation set to False
2025-03-13 00:54:13,425:INFO:Fitting Model
2025-03-13 00:54:13,440:INFO:LinearRegression(n_jobs=-1)
2025-03-13 00:54:13,442:INFO:create_model() successfully completed......................................
2025-03-13 00:54:13,507:INFO:Initializing create_model()
2025-03-13 00:54:13,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=GradientBoostingRegressor(random_state=6896), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:13,507:INFO:Checking exceptions
2025-03-13 00:54:13,509:INFO:Importing libraries
2025-03-13 00:54:13,509:INFO:Copying training dataset
2025-03-13 00:54:13,516:INFO:Defining folds
2025-03-13 00:54:13,516:INFO:Declaring metric variables
2025-03-13 00:54:13,516:INFO:Importing untrained model
2025-03-13 00:54:13,516:INFO:Declaring custom model
2025-03-13 00:54:13,516:INFO:Gradient Boosting Regressor Imported successfully
2025-03-13 00:54:13,516:INFO:Cross validation set to False
2025-03-13 00:54:13,516:INFO:Fitting Model
2025-03-13 00:54:14,019:INFO:GradientBoostingRegressor(random_state=6896)
2025-03-13 00:54:14,019:INFO:create_model() successfully completed......................................
2025-03-13 00:54:14,091:INFO:Initializing create_model()
2025-03-13 00:54:14,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=HuberRegressor(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:14,091:INFO:Checking exceptions
2025-03-13 00:54:14,093:INFO:Importing libraries
2025-03-13 00:54:14,093:INFO:Copying training dataset
2025-03-13 00:54:14,100:INFO:Defining folds
2025-03-13 00:54:14,100:INFO:Declaring metric variables
2025-03-13 00:54:14,100:INFO:Importing untrained model
2025-03-13 00:54:14,100:INFO:Declaring custom model
2025-03-13 00:54:14,100:INFO:Huber Regressor Imported successfully
2025-03-13 00:54:14,102:INFO:Cross validation set to False
2025-03-13 00:54:14,102:INFO:Fitting Model
2025-03-13 00:54:14,146:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 00:54:14,146:INFO:HuberRegressor()
2025-03-13 00:54:14,146:INFO:create_model() successfully completed......................................
2025-03-13 00:54:14,214:INFO:Initializing create_model()
2025-03-13 00:54:14,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=AdaBoostRegressor(random_state=6896), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:14,214:INFO:Checking exceptions
2025-03-13 00:54:14,216:INFO:Importing libraries
2025-03-13 00:54:14,216:INFO:Copying training dataset
2025-03-13 00:54:14,223:INFO:Defining folds
2025-03-13 00:54:14,223:INFO:Declaring metric variables
2025-03-13 00:54:14,223:INFO:Importing untrained model
2025-03-13 00:54:14,223:INFO:Declaring custom model
2025-03-13 00:54:14,223:INFO:AdaBoost Regressor Imported successfully
2025-03-13 00:54:14,223:INFO:Cross validation set to False
2025-03-13 00:54:14,223:INFO:Fitting Model
2025-03-13 00:54:14,391:INFO:AdaBoostRegressor(random_state=6896)
2025-03-13 00:54:14,391:INFO:create_model() successfully completed......................................
2025-03-13 00:54:14,454:INFO:Initializing create_model()
2025-03-13 00:54:14,454:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=6896), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:14,454:INFO:Checking exceptions
2025-03-13 00:54:14,456:INFO:Importing libraries
2025-03-13 00:54:14,456:INFO:Copying training dataset
2025-03-13 00:54:14,462:INFO:Defining folds
2025-03-13 00:54:14,462:INFO:Declaring metric variables
2025-03-13 00:54:14,462:INFO:Importing untrained model
2025-03-13 00:54:14,462:INFO:Declaring custom model
2025-03-13 00:54:14,462:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-13 00:54:14,464:INFO:Cross validation set to False
2025-03-13 00:54:14,464:INFO:Fitting Model
2025-03-13 00:54:14,479:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000496 seconds.
2025-03-13 00:54:14,479:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-13 00:54:14,479:INFO:[LightGBM] [Info] Total Bins 5456
2025-03-13 00:54:14,480:INFO:[LightGBM] [Info] Number of data points in the train set: 350, number of used features: 59
2025-03-13 00:54:14,480:INFO:[LightGBM] [Info] Start training from score 20.162207
2025-03-13 00:54:14,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 00:54:14,530:INFO:LGBMRegressor(n_jobs=-1, random_state=6896)
2025-03-13 00:54:14,530:INFO:create_model() successfully completed......................................
2025-03-13 00:54:14,602:INFO:Initializing create_model()
2025-03-13 00:54:14,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:14,604:INFO:Checking exceptions
2025-03-13 00:54:14,605:INFO:Importing libraries
2025-03-13 00:54:14,605:INFO:Copying training dataset
2025-03-13 00:54:14,614:INFO:Defining folds
2025-03-13 00:54:14,614:INFO:Declaring metric variables
2025-03-13 00:54:14,614:INFO:Importing untrained model
2025-03-13 00:54:14,614:INFO:Declaring custom model
2025-03-13 00:54:14,614:INFO:K Neighbors Regressor Imported successfully
2025-03-13 00:54:14,614:INFO:Cross validation set to False
2025-03-13 00:54:14,614:INFO:Fitting Model
2025-03-13 00:54:14,630:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-13 00:54:14,630:INFO:create_model() successfully completed......................................
2025-03-13 00:54:14,694:INFO:Initializing create_model()
2025-03-13 00:54:14,694:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=DecisionTreeRegressor(random_state=6896), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:14,694:INFO:Checking exceptions
2025-03-13 00:54:14,696:INFO:Importing libraries
2025-03-13 00:54:14,696:INFO:Copying training dataset
2025-03-13 00:54:14,702:INFO:Defining folds
2025-03-13 00:54:14,702:INFO:Declaring metric variables
2025-03-13 00:54:14,702:INFO:Importing untrained model
2025-03-13 00:54:14,702:INFO:Declaring custom model
2025-03-13 00:54:14,703:INFO:Decision Tree Regressor Imported successfully
2025-03-13 00:54:14,703:INFO:Cross validation set to False
2025-03-13 00:54:14,703:INFO:Fitting Model
2025-03-13 00:54:14,727:INFO:DecisionTreeRegressor(random_state=6896)
2025-03-13 00:54:14,727:INFO:create_model() successfully completed......................................
2025-03-13 00:54:14,805:INFO:_master_model_container: 18
2025-03-13 00:54:14,805:INFO:_display_container: 2
2025-03-13 00:54:14,807:INFO:[OrthogonalMatchingPursuit(), ExtraTreesRegressor(n_jobs=-1, random_state=6896), LassoLars(random_state=6896), Lasso(random_state=6896), ElasticNet(random_state=6896), Ridge(random_state=6896), BayesianRidge(), RandomForestRegressor(n_jobs=-1, random_state=6896), LinearRegression(n_jobs=-1), GradientBoostingRegressor(random_state=6896), HuberRegressor(), AdaBoostRegressor(random_state=6896), LGBMRegressor(n_jobs=-1, random_state=6896), KNeighborsRegressor(n_jobs=-1), DecisionTreeRegressor(random_state=6896)]
2025-03-13 00:54:14,807:INFO:compare_models() successfully completed......................................
2025-03-13 00:54:14,857:INFO:Initializing create_model()
2025-03-13 00:54:14,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 00:54:14,857:INFO:Checking exceptions
2025-03-13 00:54:14,867:INFO:Importing libraries
2025-03-13 00:54:14,867:INFO:Copying training dataset
2025-03-13 00:54:14,873:INFO:Defining folds
2025-03-13 00:54:14,873:INFO:Declaring metric variables
2025-03-13 00:54:14,876:INFO:Importing untrained model
2025-03-13 00:54:14,879:INFO:Random Forest Regressor Imported successfully
2025-03-13 00:54:14,885:INFO:Starting cross validation
2025-03-13 00:54:14,887:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 00:54:16,132:INFO:Calculating mean and std
2025-03-13 00:54:16,133:INFO:Creating metrics dataframe
2025-03-13 00:54:16,136:INFO:Finalizing model
2025-03-13 00:54:16,313:INFO:Uploading results into container
2025-03-13 00:54:16,313:INFO:Uploading model into container now
2025-03-13 00:54:16,323:INFO:_master_model_container: 19
2025-03-13 00:54:16,323:INFO:_display_container: 3
2025-03-13 00:54:16,325:INFO:RandomForestRegressor(n_jobs=-1, random_state=6896)
2025-03-13 00:54:16,325:INFO:create_model() successfully completed......................................
2025-03-13 00:54:22,074:INFO:Initializing predict_model()
2025-03-13 00:54:22,074:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000026A78F7CFD0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=6896), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000026A5C2D51C0>)
2025-03-13 00:54:22,074:INFO:Checking exceptions
2025-03-13 00:54:22,074:INFO:Preloading libraries
2025-03-13 00:54:22,076:INFO:Set up data.
2025-03-13 00:54:22,084:INFO:Set up index.
2025-03-13 15:04:07,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-13 15:04:07,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-13 15:04:07,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-13 15:04:07,916:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-13 15:04:08,017:INFO:PyCaret RegressionExperiment
2025-03-13 15:04:08,017:INFO:Logging name: reg-default-name
2025-03-13 15:04:08,017:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-13 15:04:08,017:INFO:version 3.3.2
2025-03-13 15:04:08,017:INFO:Initializing setup()
2025-03-13 15:04:08,017:INFO:self.USI: 2332
2025-03-13 15:04:08,017:INFO:self._variable_keys: {'_ml_usecase', 'gpu_param', 'X_test', 'data', 'exp_id', 'gpu_n_jobs_param', 'fold_generator', 'X', '_available_plots', 'y_train', 'seed', 'n_jobs_param', 'logging_param', 'target_param', 'fold_shuffle_param', 'transform_target_param', 'log_plots_param', 'memory', 'y_test', 'exp_name_log', 'X_train', 'fold_groups_param', 'idx', 'html_param', 'y', 'pipeline', 'USI'}
2025-03-13 15:04:08,017:INFO:Checking environment
2025-03-13 15:04:08,017:INFO:python_version: 3.11.9
2025-03-13 15:04:08,017:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-03-13 15:04:08,017:INFO:machine: AMD64
2025-03-13 15:04:08,017:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-13 15:04:08,020:INFO:Memory: svmem(total=34193833984, available=19677130752, percent=42.5, used=14516703232, free=19677130752)
2025-03-13 15:04:08,020:INFO:Physical Core: 6
2025-03-13 15:04:08,020:INFO:Logical Core: 12
2025-03-13 15:04:08,020:INFO:Checking libraries
2025-03-13 15:04:08,020:INFO:System:
2025-03-13 15:04:08,020:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-03-13 15:04:08,020:INFO:executable: d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Scripts\python.exe
2025-03-13 15:04:08,020:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-13 15:04:08,020:INFO:PyCaret required dependencies:
2025-03-13 15:04:08,036:INFO:                 pip: 24.0
2025-03-13 15:04:08,036:INFO:          setuptools: 65.5.0
2025-03-13 15:04:08,036:INFO:             pycaret: 3.3.2
2025-03-13 15:04:08,036:INFO:             IPython: 8.32.0
2025-03-13 15:04:08,036:INFO:          ipywidgets: 8.1.5
2025-03-13 15:04:08,036:INFO:                tqdm: 4.67.1
2025-03-13 15:04:08,036:INFO:               numpy: 1.26.4
2025-03-13 15:04:08,036:INFO:              pandas: 2.1.4
2025-03-13 15:04:08,036:INFO:              jinja2: 3.1.5
2025-03-13 15:04:08,036:INFO:               scipy: 1.11.4
2025-03-13 15:04:08,036:INFO:              joblib: 1.3.2
2025-03-13 15:04:08,036:INFO:             sklearn: 1.4.2
2025-03-13 15:04:08,036:INFO:                pyod: 2.0.3
2025-03-13 15:04:08,036:INFO:            imblearn: 0.13.0
2025-03-13 15:04:08,036:INFO:   category_encoders: 2.7.0
2025-03-13 15:04:08,036:INFO:            lightgbm: 4.6.0
2025-03-13 15:04:08,036:INFO:               numba: 0.61.0
2025-03-13 15:04:08,036:INFO:            requests: 2.32.3
2025-03-13 15:04:08,036:INFO:          matplotlib: 3.7.5
2025-03-13 15:04:08,036:INFO:          scikitplot: 0.3.7
2025-03-13 15:04:08,036:INFO:         yellowbrick: 1.5
2025-03-13 15:04:08,036:INFO:              plotly: 5.24.1
2025-03-13 15:04:08,036:INFO:    plotly-resampler: Not installed
2025-03-13 15:04:08,036:INFO:             kaleido: 0.2.1
2025-03-13 15:04:08,036:INFO:           schemdraw: 0.15
2025-03-13 15:04:08,036:INFO:         statsmodels: 0.14.4
2025-03-13 15:04:08,036:INFO:              sktime: 0.26.0
2025-03-13 15:04:08,036:INFO:               tbats: 1.1.3
2025-03-13 15:04:08,036:INFO:            pmdarima: 2.0.4
2025-03-13 15:04:08,036:INFO:              psutil: 7.0.0
2025-03-13 15:04:08,036:INFO:          markupsafe: 3.0.2
2025-03-13 15:04:08,037:INFO:             pickle5: Not installed
2025-03-13 15:04:08,037:INFO:         cloudpickle: 3.1.1
2025-03-13 15:04:08,037:INFO:         deprecation: 2.1.0
2025-03-13 15:04:08,037:INFO:              xxhash: 3.5.0
2025-03-13 15:04:08,037:INFO:           wurlitzer: Not installed
2025-03-13 15:04:08,037:INFO:PyCaret optional dependencies:
2025-03-13 15:04:08,044:INFO:                shap: Not installed
2025-03-13 15:04:08,044:INFO:           interpret: Not installed
2025-03-13 15:04:08,044:INFO:                umap: Not installed
2025-03-13 15:04:08,044:INFO:     ydata_profiling: Not installed
2025-03-13 15:04:08,044:INFO:  explainerdashboard: Not installed
2025-03-13 15:04:08,044:INFO:             autoviz: Not installed
2025-03-13 15:04:08,044:INFO:           fairlearn: Not installed
2025-03-13 15:04:08,044:INFO:          deepchecks: Not installed
2025-03-13 15:04:08,044:INFO:             xgboost: Not installed
2025-03-13 15:04:08,044:INFO:            catboost: Not installed
2025-03-13 15:04:08,044:INFO:              kmodes: Not installed
2025-03-13 15:04:08,044:INFO:             mlxtend: Not installed
2025-03-13 15:04:08,044:INFO:       statsforecast: Not installed
2025-03-13 15:04:08,044:INFO:        tune_sklearn: Not installed
2025-03-13 15:04:08,044:INFO:                 ray: Not installed
2025-03-13 15:04:08,044:INFO:            hyperopt: Not installed
2025-03-13 15:04:08,044:INFO:              optuna: Not installed
2025-03-13 15:04:08,044:INFO:               skopt: Not installed
2025-03-13 15:04:08,044:INFO:              mlflow: Not installed
2025-03-13 15:04:08,044:INFO:              gradio: Not installed
2025-03-13 15:04:08,044:INFO:             fastapi: Not installed
2025-03-13 15:04:08,044:INFO:             uvicorn: Not installed
2025-03-13 15:04:08,044:INFO:              m2cgen: Not installed
2025-03-13 15:04:08,044:INFO:           evidently: Not installed
2025-03-13 15:04:08,044:INFO:               fugue: Not installed
2025-03-13 15:04:08,044:INFO:           streamlit: Not installed
2025-03-13 15:04:08,044:INFO:             prophet: Not installed
2025-03-13 15:04:08,046:INFO:None
2025-03-13 15:04:08,046:INFO:Set up data.
2025-03-13 15:04:08,056:INFO:Set up folding strategy.
2025-03-13 15:04:08,056:INFO:Set up train/test split.
2025-03-13 15:04:08,062:INFO:Set up index.
2025-03-13 15:04:08,062:INFO:Assigning column types.
2025-03-13 15:04:08,068:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-13 15:04:08,068:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,071:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,074:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,115:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,144:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,147:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,150:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,190:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,218:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,218:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-13 15:04:08,221:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,225:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,273:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,300:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,302:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,306:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,343:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,372:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,372:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-13 15:04:08,377:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,416:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,443:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,445:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,445:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,449:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,487:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,515:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-13 15:04:08,561:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,589:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,589:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,632:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,661:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-13 15:04:08,703:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,731:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,772:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-13 15:04:08,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,800:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,800:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-13 15:04:08,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,947:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:08,949:INFO:Preparing preprocessing pipeline...
2025-03-13 15:04:08,949:INFO:Set up date feature engineering.
2025-03-13 15:04:08,949:INFO:Set up simple imputation.
2025-03-13 15:04:08,949:INFO:Set up removing outliers.
2025-03-13 15:04:08,988:INFO:Finished creating preprocessing pipeline.
2025-03-13 15:04:08,993:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Saeb0m\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['humidity', 'temperature', 'year',
                                             'month', 'day', 'day_of_week',
                                             'week_of_year', 'season',
                                             'dew_point', 'is_weekend',
                                             'tem...
                                             'pm_2_5_lag_4', 'pm_2_5_lag_5',
                                             'pm_2_5_lag_6', 'pm_2_5_lag_7',
                                             'pm_2_5_lag_8', 'pm_2_5_lag_9',
                                             'pm_2_5_lag_10', 'pm_2_5_lag_11',
                                             'pm_2_5_lag_12', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123)))])
2025-03-13 15:04:08,993:INFO:Creating final display dataframe.
2025-03-13 15:04:09,086:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            pm_2_5
2                   Target type        Regression
3           Original data shape         (500, 58)
4        Transformed data shape         (482, 60)
5   Transformed train set shape         (332, 60)
6    Transformed test set shape         (150, 60)
7              Numeric features                56
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13              Remove outliers              True
14           Outliers threshold              0.05
15               Fold Generator             KFold
16                  Fold Number                12
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              2332
2025-03-13 15:04:09,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:09,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:09,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:09,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-13 15:04:09,261:INFO:setup() successfully completed in 1.27s...............
2025-03-13 15:04:09,269:INFO:Initializing compare_models()
2025-03-13 15:04:09,269:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-03-13 15:04:09,269:INFO:Checking exceptions
2025-03-13 15:04:09,273:INFO:Preparing display monitor
2025-03-13 15:04:09,290:INFO:Initializing Linear Regression
2025-03-13 15:04:09,290:INFO:Total runtime is 0.0 minutes
2025-03-13 15:04:09,292:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:09,292:INFO:Initializing create_model()
2025-03-13 15:04:09,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=lr, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:09,292:INFO:Checking exceptions
2025-03-13 15:04:09,293:INFO:Importing libraries
2025-03-13 15:04:09,293:INFO:Copying training dataset
2025-03-13 15:04:09,303:INFO:Defining folds
2025-03-13 15:04:09,303:INFO:Declaring metric variables
2025-03-13 15:04:09,306:INFO:Importing untrained model
2025-03-13 15:04:09,307:INFO:Linear Regression Imported successfully
2025-03-13 15:04:09,312:INFO:Starting cross validation
2025-03-13 15:04:09,316:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:12,611:INFO:Calculating mean and std
2025-03-13 15:04:12,612:INFO:Creating metrics dataframe
2025-03-13 15:04:12,614:INFO:Uploading results into container
2025-03-13 15:04:12,614:INFO:Uploading model into container now
2025-03-13 15:04:12,614:INFO:_master_model_container: 1
2025-03-13 15:04:12,615:INFO:_display_container: 2
2025-03-13 15:04:12,615:INFO:LinearRegression(n_jobs=-1)
2025-03-13 15:04:12,615:INFO:create_model() successfully completed......................................
2025-03-13 15:04:12,682:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:12,682:INFO:Creating metrics dataframe
2025-03-13 15:04:12,685:INFO:Initializing Lasso Regression
2025-03-13 15:04:12,685:INFO:Total runtime is 0.056578723589579265 minutes
2025-03-13 15:04:12,688:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:12,688:INFO:Initializing create_model()
2025-03-13 15:04:12,688:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=lasso, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:12,688:INFO:Checking exceptions
2025-03-13 15:04:12,688:INFO:Importing libraries
2025-03-13 15:04:12,688:INFO:Copying training dataset
2025-03-13 15:04:12,693:INFO:Defining folds
2025-03-13 15:04:12,693:INFO:Declaring metric variables
2025-03-13 15:04:12,696:INFO:Importing untrained model
2025-03-13 15:04:12,698:INFO:Lasso Regression Imported successfully
2025-03-13 15:04:12,704:INFO:Starting cross validation
2025-03-13 15:04:12,704:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:12,939:INFO:Calculating mean and std
2025-03-13 15:04:12,940:INFO:Creating metrics dataframe
2025-03-13 15:04:12,941:INFO:Uploading results into container
2025-03-13 15:04:12,941:INFO:Uploading model into container now
2025-03-13 15:04:12,942:INFO:_master_model_container: 2
2025-03-13 15:04:12,942:INFO:_display_container: 2
2025-03-13 15:04:12,943:INFO:Lasso(random_state=123)
2025-03-13 15:04:12,943:INFO:create_model() successfully completed......................................
2025-03-13 15:04:12,997:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:12,997:INFO:Creating metrics dataframe
2025-03-13 15:04:13,002:INFO:Initializing Ridge Regression
2025-03-13 15:04:13,002:INFO:Total runtime is 0.061868520577748616 minutes
2025-03-13 15:04:13,004:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:13,004:INFO:Initializing create_model()
2025-03-13 15:04:13,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=ridge, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:13,004:INFO:Checking exceptions
2025-03-13 15:04:13,004:INFO:Importing libraries
2025-03-13 15:04:13,004:INFO:Copying training dataset
2025-03-13 15:04:13,010:INFO:Defining folds
2025-03-13 15:04:13,010:INFO:Declaring metric variables
2025-03-13 15:04:13,012:INFO:Importing untrained model
2025-03-13 15:04:13,014:INFO:Ridge Regression Imported successfully
2025-03-13 15:04:13,017:INFO:Starting cross validation
2025-03-13 15:04:13,018:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:13,258:INFO:Calculating mean and std
2025-03-13 15:04:13,258:INFO:Creating metrics dataframe
2025-03-13 15:04:13,259:INFO:Uploading results into container
2025-03-13 15:04:13,261:INFO:Uploading model into container now
2025-03-13 15:04:13,261:INFO:_master_model_container: 3
2025-03-13 15:04:13,261:INFO:_display_container: 2
2025-03-13 15:04:13,261:INFO:Ridge(random_state=123)
2025-03-13 15:04:13,261:INFO:create_model() successfully completed......................................
2025-03-13 15:04:13,320:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:13,320:INFO:Creating metrics dataframe
2025-03-13 15:04:13,324:INFO:Initializing Elastic Net
2025-03-13 15:04:13,324:INFO:Total runtime is 0.06723531484603881 minutes
2025-03-13 15:04:13,327:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:13,327:INFO:Initializing create_model()
2025-03-13 15:04:13,327:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=en, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:13,327:INFO:Checking exceptions
2025-03-13 15:04:13,327:INFO:Importing libraries
2025-03-13 15:04:13,327:INFO:Copying training dataset
2025-03-13 15:04:13,332:INFO:Defining folds
2025-03-13 15:04:13,332:INFO:Declaring metric variables
2025-03-13 15:04:13,334:INFO:Importing untrained model
2025-03-13 15:04:13,337:INFO:Elastic Net Imported successfully
2025-03-13 15:04:13,340:INFO:Starting cross validation
2025-03-13 15:04:13,341:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:13,614:INFO:Calculating mean and std
2025-03-13 15:04:13,615:INFO:Creating metrics dataframe
2025-03-13 15:04:13,617:INFO:Uploading results into container
2025-03-13 15:04:13,617:INFO:Uploading model into container now
2025-03-13 15:04:13,617:INFO:_master_model_container: 4
2025-03-13 15:04:13,617:INFO:_display_container: 2
2025-03-13 15:04:13,618:INFO:ElasticNet(random_state=123)
2025-03-13 15:04:13,618:INFO:create_model() successfully completed......................................
2025-03-13 15:04:13,678:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:13,678:INFO:Creating metrics dataframe
2025-03-13 15:04:13,683:INFO:Initializing Least Angle Regression
2025-03-13 15:04:13,683:INFO:Total runtime is 0.0732229193051656 minutes
2025-03-13 15:04:13,685:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:13,686:INFO:Initializing create_model()
2025-03-13 15:04:13,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=lar, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:13,686:INFO:Checking exceptions
2025-03-13 15:04:13,686:INFO:Importing libraries
2025-03-13 15:04:13,686:INFO:Copying training dataset
2025-03-13 15:04:13,692:INFO:Defining folds
2025-03-13 15:04:13,692:INFO:Declaring metric variables
2025-03-13 15:04:13,695:INFO:Importing untrained model
2025-03-13 15:04:13,696:INFO:Least Angle Regression Imported successfully
2025-03-13 15:04:13,701:INFO:Starting cross validation
2025-03-13 15:04:13,702:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:13,885:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=5.205e-02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,886:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.643e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,886:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.115e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,886:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=9.713e-03, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,887:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.226e-03, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,887:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.067e-03, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,887:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=9.775e-02, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,887:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.326e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,887:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.694e-03, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,889:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.024e-02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,889:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.031e-03, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,889:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.457e-02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,889:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.028e-02, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,891:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=3.725e+02, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,895:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=9.716e+07, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,901:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.966e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,904:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.732e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,904:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.917e-02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,904:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.310e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,905:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=1.734e+09, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,905:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=3.847e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,907:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.260e-01, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,907:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.575e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,909:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.057e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,910:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.072e+03, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,910:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.081e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,910:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.961e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,912:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.508e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,914:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.133e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,916:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.738e+06, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,916:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.792e+06, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,916:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=5.030e+07, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,916:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=4.871e+07, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,922:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.058e-01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,924:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.204e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,924:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.201e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,925:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.706e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,926:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.483e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,931:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=2.088e+04, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,935:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.135e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,937:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.617e-01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,937:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=2.061e-01, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,939:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=8.103e+09, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:13,957:INFO:Calculating mean and std
2025-03-13 15:04:13,957:INFO:Creating metrics dataframe
2025-03-13 15:04:13,960:INFO:Uploading results into container
2025-03-13 15:04:13,960:INFO:Uploading model into container now
2025-03-13 15:04:13,961:INFO:_master_model_container: 5
2025-03-13 15:04:13,961:INFO:_display_container: 2
2025-03-13 15:04:13,961:INFO:Lars(random_state=123)
2025-03-13 15:04:13,961:INFO:create_model() successfully completed......................................
2025-03-13 15:04:14,027:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:14,027:INFO:Creating metrics dataframe
2025-03-13 15:04:14,036:INFO:Initializing Lasso Least Angle Regression
2025-03-13 15:04:14,036:INFO:Total runtime is 0.0790929635365804 minutes
2025-03-13 15:04:14,039:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:14,039:INFO:Initializing create_model()
2025-03-13 15:04:14,039:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=llar, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:14,039:INFO:Checking exceptions
2025-03-13 15:04:14,039:INFO:Importing libraries
2025-03-13 15:04:14,039:INFO:Copying training dataset
2025-03-13 15:04:14,046:INFO:Defining folds
2025-03-13 15:04:14,046:INFO:Declaring metric variables
2025-03-13 15:04:14,047:INFO:Importing untrained model
2025-03-13 15:04:14,049:INFO:Lasso Least Angle Regression Imported successfully
2025-03-13 15:04:14,054:INFO:Starting cross validation
2025-03-13 15:04:14,054:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:14,305:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.966e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:14,308:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.653e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:14,333:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=1.617e+00, previous alpha=1.572e+00, with an active set of 23 regressors.
  warnings.warn(

2025-03-13 15:04:14,346:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.506e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:14,348:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.317e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-13 15:04:14,365:INFO:Calculating mean and std
2025-03-13 15:04:14,365:INFO:Creating metrics dataframe
2025-03-13 15:04:14,368:INFO:Uploading results into container
2025-03-13 15:04:14,368:INFO:Uploading model into container now
2025-03-13 15:04:14,368:INFO:_master_model_container: 6
2025-03-13 15:04:14,368:INFO:_display_container: 2
2025-03-13 15:04:14,370:INFO:LassoLars(random_state=123)
2025-03-13 15:04:14,370:INFO:create_model() successfully completed......................................
2025-03-13 15:04:14,439:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:14,439:INFO:Creating metrics dataframe
2025-03-13 15:04:14,444:INFO:Initializing Orthogonal Matching Pursuit
2025-03-13 15:04:14,444:INFO:Total runtime is 0.08590404192606607 minutes
2025-03-13 15:04:14,447:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:14,447:INFO:Initializing create_model()
2025-03-13 15:04:14,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=omp, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:14,447:INFO:Checking exceptions
2025-03-13 15:04:14,449:INFO:Importing libraries
2025-03-13 15:04:14,449:INFO:Copying training dataset
2025-03-13 15:04:14,454:INFO:Defining folds
2025-03-13 15:04:14,454:INFO:Declaring metric variables
2025-03-13 15:04:14,457:INFO:Importing untrained model
2025-03-13 15:04:14,460:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-13 15:04:14,464:INFO:Starting cross validation
2025-03-13 15:04:14,466:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:14,769:INFO:Calculating mean and std
2025-03-13 15:04:14,769:INFO:Creating metrics dataframe
2025-03-13 15:04:14,771:INFO:Uploading results into container
2025-03-13 15:04:14,772:INFO:Uploading model into container now
2025-03-13 15:04:14,772:INFO:_master_model_container: 7
2025-03-13 15:04:14,772:INFO:_display_container: 2
2025-03-13 15:04:14,772:INFO:OrthogonalMatchingPursuit()
2025-03-13 15:04:14,772:INFO:create_model() successfully completed......................................
2025-03-13 15:04:14,836:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:14,836:INFO:Creating metrics dataframe
2025-03-13 15:04:14,842:INFO:Initializing Bayesian Ridge
2025-03-13 15:04:14,842:INFO:Total runtime is 0.09254132509231566 minutes
2025-03-13 15:04:14,844:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:14,844:INFO:Initializing create_model()
2025-03-13 15:04:14,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=br, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:14,845:INFO:Checking exceptions
2025-03-13 15:04:14,845:INFO:Importing libraries
2025-03-13 15:04:14,845:INFO:Copying training dataset
2025-03-13 15:04:14,853:INFO:Defining folds
2025-03-13 15:04:14,853:INFO:Declaring metric variables
2025-03-13 15:04:14,855:INFO:Importing untrained model
2025-03-13 15:04:14,856:INFO:Bayesian Ridge Imported successfully
2025-03-13 15:04:14,861:INFO:Starting cross validation
2025-03-13 15:04:14,862:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:15,106:INFO:Calculating mean and std
2025-03-13 15:04:15,106:INFO:Creating metrics dataframe
2025-03-13 15:04:15,108:INFO:Uploading results into container
2025-03-13 15:04:15,108:INFO:Uploading model into container now
2025-03-13 15:04:15,108:INFO:_master_model_container: 8
2025-03-13 15:04:15,108:INFO:_display_container: 2
2025-03-13 15:04:15,110:INFO:BayesianRidge()
2025-03-13 15:04:15,110:INFO:create_model() successfully completed......................................
2025-03-13 15:04:15,171:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:15,171:INFO:Creating metrics dataframe
2025-03-13 15:04:15,175:INFO:Initializing Passive Aggressive Regressor
2025-03-13 15:04:15,176:INFO:Total runtime is 0.09810669819513955 minutes
2025-03-13 15:04:15,178:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:15,178:INFO:Initializing create_model()
2025-03-13 15:04:15,179:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=par, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:15,179:INFO:Checking exceptions
2025-03-13 15:04:15,179:INFO:Importing libraries
2025-03-13 15:04:15,179:INFO:Copying training dataset
2025-03-13 15:04:15,197:INFO:Defining folds
2025-03-13 15:04:15,199:INFO:Declaring metric variables
2025-03-13 15:04:15,202:INFO:Importing untrained model
2025-03-13 15:04:15,207:INFO:Passive Aggressive Regressor Imported successfully
2025-03-13 15:04:15,216:INFO:Starting cross validation
2025-03-13 15:04:15,217:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:15,511:INFO:Calculating mean and std
2025-03-13 15:04:15,512:INFO:Creating metrics dataframe
2025-03-13 15:04:15,513:INFO:Uploading results into container
2025-03-13 15:04:15,513:INFO:Uploading model into container now
2025-03-13 15:04:15,513:INFO:_master_model_container: 9
2025-03-13 15:04:15,513:INFO:_display_container: 2
2025-03-13 15:04:15,515:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-13 15:04:15,515:INFO:create_model() successfully completed......................................
2025-03-13 15:04:15,574:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:15,574:INFO:Creating metrics dataframe
2025-03-13 15:04:15,580:INFO:Initializing Huber Regressor
2025-03-13 15:04:15,580:INFO:Total runtime is 0.10483511686325071 minutes
2025-03-13 15:04:15,582:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:15,582:INFO:Initializing create_model()
2025-03-13 15:04:15,582:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=huber, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:15,582:INFO:Checking exceptions
2025-03-13 15:04:15,582:INFO:Importing libraries
2025-03-13 15:04:15,582:INFO:Copying training dataset
2025-03-13 15:04:15,588:INFO:Defining folds
2025-03-13 15:04:15,588:INFO:Declaring metric variables
2025-03-13 15:04:15,590:INFO:Importing untrained model
2025-03-13 15:04:15,593:INFO:Huber Regressor Imported successfully
2025-03-13 15:04:15,596:INFO:Starting cross validation
2025-03-13 15:04:15,597:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:15,797:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 15:04:15,805:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 15:04:15,816:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 15:04:15,820:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 15:04:15,827:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 15:04:15,832:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 15:04:15,838:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 15:04:15,840:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 15:04:15,843:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 15:04:15,849:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 15:04:15,862:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 15:04:15,865:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 15:04:15,880:INFO:Calculating mean and std
2025-03-13 15:04:15,881:INFO:Creating metrics dataframe
2025-03-13 15:04:15,882:INFO:Uploading results into container
2025-03-13 15:04:15,883:INFO:Uploading model into container now
2025-03-13 15:04:15,883:INFO:_master_model_container: 10
2025-03-13 15:04:15,883:INFO:_display_container: 2
2025-03-13 15:04:15,883:INFO:HuberRegressor()
2025-03-13 15:04:15,883:INFO:create_model() successfully completed......................................
2025-03-13 15:04:15,944:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:15,946:INFO:Creating metrics dataframe
2025-03-13 15:04:15,952:INFO:Initializing K Neighbors Regressor
2025-03-13 15:04:15,952:INFO:Total runtime is 0.11102765401204426 minutes
2025-03-13 15:04:15,953:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:15,953:INFO:Initializing create_model()
2025-03-13 15:04:15,953:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=knn, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:15,954:INFO:Checking exceptions
2025-03-13 15:04:15,954:INFO:Importing libraries
2025-03-13 15:04:15,954:INFO:Copying training dataset
2025-03-13 15:04:15,960:INFO:Defining folds
2025-03-13 15:04:15,960:INFO:Declaring metric variables
2025-03-13 15:04:15,963:INFO:Importing untrained model
2025-03-13 15:04:15,966:INFO:K Neighbors Regressor Imported successfully
2025-03-13 15:04:15,970:INFO:Starting cross validation
2025-03-13 15:04:15,970:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:16,299:INFO:Calculating mean and std
2025-03-13 15:04:16,299:INFO:Creating metrics dataframe
2025-03-13 15:04:16,301:INFO:Uploading results into container
2025-03-13 15:04:16,302:INFO:Uploading model into container now
2025-03-13 15:04:16,302:INFO:_master_model_container: 11
2025-03-13 15:04:16,302:INFO:_display_container: 2
2025-03-13 15:04:16,303:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-13 15:04:16,303:INFO:create_model() successfully completed......................................
2025-03-13 15:04:16,356:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:16,358:INFO:Creating metrics dataframe
2025-03-13 15:04:16,362:INFO:Initializing Decision Tree Regressor
2025-03-13 15:04:16,362:INFO:Total runtime is 0.11786349614461261 minutes
2025-03-13 15:04:16,365:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:16,365:INFO:Initializing create_model()
2025-03-13 15:04:16,365:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=dt, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:16,365:INFO:Checking exceptions
2025-03-13 15:04:16,365:INFO:Importing libraries
2025-03-13 15:04:16,365:INFO:Copying training dataset
2025-03-13 15:04:16,372:INFO:Defining folds
2025-03-13 15:04:16,372:INFO:Declaring metric variables
2025-03-13 15:04:16,373:INFO:Importing untrained model
2025-03-13 15:04:16,377:INFO:Decision Tree Regressor Imported successfully
2025-03-13 15:04:16,381:INFO:Starting cross validation
2025-03-13 15:04:16,382:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:16,652:INFO:Calculating mean and std
2025-03-13 15:04:16,652:INFO:Creating metrics dataframe
2025-03-13 15:04:16,654:INFO:Uploading results into container
2025-03-13 15:04:16,654:INFO:Uploading model into container now
2025-03-13 15:04:16,654:INFO:_master_model_container: 12
2025-03-13 15:04:16,654:INFO:_display_container: 2
2025-03-13 15:04:16,655:INFO:DecisionTreeRegressor(random_state=123)
2025-03-13 15:04:16,655:INFO:create_model() successfully completed......................................
2025-03-13 15:04:16,712:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:16,712:INFO:Creating metrics dataframe
2025-03-13 15:04:16,718:INFO:Initializing Random Forest Regressor
2025-03-13 15:04:16,718:INFO:Total runtime is 0.1238059361775716 minutes
2025-03-13 15:04:16,721:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:16,721:INFO:Initializing create_model()
2025-03-13 15:04:16,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=rf, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:16,721:INFO:Checking exceptions
2025-03-13 15:04:16,721:INFO:Importing libraries
2025-03-13 15:04:16,721:INFO:Copying training dataset
2025-03-13 15:04:16,727:INFO:Defining folds
2025-03-13 15:04:16,727:INFO:Declaring metric variables
2025-03-13 15:04:16,730:INFO:Importing untrained model
2025-03-13 15:04:16,731:INFO:Random Forest Regressor Imported successfully
2025-03-13 15:04:16,736:INFO:Starting cross validation
2025-03-13 15:04:16,736:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:18,427:INFO:Calculating mean and std
2025-03-13 15:04:18,429:INFO:Creating metrics dataframe
2025-03-13 15:04:18,429:INFO:Uploading results into container
2025-03-13 15:04:18,430:INFO:Uploading model into container now
2025-03-13 15:04:18,430:INFO:_master_model_container: 13
2025-03-13 15:04:18,430:INFO:_display_container: 2
2025-03-13 15:04:18,431:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-13 15:04:18,431:INFO:create_model() successfully completed......................................
2025-03-13 15:04:18,495:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:18,495:INFO:Creating metrics dataframe
2025-03-13 15:04:18,503:INFO:Initializing Extra Trees Regressor
2025-03-13 15:04:18,503:INFO:Total runtime is 0.15354399681091307 minutes
2025-03-13 15:04:18,504:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:18,505:INFO:Initializing create_model()
2025-03-13 15:04:18,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=et, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:18,505:INFO:Checking exceptions
2025-03-13 15:04:18,505:INFO:Importing libraries
2025-03-13 15:04:18,505:INFO:Copying training dataset
2025-03-13 15:04:18,511:INFO:Defining folds
2025-03-13 15:04:18,512:INFO:Declaring metric variables
2025-03-13 15:04:18,514:INFO:Importing untrained model
2025-03-13 15:04:18,515:INFO:Extra Trees Regressor Imported successfully
2025-03-13 15:04:18,520:INFO:Starting cross validation
2025-03-13 15:04:18,521:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:19,494:INFO:Calculating mean and std
2025-03-13 15:04:19,494:INFO:Creating metrics dataframe
2025-03-13 15:04:19,495:INFO:Uploading results into container
2025-03-13 15:04:19,497:INFO:Uploading model into container now
2025-03-13 15:04:19,497:INFO:_master_model_container: 14
2025-03-13 15:04:19,497:INFO:_display_container: 2
2025-03-13 15:04:19,497:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-13 15:04:19,497:INFO:create_model() successfully completed......................................
2025-03-13 15:04:19,560:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:19,560:INFO:Creating metrics dataframe
2025-03-13 15:04:19,568:INFO:Initializing AdaBoost Regressor
2025-03-13 15:04:19,568:INFO:Total runtime is 0.17130014101664223 minutes
2025-03-13 15:04:19,571:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:19,571:INFO:Initializing create_model()
2025-03-13 15:04:19,571:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=ada, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:19,571:INFO:Checking exceptions
2025-03-13 15:04:19,571:INFO:Importing libraries
2025-03-13 15:04:19,571:INFO:Copying training dataset
2025-03-13 15:04:19,579:INFO:Defining folds
2025-03-13 15:04:19,579:INFO:Declaring metric variables
2025-03-13 15:04:19,582:INFO:Importing untrained model
2025-03-13 15:04:19,584:INFO:AdaBoost Regressor Imported successfully
2025-03-13 15:04:19,588:INFO:Starting cross validation
2025-03-13 15:04:19,588:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:20,078:INFO:Calculating mean and std
2025-03-13 15:04:20,078:INFO:Creating metrics dataframe
2025-03-13 15:04:20,080:INFO:Uploading results into container
2025-03-13 15:04:20,080:INFO:Uploading model into container now
2025-03-13 15:04:20,081:INFO:_master_model_container: 15
2025-03-13 15:04:20,081:INFO:_display_container: 2
2025-03-13 15:04:20,081:INFO:AdaBoostRegressor(random_state=123)
2025-03-13 15:04:20,081:INFO:create_model() successfully completed......................................
2025-03-13 15:04:20,140:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:20,141:INFO:Creating metrics dataframe
2025-03-13 15:04:20,146:INFO:Initializing Gradient Boosting Regressor
2025-03-13 15:04:20,146:INFO:Total runtime is 0.18094007968902587 minutes
2025-03-13 15:04:20,148:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:20,148:INFO:Initializing create_model()
2025-03-13 15:04:20,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=gbr, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:20,149:INFO:Checking exceptions
2025-03-13 15:04:20,149:INFO:Importing libraries
2025-03-13 15:04:20,149:INFO:Copying training dataset
2025-03-13 15:04:20,155:INFO:Defining folds
2025-03-13 15:04:20,155:INFO:Declaring metric variables
2025-03-13 15:04:20,157:INFO:Importing untrained model
2025-03-13 15:04:20,158:INFO:Gradient Boosting Regressor Imported successfully
2025-03-13 15:04:20,162:INFO:Starting cross validation
2025-03-13 15:04:20,164:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:21,160:INFO:Calculating mean and std
2025-03-13 15:04:21,161:INFO:Creating metrics dataframe
2025-03-13 15:04:21,162:INFO:Uploading results into container
2025-03-13 15:04:21,162:INFO:Uploading model into container now
2025-03-13 15:04:21,162:INFO:_master_model_container: 16
2025-03-13 15:04:21,164:INFO:_display_container: 2
2025-03-13 15:04:21,164:INFO:GradientBoostingRegressor(random_state=123)
2025-03-13 15:04:21,164:INFO:create_model() successfully completed......................................
2025-03-13 15:04:21,224:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:21,224:INFO:Creating metrics dataframe
2025-03-13 15:04:21,232:INFO:Initializing Light Gradient Boosting Machine
2025-03-13 15:04:21,232:INFO:Total runtime is 0.19902869860331215 minutes
2025-03-13 15:04:21,235:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:21,235:INFO:Initializing create_model()
2025-03-13 15:04:21,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=lightgbm, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:21,235:INFO:Checking exceptions
2025-03-13 15:04:21,235:INFO:Importing libraries
2025-03-13 15:04:21,235:INFO:Copying training dataset
2025-03-13 15:04:21,241:INFO:Defining folds
2025-03-13 15:04:21,241:INFO:Declaring metric variables
2025-03-13 15:04:21,242:INFO:Importing untrained model
2025-03-13 15:04:21,245:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-13 15:04:21,250:INFO:Starting cross validation
2025-03-13 15:04:21,251:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:22,206:INFO:Calculating mean and std
2025-03-13 15:04:22,206:INFO:Creating metrics dataframe
2025-03-13 15:04:22,209:INFO:Uploading results into container
2025-03-13 15:04:22,209:INFO:Uploading model into container now
2025-03-13 15:04:22,209:INFO:_master_model_container: 17
2025-03-13 15:04:22,209:INFO:_display_container: 2
2025-03-13 15:04:22,211:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-13 15:04:22,211:INFO:create_model() successfully completed......................................
2025-03-13 15:04:22,280:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:22,280:INFO:Creating metrics dataframe
2025-03-13 15:04:22,288:INFO:Initializing Dummy Regressor
2025-03-13 15:04:22,288:INFO:Total runtime is 0.2166392167409261 minutes
2025-03-13 15:04:22,292:INFO:SubProcess create_model() called ==================================
2025-03-13 15:04:22,292:INFO:Initializing create_model()
2025-03-13 15:04:22,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=dummy, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016D33663BD0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:22,292:INFO:Checking exceptions
2025-03-13 15:04:22,292:INFO:Importing libraries
2025-03-13 15:04:22,292:INFO:Copying training dataset
2025-03-13 15:04:22,312:INFO:Defining folds
2025-03-13 15:04:22,312:INFO:Declaring metric variables
2025-03-13 15:04:22,317:INFO:Importing untrained model
2025-03-13 15:04:22,322:INFO:Dummy Regressor Imported successfully
2025-03-13 15:04:22,328:INFO:Starting cross validation
2025-03-13 15:04:22,329:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:22,605:INFO:Calculating mean and std
2025-03-13 15:04:22,605:INFO:Creating metrics dataframe
2025-03-13 15:04:22,607:INFO:Uploading results into container
2025-03-13 15:04:22,607:INFO:Uploading model into container now
2025-03-13 15:04:22,608:INFO:_master_model_container: 18
2025-03-13 15:04:22,608:INFO:_display_container: 2
2025-03-13 15:04:22,608:INFO:DummyRegressor()
2025-03-13 15:04:22,608:INFO:create_model() successfully completed......................................
2025-03-13 15:04:22,682:INFO:SubProcess create_model() end ==================================
2025-03-13 15:04:22,682:INFO:Creating metrics dataframe
2025-03-13 15:04:22,692:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-03-13 15:04:22,697:INFO:Initializing create_model()
2025-03-13 15:04:22,697:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:22,697:INFO:Checking exceptions
2025-03-13 15:04:22,698:INFO:Importing libraries
2025-03-13 15:04:22,698:INFO:Copying training dataset
2025-03-13 15:04:22,704:INFO:Defining folds
2025-03-13 15:04:22,704:INFO:Declaring metric variables
2025-03-13 15:04:22,704:INFO:Importing untrained model
2025-03-13 15:04:22,704:INFO:Declaring custom model
2025-03-13 15:04:22,704:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-13 15:04:22,705:INFO:Cross validation set to False
2025-03-13 15:04:22,705:INFO:Fitting Model
2025-03-13 15:04:22,814:INFO:OrthogonalMatchingPursuit()
2025-03-13 15:04:22,814:INFO:create_model() successfully completed......................................
2025-03-13 15:04:22,882:INFO:Initializing create_model()
2025-03-13 15:04:22,882:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:22,882:INFO:Checking exceptions
2025-03-13 15:04:22,883:INFO:Importing libraries
2025-03-13 15:04:22,883:INFO:Copying training dataset
2025-03-13 15:04:22,889:INFO:Defining folds
2025-03-13 15:04:22,889:INFO:Declaring metric variables
2025-03-13 15:04:22,889:INFO:Importing untrained model
2025-03-13 15:04:22,889:INFO:Declaring custom model
2025-03-13 15:04:22,891:INFO:AdaBoost Regressor Imported successfully
2025-03-13 15:04:22,892:INFO:Cross validation set to False
2025-03-13 15:04:22,892:INFO:Fitting Model
2025-03-13 15:04:23,137:INFO:AdaBoostRegressor(random_state=123)
2025-03-13 15:04:23,138:INFO:create_model() successfully completed......................................
2025-03-13 15:04:23,201:INFO:Initializing create_model()
2025-03-13 15:04:23,201:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:23,201:INFO:Checking exceptions
2025-03-13 15:04:23,202:INFO:Importing libraries
2025-03-13 15:04:23,202:INFO:Copying training dataset
2025-03-13 15:04:23,208:INFO:Defining folds
2025-03-13 15:04:23,208:INFO:Declaring metric variables
2025-03-13 15:04:23,208:INFO:Importing untrained model
2025-03-13 15:04:23,208:INFO:Declaring custom model
2025-03-13 15:04:23,208:INFO:Extra Trees Regressor Imported successfully
2025-03-13 15:04:23,208:INFO:Cross validation set to False
2025-03-13 15:04:23,208:INFO:Fitting Model
2025-03-13 15:04:23,375:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-13 15:04:23,375:INFO:create_model() successfully completed......................................
2025-03-13 15:04:23,438:INFO:Initializing create_model()
2025-03-13 15:04:23,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=BayesianRidge(), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:23,438:INFO:Checking exceptions
2025-03-13 15:04:23,439:INFO:Importing libraries
2025-03-13 15:04:23,439:INFO:Copying training dataset
2025-03-13 15:04:23,447:INFO:Defining folds
2025-03-13 15:04:23,447:INFO:Declaring metric variables
2025-03-13 15:04:23,447:INFO:Importing untrained model
2025-03-13 15:04:23,447:INFO:Declaring custom model
2025-03-13 15:04:23,447:INFO:Bayesian Ridge Imported successfully
2025-03-13 15:04:23,448:INFO:Cross validation set to False
2025-03-13 15:04:23,448:INFO:Fitting Model
2025-03-13 15:04:23,564:INFO:BayesianRidge()
2025-03-13 15:04:23,564:INFO:create_model() successfully completed......................................
2025-03-13 15:04:23,622:INFO:Initializing create_model()
2025-03-13 15:04:23,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=LassoLars(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:23,624:INFO:Checking exceptions
2025-03-13 15:04:23,624:INFO:Importing libraries
2025-03-13 15:04:23,626:INFO:Copying training dataset
2025-03-13 15:04:23,630:INFO:Defining folds
2025-03-13 15:04:23,631:INFO:Declaring metric variables
2025-03-13 15:04:23,631:INFO:Importing untrained model
2025-03-13 15:04:23,631:INFO:Declaring custom model
2025-03-13 15:04:23,631:INFO:Lasso Least Angle Regression Imported successfully
2025-03-13 15:04:23,632:INFO:Cross validation set to False
2025-03-13 15:04:23,632:INFO:Fitting Model
2025-03-13 15:04:23,729:INFO:LassoLars(random_state=123)
2025-03-13 15:04:23,729:INFO:create_model() successfully completed......................................
2025-03-13 15:04:23,787:INFO:Initializing create_model()
2025-03-13 15:04:23,787:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=Lasso(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:23,787:INFO:Checking exceptions
2025-03-13 15:04:23,789:INFO:Importing libraries
2025-03-13 15:04:23,789:INFO:Copying training dataset
2025-03-13 15:04:23,796:INFO:Defining folds
2025-03-13 15:04:23,796:INFO:Declaring metric variables
2025-03-13 15:04:23,796:INFO:Importing untrained model
2025-03-13 15:04:23,796:INFO:Declaring custom model
2025-03-13 15:04:23,796:INFO:Lasso Regression Imported successfully
2025-03-13 15:04:23,798:INFO:Cross validation set to False
2025-03-13 15:04:23,798:INFO:Fitting Model
2025-03-13 15:04:23,895:INFO:Lasso(random_state=123)
2025-03-13 15:04:23,895:INFO:create_model() successfully completed......................................
2025-03-13 15:04:23,953:INFO:Initializing create_model()
2025-03-13 15:04:23,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:23,954:INFO:Checking exceptions
2025-03-13 15:04:23,956:INFO:Importing libraries
2025-03-13 15:04:23,956:INFO:Copying training dataset
2025-03-13 15:04:23,960:INFO:Defining folds
2025-03-13 15:04:23,960:INFO:Declaring metric variables
2025-03-13 15:04:23,961:INFO:Importing untrained model
2025-03-13 15:04:23,961:INFO:Declaring custom model
2025-03-13 15:04:23,962:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-13 15:04:23,962:INFO:Cross validation set to False
2025-03-13 15:04:23,962:INFO:Fitting Model
2025-03-13 15:04:24,057:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000275 seconds.
2025-03-13 15:04:24,057:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-03-13 15:04:24,057:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-03-13 15:04:24,057:INFO:[LightGBM] [Info] Total Bins 5183
2025-03-13 15:04:24,057:INFO:[LightGBM] [Info] Number of data points in the train set: 332, number of used features: 59
2025-03-13 15:04:24,058:INFO:[LightGBM] [Info] Start training from score 20.304244
2025-03-13 15:04:24,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:24,104:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-13 15:04:24,104:INFO:create_model() successfully completed......................................
2025-03-13 15:04:24,182:INFO:Initializing create_model()
2025-03-13 15:04:24,182:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=HuberRegressor(), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:24,182:INFO:Checking exceptions
2025-03-13 15:04:24,184:INFO:Importing libraries
2025-03-13 15:04:24,184:INFO:Copying training dataset
2025-03-13 15:04:24,194:INFO:Defining folds
2025-03-13 15:04:24,194:INFO:Declaring metric variables
2025-03-13 15:04:24,194:INFO:Importing untrained model
2025-03-13 15:04:24,194:INFO:Declaring custom model
2025-03-13 15:04:24,194:INFO:Huber Regressor Imported successfully
2025-03-13 15:04:24,195:INFO:Cross validation set to False
2025-03-13 15:04:24,195:INFO:Fitting Model
2025-03-13 15:04:24,325:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-13 15:04:24,327:INFO:HuberRegressor()
2025-03-13 15:04:24,327:INFO:create_model() successfully completed......................................
2025-03-13 15:04:24,387:INFO:Initializing create_model()
2025-03-13 15:04:24,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:24,387:INFO:Checking exceptions
2025-03-13 15:04:24,389:INFO:Importing libraries
2025-03-13 15:04:24,389:INFO:Copying training dataset
2025-03-13 15:04:24,394:INFO:Defining folds
2025-03-13 15:04:24,394:INFO:Declaring metric variables
2025-03-13 15:04:24,394:INFO:Importing untrained model
2025-03-13 15:04:24,394:INFO:Declaring custom model
2025-03-13 15:04:24,394:INFO:Gradient Boosting Regressor Imported successfully
2025-03-13 15:04:24,396:INFO:Cross validation set to False
2025-03-13 15:04:24,396:INFO:Fitting Model
2025-03-13 15:04:24,993:INFO:GradientBoostingRegressor(random_state=123)
2025-03-13 15:04:24,993:INFO:create_model() successfully completed......................................
2025-03-13 15:04:25,054:INFO:Initializing create_model()
2025-03-13 15:04:25,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=ElasticNet(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:25,054:INFO:Checking exceptions
2025-03-13 15:04:25,055:INFO:Importing libraries
2025-03-13 15:04:25,055:INFO:Copying training dataset
2025-03-13 15:04:25,062:INFO:Defining folds
2025-03-13 15:04:25,062:INFO:Declaring metric variables
2025-03-13 15:04:25,062:INFO:Importing untrained model
2025-03-13 15:04:25,062:INFO:Declaring custom model
2025-03-13 15:04:25,063:INFO:Elastic Net Imported successfully
2025-03-13 15:04:25,063:INFO:Cross validation set to False
2025-03-13 15:04:25,063:INFO:Fitting Model
2025-03-13 15:04:25,162:INFO:ElasticNet(random_state=123)
2025-03-13 15:04:25,162:INFO:create_model() successfully completed......................................
2025-03-13 15:04:25,229:INFO:Initializing create_model()
2025-03-13 15:04:25,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:25,229:INFO:Checking exceptions
2025-03-13 15:04:25,230:INFO:Importing libraries
2025-03-13 15:04:25,230:INFO:Copying training dataset
2025-03-13 15:04:25,236:INFO:Defining folds
2025-03-13 15:04:25,236:INFO:Declaring metric variables
2025-03-13 15:04:25,236:INFO:Importing untrained model
2025-03-13 15:04:25,236:INFO:Declaring custom model
2025-03-13 15:04:25,236:INFO:Random Forest Regressor Imported successfully
2025-03-13 15:04:25,237:INFO:Cross validation set to False
2025-03-13 15:04:25,237:INFO:Fitting Model
2025-03-13 15:04:25,467:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-13 15:04:25,467:INFO:create_model() successfully completed......................................
2025-03-13 15:04:25,526:INFO:Initializing create_model()
2025-03-13 15:04:25,526:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=Ridge(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:25,527:INFO:Checking exceptions
2025-03-13 15:04:25,527:INFO:Importing libraries
2025-03-13 15:04:25,529:INFO:Copying training dataset
2025-03-13 15:04:25,536:INFO:Defining folds
2025-03-13 15:04:25,536:INFO:Declaring metric variables
2025-03-13 15:04:25,536:INFO:Importing untrained model
2025-03-13 15:04:25,536:INFO:Declaring custom model
2025-03-13 15:04:25,536:INFO:Ridge Regression Imported successfully
2025-03-13 15:04:25,537:INFO:Cross validation set to False
2025-03-13 15:04:25,537:INFO:Fitting Model
2025-03-13 15:04:25,646:INFO:Ridge(random_state=123)
2025-03-13 15:04:25,646:INFO:create_model() successfully completed......................................
2025-03-13 15:04:25,702:INFO:Initializing create_model()
2025-03-13 15:04:25,704:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:25,704:INFO:Checking exceptions
2025-03-13 15:04:25,705:INFO:Importing libraries
2025-03-13 15:04:25,705:INFO:Copying training dataset
2025-03-13 15:04:25,710:INFO:Defining folds
2025-03-13 15:04:25,710:INFO:Declaring metric variables
2025-03-13 15:04:25,711:INFO:Importing untrained model
2025-03-13 15:04:25,711:INFO:Declaring custom model
2025-03-13 15:04:25,711:INFO:Linear Regression Imported successfully
2025-03-13 15:04:25,712:INFO:Cross validation set to False
2025-03-13 15:04:25,712:INFO:Fitting Model
2025-03-13 15:04:25,805:INFO:LinearRegression(n_jobs=-1)
2025-03-13 15:04:25,805:INFO:create_model() successfully completed......................................
2025-03-13 15:04:25,866:INFO:Initializing create_model()
2025-03-13 15:04:25,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:25,866:INFO:Checking exceptions
2025-03-13 15:04:25,867:INFO:Importing libraries
2025-03-13 15:04:25,867:INFO:Copying training dataset
2025-03-13 15:04:25,872:INFO:Defining folds
2025-03-13 15:04:25,872:INFO:Declaring metric variables
2025-03-13 15:04:25,872:INFO:Importing untrained model
2025-03-13 15:04:25,872:INFO:Declaring custom model
2025-03-13 15:04:25,874:INFO:K Neighbors Regressor Imported successfully
2025-03-13 15:04:25,874:INFO:Cross validation set to False
2025-03-13 15:04:25,874:INFO:Fitting Model
2025-03-13 15:04:25,975:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-13 15:04:25,975:INFO:create_model() successfully completed......................................
2025-03-13 15:04:26,033:INFO:Initializing create_model()
2025-03-13 15:04:26,033:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=DummyRegressor(), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:26,033:INFO:Checking exceptions
2025-03-13 15:04:26,035:INFO:Importing libraries
2025-03-13 15:04:26,035:INFO:Copying training dataset
2025-03-13 15:04:26,040:INFO:Defining folds
2025-03-13 15:04:26,040:INFO:Declaring metric variables
2025-03-13 15:04:26,040:INFO:Importing untrained model
2025-03-13 15:04:26,040:INFO:Declaring custom model
2025-03-13 15:04:26,040:INFO:Dummy Regressor Imported successfully
2025-03-13 15:04:26,041:INFO:Cross validation set to False
2025-03-13 15:04:26,041:INFO:Fitting Model
2025-03-13 15:04:26,129:INFO:DummyRegressor()
2025-03-13 15:04:26,129:INFO:create_model() successfully completed......................................
2025-03-13 15:04:26,197:INFO:_master_model_container: 18
2025-03-13 15:04:26,197:INFO:_display_container: 2
2025-03-13 15:04:26,198:INFO:[OrthogonalMatchingPursuit(), AdaBoostRegressor(random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123), BayesianRidge(), LassoLars(random_state=123), Lasso(random_state=123), LGBMRegressor(n_jobs=-1, random_state=123), HuberRegressor(), GradientBoostingRegressor(random_state=123), ElasticNet(random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), Ridge(random_state=123), LinearRegression(n_jobs=-1), KNeighborsRegressor(n_jobs=-1), DummyRegressor()]
2025-03-13 15:04:26,198:INFO:compare_models() successfully completed......................................
2025-03-13 15:04:26,211:INFO:Initializing create_model()
2025-03-13 15:04:26,211:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:26,211:INFO:Checking exceptions
2025-03-13 15:04:26,221:INFO:Importing libraries
2025-03-13 15:04:26,222:INFO:Copying training dataset
2025-03-13 15:04:26,228:INFO:Defining folds
2025-03-13 15:04:26,228:INFO:Declaring metric variables
2025-03-13 15:04:26,231:INFO:Importing untrained model
2025-03-13 15:04:26,234:INFO:Random Forest Regressor Imported successfully
2025-03-13 15:04:26,239:INFO:Starting cross validation
2025-03-13 15:04:26,239:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:27,836:INFO:Calculating mean and std
2025-03-13 15:04:27,836:INFO:Creating metrics dataframe
2025-03-13 15:04:27,839:INFO:Finalizing model
2025-03-13 15:04:28,085:INFO:Uploading results into container
2025-03-13 15:04:28,086:INFO:Uploading model into container now
2025-03-13 15:04:28,092:INFO:_master_model_container: 19
2025-03-13 15:04:28,092:INFO:_display_container: 3
2025-03-13 15:04:28,092:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-13 15:04:28,092:INFO:create_model() successfully completed......................................
2025-03-13 15:04:28,234:INFO:Initializing create_model()
2025-03-13 15:04:28,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:28,234:INFO:Checking exceptions
2025-03-13 15:04:28,244:INFO:Importing libraries
2025-03-13 15:04:28,244:INFO:Copying training dataset
2025-03-13 15:04:28,252:INFO:Defining folds
2025-03-13 15:04:28,252:INFO:Declaring metric variables
2025-03-13 15:04:28,255:INFO:Importing untrained model
2025-03-13 15:04:28,258:INFO:AdaBoost Regressor Imported successfully
2025-03-13 15:04:28,262:INFO:Starting cross validation
2025-03-13 15:04:28,262:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:28,726:INFO:Calculating mean and std
2025-03-13 15:04:28,726:INFO:Creating metrics dataframe
2025-03-13 15:04:28,729:INFO:Finalizing model
2025-03-13 15:04:28,968:INFO:Uploading results into container
2025-03-13 15:04:28,968:INFO:Uploading model into container now
2025-03-13 15:04:28,973:INFO:_master_model_container: 20
2025-03-13 15:04:28,973:INFO:_display_container: 4
2025-03-13 15:04:28,973:INFO:AdaBoostRegressor(random_state=123)
2025-03-13 15:04:28,973:INFO:create_model() successfully completed......................................
2025-03-13 15:04:29,028:INFO:Initializing create_model()
2025-03-13 15:04:29,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:29,030:INFO:Checking exceptions
2025-03-13 15:04:29,039:INFO:Importing libraries
2025-03-13 15:04:29,039:INFO:Copying training dataset
2025-03-13 15:04:29,045:INFO:Defining folds
2025-03-13 15:04:29,047:INFO:Declaring metric variables
2025-03-13 15:04:29,048:INFO:Importing untrained model
2025-03-13 15:04:29,051:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-13 15:04:29,056:INFO:Starting cross validation
2025-03-13 15:04:29,057:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:30,096:INFO:Calculating mean and std
2025-03-13 15:04:30,097:INFO:Creating metrics dataframe
2025-03-13 15:04:30,103:INFO:Finalizing model
2025-03-13 15:04:30,232:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000467 seconds.
2025-03-13 15:04:30,232:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-13 15:04:30,232:INFO:[LightGBM] [Info] Total Bins 5183
2025-03-13 15:04:30,232:INFO:[LightGBM] [Info] Number of data points in the train set: 332, number of used features: 59
2025-03-13 15:04:30,232:INFO:[LightGBM] [Info] Start training from score 20.304244
2025-03-13 15:04:30,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-13 15:04:30,267:INFO:Uploading results into container
2025-03-13 15:04:30,268:INFO:Uploading model into container now
2025-03-13 15:04:30,277:INFO:_master_model_container: 21
2025-03-13 15:04:30,277:INFO:_display_container: 5
2025-03-13 15:04:30,277:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-13 15:04:30,279:INFO:create_model() successfully completed......................................
2025-03-13 15:04:30,341:INFO:Initializing create_model()
2025-03-13 15:04:30,341:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=br, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:30,341:INFO:Checking exceptions
2025-03-13 15:04:30,351:INFO:Importing libraries
2025-03-13 15:04:30,351:INFO:Copying training dataset
2025-03-13 15:04:30,361:INFO:Defining folds
2025-03-13 15:04:30,362:INFO:Declaring metric variables
2025-03-13 15:04:30,364:INFO:Importing untrained model
2025-03-13 15:04:30,367:INFO:Bayesian Ridge Imported successfully
2025-03-13 15:04:30,370:INFO:Starting cross validation
2025-03-13 15:04:30,371:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:30,594:INFO:Calculating mean and std
2025-03-13 15:04:30,594:INFO:Creating metrics dataframe
2025-03-13 15:04:30,597:INFO:Finalizing model
2025-03-13 15:04:30,742:INFO:Uploading results into container
2025-03-13 15:04:30,744:INFO:Uploading model into container now
2025-03-13 15:04:30,749:INFO:_master_model_container: 22
2025-03-13 15:04:30,750:INFO:_display_container: 6
2025-03-13 15:04:30,750:INFO:BayesianRidge()
2025-03-13 15:04:30,750:INFO:create_model() successfully completed......................................
2025-03-13 15:04:30,806:INFO:Initializing create_model()
2025-03-13 15:04:30,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-13 15:04:30,806:INFO:Checking exceptions
2025-03-13 15:04:30,815:INFO:Importing libraries
2025-03-13 15:04:30,815:INFO:Copying training dataset
2025-03-13 15:04:30,823:INFO:Defining folds
2025-03-13 15:04:30,823:INFO:Declaring metric variables
2025-03-13 15:04:30,827:INFO:Importing untrained model
2025-03-13 15:04:30,830:INFO:Extra Trees Regressor Imported successfully
2025-03-13 15:04:30,834:INFO:Starting cross validation
2025-03-13 15:04:30,835:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-13 15:04:31,704:INFO:Calculating mean and std
2025-03-13 15:04:31,704:INFO:Creating metrics dataframe
2025-03-13 15:04:31,708:INFO:Finalizing model
2025-03-13 15:04:31,894:INFO:Uploading results into container
2025-03-13 15:04:31,896:INFO:Uploading model into container now
2025-03-13 15:04:31,902:INFO:_master_model_container: 23
2025-03-13 15:04:31,902:INFO:_display_container: 7
2025-03-13 15:04:31,903:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-13 15:04:31,903:INFO:create_model() successfully completed......................................
2025-03-13 15:04:31,982:INFO:Initializing evaluate_model()
2025-03-13 15:04:31,982:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-13 15:04:32,005:INFO:Initializing plot_model()
2025-03-13 15:04:32,005:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=12, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-03-13 15:04:32,005:INFO:Checking exceptions
2025-03-13 15:04:32,008:INFO:Preloading libraries
2025-03-13 15:04:32,012:INFO:Copying training dataset
2025-03-13 15:04:32,012:INFO:Plot type: pipeline
2025-03-13 15:04:32,283:INFO:Visual Rendered Successfully
2025-03-13 15:04:32,339:INFO:plot_model() successfully completed......................................
2025-03-13 15:04:32,355:INFO:Initializing predict_model()
2025-03-13 15:04:32,355:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33859DA0>)
2025-03-13 15:04:32,355:INFO:Checking exceptions
2025-03-13 15:04:32,355:INFO:Preloading libraries
2025-03-13 15:04:32,357:INFO:Set up data.
2025-03-13 15:04:32,364:INFO:Set up index.
2025-03-13 15:04:32,965:INFO:Initializing predict_model()
2025-03-13 15:04:32,965:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D3369CD60>)
2025-03-13 15:04:32,965:INFO:Checking exceptions
2025-03-13 15:04:32,965:INFO:Preloading libraries
2025-03-13 15:04:32,968:INFO:Set up data.
2025-03-13 15:04:32,974:INFO:Set up index.
2025-03-13 15:04:33,100:INFO:Initializing predict_model()
2025-03-13 15:04:33,100:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D336000E0>)
2025-03-13 15:04:33,100:INFO:Checking exceptions
2025-03-13 15:04:33,100:INFO:Preloading libraries
2025-03-13 15:04:33,102:INFO:Set up data.
2025-03-13 15:04:33,108:INFO:Set up index.
2025-03-13 15:04:33,229:INFO:Initializing predict_model()
2025-03-13 15:04:33,229:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33600180>)
2025-03-13 15:04:33,229:INFO:Checking exceptions
2025-03-13 15:04:33,229:INFO:Preloading libraries
2025-03-13 15:04:33,229:INFO:Set up data.
2025-03-13 15:04:33,237:INFO:Set up index.
2025-03-13 15:04:33,367:INFO:Initializing predict_model()
2025-03-13 15:04:33,367:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D3369C9A0>)
2025-03-13 15:04:33,367:INFO:Checking exceptions
2025-03-13 15:04:33,367:INFO:Preloading libraries
2025-03-13 15:04:33,369:INFO:Set up data.
2025-03-13 15:04:33,375:INFO:Set up index.
2025-03-13 15:04:33,495:INFO:Initializing predict_model()
2025-03-13 15:04:33,495:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D336000E0>)
2025-03-13 15:04:33,495:INFO:Checking exceptions
2025-03-13 15:04:33,495:INFO:Preloading libraries
2025-03-13 15:04:33,497:INFO:Set up data.
2025-03-13 15:04:33,502:INFO:Set up index.
2025-03-13 15:04:33,625:INFO:Initializing predict_model()
2025-03-13 15:04:33,625:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33603CE0>)
2025-03-13 15:04:33,625:INFO:Checking exceptions
2025-03-13 15:04:33,625:INFO:Preloading libraries
2025-03-13 15:04:33,627:INFO:Set up data.
2025-03-13 15:04:33,632:INFO:Set up index.
2025-03-13 15:04:33,775:INFO:Initializing predict_model()
2025-03-13 15:04:33,775:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D3369CD60>)
2025-03-13 15:04:33,775:INFO:Checking exceptions
2025-03-13 15:04:33,775:INFO:Preloading libraries
2025-03-13 15:04:33,777:INFO:Set up data.
2025-03-13 15:04:33,787:INFO:Set up index.
2025-03-13 15:04:33,904:INFO:Initializing predict_model()
2025-03-13 15:04:33,904:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33600180>)
2025-03-13 15:04:33,904:INFO:Checking exceptions
2025-03-13 15:04:33,904:INFO:Preloading libraries
2025-03-13 15:04:33,906:INFO:Set up data.
2025-03-13 15:04:33,913:INFO:Set up index.
2025-03-13 15:04:34,042:INFO:Initializing predict_model()
2025-03-13 15:04:34,042:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D336000E0>)
2025-03-13 15:04:34,042:INFO:Checking exceptions
2025-03-13 15:04:34,042:INFO:Preloading libraries
2025-03-13 15:04:34,042:INFO:Set up data.
2025-03-13 15:04:34,048:INFO:Set up index.
2025-03-13 15:04:34,168:INFO:Initializing predict_model()
2025-03-13 15:04:34,168:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D3369C220>)
2025-03-13 15:04:34,168:INFO:Checking exceptions
2025-03-13 15:04:34,168:INFO:Preloading libraries
2025-03-13 15:04:34,170:INFO:Set up data.
2025-03-13 15:04:34,178:INFO:Set up index.
2025-03-13 15:04:34,300:INFO:Initializing predict_model()
2025-03-13 15:04:34,300:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D3349BF60>)
2025-03-13 15:04:34,300:INFO:Checking exceptions
2025-03-13 15:04:34,300:INFO:Preloading libraries
2025-03-13 15:04:34,302:INFO:Set up data.
2025-03-13 15:04:34,307:INFO:Set up index.
2025-03-13 15:04:34,454:INFO:Initializing predict_model()
2025-03-13 15:04:34,454:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D3369CC20>)
2025-03-13 15:04:34,454:INFO:Checking exceptions
2025-03-13 15:04:34,454:INFO:Preloading libraries
2025-03-13 15:04:34,455:INFO:Set up data.
2025-03-13 15:04:34,466:INFO:Set up index.
2025-03-13 15:04:34,588:INFO:Initializing predict_model()
2025-03-13 15:04:34,588:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D3369CAE0>)
2025-03-13 15:04:34,588:INFO:Checking exceptions
2025-03-13 15:04:34,588:INFO:Preloading libraries
2025-03-13 15:04:34,590:INFO:Set up data.
2025-03-13 15:04:34,595:INFO:Set up index.
2025-03-13 15:04:34,728:INFO:Initializing predict_model()
2025-03-13 15:04:34,728:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33859DA0>)
2025-03-13 15:04:34,728:INFO:Checking exceptions
2025-03-13 15:04:34,728:INFO:Preloading libraries
2025-03-13 15:04:34,731:INFO:Set up data.
2025-03-13 15:04:34,738:INFO:Set up index.
2025-03-13 15:04:34,863:INFO:Initializing predict_model()
2025-03-13 15:04:34,863:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D3349BD80>)
2025-03-13 15:04:34,863:INFO:Checking exceptions
2025-03-13 15:04:34,863:INFO:Preloading libraries
2025-03-13 15:04:34,864:INFO:Set up data.
2025-03-13 15:04:34,870:INFO:Set up index.
2025-03-13 15:04:34,979:INFO:Initializing predict_model()
2025-03-13 15:04:34,979:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D3349BBA0>)
2025-03-13 15:04:34,979:INFO:Checking exceptions
2025-03-13 15:04:34,979:INFO:Preloading libraries
2025-03-13 15:04:34,981:INFO:Set up data.
2025-03-13 15:04:34,987:INFO:Set up index.
2025-03-13 15:04:35,094:INFO:Initializing predict_model()
2025-03-13 15:04:35,094:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33600180>)
2025-03-13 15:04:35,094:INFO:Checking exceptions
2025-03-13 15:04:35,094:INFO:Preloading libraries
2025-03-13 15:04:35,095:INFO:Set up data.
2025-03-13 15:04:35,101:INFO:Set up index.
2025-03-13 15:04:35,215:INFO:Initializing predict_model()
2025-03-13 15:04:35,215:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33603CE0>)
2025-03-13 15:04:35,215:INFO:Checking exceptions
2025-03-13 15:04:35,215:INFO:Preloading libraries
2025-03-13 15:04:35,217:INFO:Set up data.
2025-03-13 15:04:35,222:INFO:Set up index.
2025-03-13 15:04:35,333:INFO:Initializing predict_model()
2025-03-13 15:04:35,333:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D3349BF60>)
2025-03-13 15:04:35,333:INFO:Checking exceptions
2025-03-13 15:04:35,333:INFO:Preloading libraries
2025-03-13 15:04:35,334:INFO:Set up data.
2025-03-13 15:04:35,341:INFO:Set up index.
2025-03-13 15:04:35,445:INFO:Initializing predict_model()
2025-03-13 15:04:35,445:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33858720>)
2025-03-13 15:04:35,445:INFO:Checking exceptions
2025-03-13 15:04:35,445:INFO:Preloading libraries
2025-03-13 15:04:35,447:INFO:Set up data.
2025-03-13 15:04:35,454:INFO:Set up index.
2025-03-13 15:04:35,565:INFO:Initializing predict_model()
2025-03-13 15:04:35,565:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D336000E0>)
2025-03-13 15:04:35,565:INFO:Checking exceptions
2025-03-13 15:04:35,565:INFO:Preloading libraries
2025-03-13 15:04:35,566:INFO:Set up data.
2025-03-13 15:04:35,572:INFO:Set up index.
2025-03-13 15:04:35,681:INFO:Initializing predict_model()
2025-03-13 15:04:35,681:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33603CE0>)
2025-03-13 15:04:35,681:INFO:Checking exceptions
2025-03-13 15:04:35,681:INFO:Preloading libraries
2025-03-13 15:04:35,682:INFO:Set up data.
2025-03-13 15:04:35,688:INFO:Set up index.
2025-03-13 15:04:35,799:INFO:Initializing predict_model()
2025-03-13 15:04:35,799:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33859F80>)
2025-03-13 15:04:35,799:INFO:Checking exceptions
2025-03-13 15:04:35,799:INFO:Preloading libraries
2025-03-13 15:04:35,801:INFO:Set up data.
2025-03-13 15:04:35,807:INFO:Set up index.
2025-03-13 15:04:35,936:INFO:Initializing predict_model()
2025-03-13 15:04:35,936:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33603CE0>)
2025-03-13 15:04:35,936:INFO:Checking exceptions
2025-03-13 15:04:35,936:INFO:Preloading libraries
2025-03-13 15:04:35,938:INFO:Set up data.
2025-03-13 15:04:35,944:INFO:Set up index.
2025-03-13 15:04:36,052:INFO:Initializing predict_model()
2025-03-13 15:04:36,054:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33600180>)
2025-03-13 15:04:36,054:INFO:Checking exceptions
2025-03-13 15:04:36,054:INFO:Preloading libraries
2025-03-13 15:04:36,055:INFO:Set up data.
2025-03-13 15:04:36,062:INFO:Set up index.
2025-03-13 15:04:36,177:INFO:Initializing predict_model()
2025-03-13 15:04:36,177:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33858A40>)
2025-03-13 15:04:36,177:INFO:Checking exceptions
2025-03-13 15:04:36,177:INFO:Preloading libraries
2025-03-13 15:04:36,178:INFO:Set up data.
2025-03-13 15:04:36,184:INFO:Set up index.
2025-03-13 15:04:36,297:INFO:Initializing predict_model()
2025-03-13 15:04:36,297:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D3349BEC0>)
2025-03-13 15:04:36,297:INFO:Checking exceptions
2025-03-13 15:04:36,297:INFO:Preloading libraries
2025-03-13 15:04:36,298:INFO:Set up data.
2025-03-13 15:04:36,304:INFO:Set up index.
2025-03-13 15:04:36,417:INFO:Initializing predict_model()
2025-03-13 15:04:36,417:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D33600180>)
2025-03-13 15:04:36,417:INFO:Checking exceptions
2025-03-13 15:04:36,417:INFO:Preloading libraries
2025-03-13 15:04:36,418:INFO:Set up data.
2025-03-13 15:04:36,427:INFO:Set up index.
2025-03-13 15:04:36,543:INFO:Initializing predict_model()
2025-03-13 15:04:36,543:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D336000E0>)
2025-03-13 15:04:36,543:INFO:Checking exceptions
2025-03-13 15:04:36,543:INFO:Preloading libraries
2025-03-13 15:04:36,544:INFO:Set up data.
2025-03-13 15:04:36,551:INFO:Set up index.
2025-03-13 15:04:36,668:INFO:Initializing predict_model()
2025-03-13 15:04:36,668:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016D3349BF60>)
2025-03-13 15:04:36,668:INFO:Checking exceptions
2025-03-13 15:04:36,668:INFO:Preloading libraries
2025-03-13 15:04:36,670:INFO:Set up data.
2025-03-13 15:04:36,676:INFO:Set up index.
2025-03-13 15:04:36,787:INFO:Initializing plot_model()
2025-03-13 15:04:36,787:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), plot=learning, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-03-13 15:04:36,787:INFO:Checking exceptions
2025-03-13 15:04:36,809:INFO:Preloading libraries
2025-03-13 15:04:36,817:INFO:Copying training dataset
2025-03-13 15:04:36,817:INFO:Plot type: learning
2025-03-13 15:04:36,947:INFO:Fitting Model
2025-03-13 15:04:45,616:INFO:Visual Rendered Successfully
2025-03-13 15:04:45,672:INFO:plot_model() successfully completed......................................
2025-03-13 15:15:11,364:INFO:Initializing plot_model()
2025-03-13 15:15:11,364:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000016D16C51C50>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), plot=learning, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-03-13 15:15:11,364:INFO:Checking exceptions
2025-03-13 15:15:11,385:INFO:Preloading libraries
2025-03-13 15:15:11,392:INFO:Copying training dataset
2025-03-13 15:15:11,392:INFO:Plot type: learning
2025-03-13 15:15:11,485:INFO:Fitting Model
2025-03-13 15:15:22,547:INFO:Visual Rendered Successfully
2025-03-13 15:15:22,642:INFO:plot_model() successfully completed......................................
2025-03-13 16:42:39,680:INFO:Initializing save_model()
2025-03-13 16:42:39,680:INFO:save_model(model=RandomForestRegressor(n_jobs=-1, random_state=123), model_name=pm2_5_model_1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Saeb0m\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['humidity', 'temperature', 'year',
                                             'month', 'day', 'day_of_week',
                                             'week_of_year', 'season',
                                             'dew_point', 'is_weekend',
                                             'tem...
                                             'pm_2_5_lag_4', 'pm_2_5_lag_5',
                                             'pm_2_5_lag_6', 'pm_2_5_lag_7',
                                             'pm_2_5_lag_8', 'pm_2_5_lag_9',
                                             'pm_2_5_lag_10', 'pm_2_5_lag_11',
                                             'pm_2_5_lag_12', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-13 16:42:39,680:INFO:Adding model into prep_pipe
2025-03-13 16:42:39,703:INFO:pm2_5_model_1.pkl saved in current working directory
2025-03-13 16:42:39,707:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['humidity', 'temperature', 'year',
                                             'month', 'day', 'day_of_week',
                                             'week_of_year', 'season',
                                             'dew_point', 'is_weekend',
                                             'temp_humidity_ratio',
                                             'heat_index', 'rh_index'...
                                             'pm_2_5_lag_8', 'pm_2_5_lag_9',
                                             'pm_2_5_lag_10', 'pm_2_5_lag_11',
                                             'pm_2_5_lag_12', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('trained_model',
                 RandomForestRegressor(n_jobs=-1, random_state=123))])
2025-03-13 16:42:39,707:INFO:save_model() successfully completed......................................
2025-03-15 10:07:01,805:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 10:07:01,805:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 10:07:01,805:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 10:07:01,805:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 10:07:01,978:INFO:PyCaret RegressionExperiment
2025-03-15 10:07:01,978:INFO:Logging name: reg-default-name
2025-03-15 10:07:01,978:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-15 10:07:01,978:INFO:version 3.3.2
2025-03-15 10:07:01,979:INFO:Initializing setup()
2025-03-15 10:07:01,979:INFO:self.USI: c79f
2025-03-15 10:07:01,979:INFO:self._variable_keys: {'log_plots_param', 'fold_groups_param', 'n_jobs_param', 'seed', 'y', 'y_train', 'y_test', 'html_param', 'exp_name_log', 'idx', 'X', 'exp_id', '_ml_usecase', 'target_param', 'X_test', '_available_plots', 'memory', 'fold_generator', 'X_train', 'gpu_n_jobs_param', 'fold_shuffle_param', 'data', 'pipeline', 'USI', 'transform_target_param', 'logging_param', 'gpu_param'}
2025-03-15 10:07:01,979:INFO:Checking environment
2025-03-15 10:07:01,979:INFO:python_version: 3.11.9
2025-03-15 10:07:01,979:INFO:python_build: ('tags/v3.11.9:de54cf5', 'Apr  2 2024 10:12:12')
2025-03-15 10:07:01,979:INFO:machine: AMD64
2025-03-15 10:07:01,979:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-15 10:07:01,982:INFO:Memory: svmem(total=34193833984, available=21098270720, percent=38.3, used=13095563264, free=21098270720)
2025-03-15 10:07:01,982:INFO:Physical Core: 6
2025-03-15 10:07:01,982:INFO:Logical Core: 12
2025-03-15 10:07:01,982:INFO:Checking libraries
2025-03-15 10:07:01,982:INFO:System:
2025-03-15 10:07:01,982:INFO:    python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]
2025-03-15 10:07:01,982:INFO:executable: d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Scripts\python.exe
2025-03-15 10:07:01,982:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-15 10:07:01,982:INFO:PyCaret required dependencies:
2025-03-15 10:07:02,032:INFO:                 pip: 24.0
2025-03-15 10:07:02,033:INFO:          setuptools: 65.5.0
2025-03-15 10:07:02,033:INFO:             pycaret: 3.3.2
2025-03-15 10:07:02,033:INFO:             IPython: 8.32.0
2025-03-15 10:07:02,033:INFO:          ipywidgets: 8.1.5
2025-03-15 10:07:02,033:INFO:                tqdm: 4.67.1
2025-03-15 10:07:02,033:INFO:               numpy: 1.26.4
2025-03-15 10:07:02,033:INFO:              pandas: 2.1.4
2025-03-15 10:07:02,033:INFO:              jinja2: 3.1.5
2025-03-15 10:07:02,033:INFO:               scipy: 1.11.4
2025-03-15 10:07:02,033:INFO:              joblib: 1.3.2
2025-03-15 10:07:02,033:INFO:             sklearn: 1.4.2
2025-03-15 10:07:02,033:INFO:                pyod: 2.0.3
2025-03-15 10:07:02,033:INFO:            imblearn: 0.13.0
2025-03-15 10:07:02,033:INFO:   category_encoders: 2.7.0
2025-03-15 10:07:02,033:INFO:            lightgbm: 4.6.0
2025-03-15 10:07:02,033:INFO:               numba: 0.61.0
2025-03-15 10:07:02,033:INFO:            requests: 2.32.3
2025-03-15 10:07:02,033:INFO:          matplotlib: 3.7.5
2025-03-15 10:07:02,033:INFO:          scikitplot: 0.3.7
2025-03-15 10:07:02,033:INFO:         yellowbrick: 1.5
2025-03-15 10:07:02,033:INFO:              plotly: 5.24.1
2025-03-15 10:07:02,033:INFO:    plotly-resampler: Not installed
2025-03-15 10:07:02,033:INFO:             kaleido: 0.2.1
2025-03-15 10:07:02,033:INFO:           schemdraw: 0.15
2025-03-15 10:07:02,033:INFO:         statsmodels: 0.14.4
2025-03-15 10:07:02,033:INFO:              sktime: 0.26.0
2025-03-15 10:07:02,033:INFO:               tbats: 1.1.3
2025-03-15 10:07:02,033:INFO:            pmdarima: 2.0.4
2025-03-15 10:07:02,033:INFO:              psutil: 7.0.0
2025-03-15 10:07:02,033:INFO:          markupsafe: 3.0.2
2025-03-15 10:07:02,033:INFO:             pickle5: Not installed
2025-03-15 10:07:02,033:INFO:         cloudpickle: 3.1.1
2025-03-15 10:07:02,033:INFO:         deprecation: 2.1.0
2025-03-15 10:07:02,033:INFO:              xxhash: 3.5.0
2025-03-15 10:07:02,033:INFO:           wurlitzer: Not installed
2025-03-15 10:07:02,033:INFO:PyCaret optional dependencies:
2025-03-15 10:07:02,040:INFO:                shap: Not installed
2025-03-15 10:07:02,042:INFO:           interpret: Not installed
2025-03-15 10:07:02,042:INFO:                umap: Not installed
2025-03-15 10:07:02,042:INFO:     ydata_profiling: Not installed
2025-03-15 10:07:02,042:INFO:  explainerdashboard: Not installed
2025-03-15 10:07:02,042:INFO:             autoviz: Not installed
2025-03-15 10:07:02,042:INFO:           fairlearn: Not installed
2025-03-15 10:07:02,042:INFO:          deepchecks: Not installed
2025-03-15 10:07:02,042:INFO:             xgboost: Not installed
2025-03-15 10:07:02,042:INFO:            catboost: Not installed
2025-03-15 10:07:02,042:INFO:              kmodes: Not installed
2025-03-15 10:07:02,042:INFO:             mlxtend: Not installed
2025-03-15 10:07:02,042:INFO:       statsforecast: Not installed
2025-03-15 10:07:02,042:INFO:        tune_sklearn: Not installed
2025-03-15 10:07:02,042:INFO:                 ray: Not installed
2025-03-15 10:07:02,042:INFO:            hyperopt: Not installed
2025-03-15 10:07:02,042:INFO:              optuna: Not installed
2025-03-15 10:07:02,042:INFO:               skopt: Not installed
2025-03-15 10:07:02,042:INFO:              mlflow: Not installed
2025-03-15 10:07:02,042:INFO:              gradio: Not installed
2025-03-15 10:07:02,042:INFO:             fastapi: Not installed
2025-03-15 10:07:02,042:INFO:             uvicorn: Not installed
2025-03-15 10:07:02,042:INFO:              m2cgen: Not installed
2025-03-15 10:07:02,042:INFO:           evidently: Not installed
2025-03-15 10:07:02,042:INFO:               fugue: Not installed
2025-03-15 10:07:02,042:INFO:           streamlit: Not installed
2025-03-15 10:07:02,042:INFO:             prophet: Not installed
2025-03-15 10:07:02,042:INFO:None
2025-03-15 10:07:02,042:INFO:Set up data.
2025-03-15 10:07:02,051:INFO:Set up folding strategy.
2025-03-15 10:07:02,051:INFO:Set up train/test split.
2025-03-15 10:07:02,057:INFO:Set up index.
2025-03-15 10:07:02,057:INFO:Assigning column types.
2025-03-15 10:07:02,063:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-15 10:07:02,063:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,064:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,068:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,107:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,134:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,135:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,137:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,140:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,186:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,213:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,213:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-15 10:07:02,216:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,219:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,300:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,305:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,306:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,342:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,368:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,370:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-15 10:07:02,374:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,412:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,440:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,446:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,486:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,516:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-15 10:07:02,560:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,599:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,599:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,689:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,727:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,728:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-15 10:07:02,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,801:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 10:07:02,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,873:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-15 10:07:02,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:02,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:03,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:03,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:03,071:INFO:Preparing preprocessing pipeline...
2025-03-15 10:07:03,071:INFO:Set up date feature engineering.
2025-03-15 10:07:03,071:INFO:Set up simple imputation.
2025-03-15 10:07:03,071:INFO:Set up removing outliers.
2025-03-15 10:07:03,118:INFO:Finished creating preprocessing pipeline.
2025-03-15 10:07:03,124:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Saeb0m\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['humidity', 'temperature', 'year',
                                             'month', 'day', 'day_of_week',
                                             'week_of_year', 'season',
                                             'dew_point', 'is_weekend',
                                             'tem...
                                             'pm_2_5_lag_4', 'pm_2_5_lag_5',
                                             'pm_2_5_lag_6', 'pm_2_5_lag_7',
                                             'pm_2_5_lag_8', 'pm_2_5_lag_9',
                                             'pm_2_5_lag_10', 'pm_2_5_lag_11',
                                             'pm_2_5_lag_12', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123)))])
2025-03-15 10:07:03,124:INFO:Creating final display dataframe.
2025-03-15 10:07:03,248:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            pm_2_5
2                   Target type        Regression
3           Original data shape         (500, 58)
4        Transformed data shape         (482, 60)
5   Transformed train set shape         (332, 60)
6    Transformed test set shape         (150, 60)
7              Numeric features                56
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13              Remove outliers              True
14           Outliers threshold              0.05
15               Fold Generator             KFold
16                  Fold Number                12
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              c79f
2025-03-15 10:07:03,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:03,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:03,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:03,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 10:07:03,411:INFO:setup() successfully completed in 1.48s...............
2025-03-15 10:07:03,420:INFO:Initializing compare_models()
2025-03-15 10:07:03,420:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=15, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 15, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-03-15 10:07:03,420:INFO:Checking exceptions
2025-03-15 10:07:03,423:INFO:Preparing display monitor
2025-03-15 10:07:03,442:INFO:Initializing Linear Regression
2025-03-15 10:07:03,443:INFO:Total runtime is 2.1767616271972656e-05 minutes
2025-03-15 10:07:03,446:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:03,446:INFO:Initializing create_model()
2025-03-15 10:07:03,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=lr, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:03,446:INFO:Checking exceptions
2025-03-15 10:07:03,446:INFO:Importing libraries
2025-03-15 10:07:03,446:INFO:Copying training dataset
2025-03-15 10:07:03,455:INFO:Defining folds
2025-03-15 10:07:03,455:INFO:Declaring metric variables
2025-03-15 10:07:03,456:INFO:Importing untrained model
2025-03-15 10:07:03,460:INFO:Linear Regression Imported successfully
2025-03-15 10:07:03,465:INFO:Starting cross validation
2025-03-15 10:07:03,469:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:07,043:INFO:Calculating mean and std
2025-03-15 10:07:07,045:INFO:Creating metrics dataframe
2025-03-15 10:07:07,045:INFO:Uploading results into container
2025-03-15 10:07:07,047:INFO:Uploading model into container now
2025-03-15 10:07:07,047:INFO:_master_model_container: 1
2025-03-15 10:07:07,047:INFO:_display_container: 2
2025-03-15 10:07:07,047:INFO:LinearRegression(n_jobs=-1)
2025-03-15 10:07:07,047:INFO:create_model() successfully completed......................................
2025-03-15 10:07:07,114:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:07,114:INFO:Creating metrics dataframe
2025-03-15 10:07:07,118:INFO:Initializing Lasso Regression
2025-03-15 10:07:07,119:INFO:Total runtime is 0.061287780602773026 minutes
2025-03-15 10:07:07,121:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:07,121:INFO:Initializing create_model()
2025-03-15 10:07:07,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=lasso, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:07,122:INFO:Checking exceptions
2025-03-15 10:07:07,122:INFO:Importing libraries
2025-03-15 10:07:07,122:INFO:Copying training dataset
2025-03-15 10:07:07,129:INFO:Defining folds
2025-03-15 10:07:07,129:INFO:Declaring metric variables
2025-03-15 10:07:07,130:INFO:Importing untrained model
2025-03-15 10:07:07,133:INFO:Lasso Regression Imported successfully
2025-03-15 10:07:07,137:INFO:Starting cross validation
2025-03-15 10:07:07,137:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:07,420:INFO:Calculating mean and std
2025-03-15 10:07:07,420:INFO:Creating metrics dataframe
2025-03-15 10:07:07,422:INFO:Uploading results into container
2025-03-15 10:07:07,422:INFO:Uploading model into container now
2025-03-15 10:07:07,423:INFO:_master_model_container: 2
2025-03-15 10:07:07,423:INFO:_display_container: 2
2025-03-15 10:07:07,423:INFO:Lasso(random_state=123)
2025-03-15 10:07:07,423:INFO:create_model() successfully completed......................................
2025-03-15 10:07:07,484:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:07,484:INFO:Creating metrics dataframe
2025-03-15 10:07:07,490:INFO:Initializing Ridge Regression
2025-03-15 10:07:07,490:INFO:Total runtime is 0.0674682060877482 minutes
2025-03-15 10:07:07,493:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:07,493:INFO:Initializing create_model()
2025-03-15 10:07:07,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=ridge, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:07,493:INFO:Checking exceptions
2025-03-15 10:07:07,493:INFO:Importing libraries
2025-03-15 10:07:07,493:INFO:Copying training dataset
2025-03-15 10:07:07,501:INFO:Defining folds
2025-03-15 10:07:07,501:INFO:Declaring metric variables
2025-03-15 10:07:07,502:INFO:Importing untrained model
2025-03-15 10:07:07,505:INFO:Ridge Regression Imported successfully
2025-03-15 10:07:07,511:INFO:Starting cross validation
2025-03-15 10:07:07,513:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:07,792:INFO:Calculating mean and std
2025-03-15 10:07:07,792:INFO:Creating metrics dataframe
2025-03-15 10:07:07,793:INFO:Uploading results into container
2025-03-15 10:07:07,795:INFO:Uploading model into container now
2025-03-15 10:07:07,795:INFO:_master_model_container: 3
2025-03-15 10:07:07,795:INFO:_display_container: 2
2025-03-15 10:07:07,795:INFO:Ridge(random_state=123)
2025-03-15 10:07:07,795:INFO:create_model() successfully completed......................................
2025-03-15 10:07:07,854:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:07,854:INFO:Creating metrics dataframe
2025-03-15 10:07:07,859:INFO:Initializing Elastic Net
2025-03-15 10:07:07,859:INFO:Total runtime is 0.0736188530921936 minutes
2025-03-15 10:07:07,862:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:07,862:INFO:Initializing create_model()
2025-03-15 10:07:07,862:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=en, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:07,862:INFO:Checking exceptions
2025-03-15 10:07:07,862:INFO:Importing libraries
2025-03-15 10:07:07,862:INFO:Copying training dataset
2025-03-15 10:07:07,868:INFO:Defining folds
2025-03-15 10:07:07,868:INFO:Declaring metric variables
2025-03-15 10:07:07,870:INFO:Importing untrained model
2025-03-15 10:07:07,873:INFO:Elastic Net Imported successfully
2025-03-15 10:07:07,877:INFO:Starting cross validation
2025-03-15 10:07:07,877:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:08,159:INFO:Calculating mean and std
2025-03-15 10:07:08,160:INFO:Creating metrics dataframe
2025-03-15 10:07:08,161:INFO:Uploading results into container
2025-03-15 10:07:08,161:INFO:Uploading model into container now
2025-03-15 10:07:08,162:INFO:_master_model_container: 4
2025-03-15 10:07:08,162:INFO:_display_container: 2
2025-03-15 10:07:08,162:INFO:ElasticNet(random_state=123)
2025-03-15 10:07:08,162:INFO:create_model() successfully completed......................................
2025-03-15 10:07:08,222:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:08,222:INFO:Creating metrics dataframe
2025-03-15 10:07:08,229:INFO:Initializing Least Angle Regression
2025-03-15 10:07:08,229:INFO:Total runtime is 0.07977848847707113 minutes
2025-03-15 10:07:08,231:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:08,231:INFO:Initializing create_model()
2025-03-15 10:07:08,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=lar, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:08,231:INFO:Checking exceptions
2025-03-15 10:07:08,231:INFO:Importing libraries
2025-03-15 10:07:08,231:INFO:Copying training dataset
2025-03-15 10:07:08,240:INFO:Defining folds
2025-03-15 10:07:08,240:INFO:Declaring metric variables
2025-03-15 10:07:08,244:INFO:Importing untrained model
2025-03-15 10:07:08,247:INFO:Least Angle Regression Imported successfully
2025-03-15 10:07:08,253:INFO:Starting cross validation
2025-03-15 10:07:08,253:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:08,459:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=5.205e-02, with an active set of 46 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,459:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.643e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,459:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.115e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,460:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=9.713e-03, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,461:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.226e-03, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,461:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=8.067e-03, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,462:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=4.694e-03, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,463:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.024e-02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,463:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=9.716e+07, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,463:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.031e-03, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,466:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.508e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,467:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.133e-02, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,470:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.738e+06, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,470:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.966e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,472:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.732e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,473:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.310e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,474:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=3.847e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,474:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=8.917e-02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,477:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=1.260e-01, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,478:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.056e+03, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,479:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.072e+03, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,479:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=2.081e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,479:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=1.961e+01, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,482:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.575e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,483:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.057e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,490:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=5.030e+07, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,490:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=4.871e+07, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,507:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.326e-01, with an active set of 42 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,507:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.457e-02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,508:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.058e-01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,510:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.135e-01, with an active set of 49 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,511:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.204e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,511:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=1.201e+02, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,512:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=9.775e-02, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,512:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=1.617e-01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,512:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=7.028e-02, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,512:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=2.061e-01, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,514:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=3.725e+02, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,514:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=8.103e+09, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,532:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=1.734e+09, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,552:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.706e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,552:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.483e+00, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,555:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=2.088e+04, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,572:INFO:Calculating mean and std
2025-03-15 10:07:08,572:INFO:Creating metrics dataframe
2025-03-15 10:07:08,574:INFO:Uploading results into container
2025-03-15 10:07:08,574:INFO:Uploading model into container now
2025-03-15 10:07:08,575:INFO:_master_model_container: 5
2025-03-15 10:07:08,575:INFO:_display_container: 2
2025-03-15 10:07:08,575:INFO:Lars(random_state=123)
2025-03-15 10:07:08,575:INFO:create_model() successfully completed......................................
2025-03-15 10:07:08,636:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:08,636:INFO:Creating metrics dataframe
2025-03-15 10:07:08,643:INFO:Initializing Lasso Least Angle Regression
2025-03-15 10:07:08,643:INFO:Total runtime is 0.08669157028198242 minutes
2025-03-15 10:07:08,646:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:08,646:INFO:Initializing create_model()
2025-03-15 10:07:08,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=llar, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:08,646:INFO:Checking exceptions
2025-03-15 10:07:08,646:INFO:Importing libraries
2025-03-15 10:07:08,646:INFO:Copying training dataset
2025-03-15 10:07:08,652:INFO:Defining folds
2025-03-15 10:07:08,652:INFO:Declaring metric variables
2025-03-15 10:07:08,658:INFO:Importing untrained model
2025-03-15 10:07:08,662:INFO:Lasso Least Angle Regression Imported successfully
2025-03-15 10:07:08,666:INFO:Starting cross validation
2025-03-15 10:07:08,668:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:08,877:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.966e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,880:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.653e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,911:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 26 iterations, alpha=1.617e+00, previous alpha=1.572e+00, with an active set of 23 regressors.
  warnings.warn(

2025-03-15 10:07:08,914:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.506e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,914:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.317e+00, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2025-03-15 10:07:08,944:INFO:Calculating mean and std
2025-03-15 10:07:08,944:INFO:Creating metrics dataframe
2025-03-15 10:07:08,946:INFO:Uploading results into container
2025-03-15 10:07:08,947:INFO:Uploading model into container now
2025-03-15 10:07:08,947:INFO:_master_model_container: 6
2025-03-15 10:07:08,947:INFO:_display_container: 2
2025-03-15 10:07:08,947:INFO:LassoLars(random_state=123)
2025-03-15 10:07:08,947:INFO:create_model() successfully completed......................................
2025-03-15 10:07:09,004:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:09,004:INFO:Creating metrics dataframe
2025-03-15 10:07:09,010:INFO:Initializing Orthogonal Matching Pursuit
2025-03-15 10:07:09,010:INFO:Total runtime is 0.09280726114908854 minutes
2025-03-15 10:07:09,012:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:09,013:INFO:Initializing create_model()
2025-03-15 10:07:09,013:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=omp, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:09,013:INFO:Checking exceptions
2025-03-15 10:07:09,013:INFO:Importing libraries
2025-03-15 10:07:09,013:INFO:Copying training dataset
2025-03-15 10:07:09,019:INFO:Defining folds
2025-03-15 10:07:09,019:INFO:Declaring metric variables
2025-03-15 10:07:09,021:INFO:Importing untrained model
2025-03-15 10:07:09,023:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-15 10:07:09,027:INFO:Starting cross validation
2025-03-15 10:07:09,027:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:09,273:INFO:Calculating mean and std
2025-03-15 10:07:09,274:INFO:Creating metrics dataframe
2025-03-15 10:07:09,275:INFO:Uploading results into container
2025-03-15 10:07:09,275:INFO:Uploading model into container now
2025-03-15 10:07:09,275:INFO:_master_model_container: 7
2025-03-15 10:07:09,275:INFO:_display_container: 2
2025-03-15 10:07:09,275:INFO:OrthogonalMatchingPursuit()
2025-03-15 10:07:09,277:INFO:create_model() successfully completed......................................
2025-03-15 10:07:09,332:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:09,333:INFO:Creating metrics dataframe
2025-03-15 10:07:09,339:INFO:Initializing Bayesian Ridge
2025-03-15 10:07:09,339:INFO:Total runtime is 0.0982832948366801 minutes
2025-03-15 10:07:09,342:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:09,342:INFO:Initializing create_model()
2025-03-15 10:07:09,342:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=br, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:09,342:INFO:Checking exceptions
2025-03-15 10:07:09,342:INFO:Importing libraries
2025-03-15 10:07:09,342:INFO:Copying training dataset
2025-03-15 10:07:09,349:INFO:Defining folds
2025-03-15 10:07:09,349:INFO:Declaring metric variables
2025-03-15 10:07:09,351:INFO:Importing untrained model
2025-03-15 10:07:09,353:INFO:Bayesian Ridge Imported successfully
2025-03-15 10:07:09,358:INFO:Starting cross validation
2025-03-15 10:07:09,359:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:09,614:INFO:Calculating mean and std
2025-03-15 10:07:09,614:INFO:Creating metrics dataframe
2025-03-15 10:07:09,615:INFO:Uploading results into container
2025-03-15 10:07:09,615:INFO:Uploading model into container now
2025-03-15 10:07:09,617:INFO:_master_model_container: 8
2025-03-15 10:07:09,617:INFO:_display_container: 2
2025-03-15 10:07:09,617:INFO:BayesianRidge()
2025-03-15 10:07:09,617:INFO:create_model() successfully completed......................................
2025-03-15 10:07:09,677:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:09,677:INFO:Creating metrics dataframe
2025-03-15 10:07:09,683:INFO:Initializing Passive Aggressive Regressor
2025-03-15 10:07:09,683:INFO:Total runtime is 0.10401340723037719 minutes
2025-03-15 10:07:09,685:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:09,687:INFO:Initializing create_model()
2025-03-15 10:07:09,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=par, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:09,687:INFO:Checking exceptions
2025-03-15 10:07:09,687:INFO:Importing libraries
2025-03-15 10:07:09,687:INFO:Copying training dataset
2025-03-15 10:07:09,694:INFO:Defining folds
2025-03-15 10:07:09,694:INFO:Declaring metric variables
2025-03-15 10:07:09,698:INFO:Importing untrained model
2025-03-15 10:07:09,700:INFO:Passive Aggressive Regressor Imported successfully
2025-03-15 10:07:09,704:INFO:Starting cross validation
2025-03-15 10:07:09,705:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:09,942:INFO:Calculating mean and std
2025-03-15 10:07:09,942:INFO:Creating metrics dataframe
2025-03-15 10:07:09,943:INFO:Uploading results into container
2025-03-15 10:07:09,943:INFO:Uploading model into container now
2025-03-15 10:07:09,945:INFO:_master_model_container: 9
2025-03-15 10:07:09,945:INFO:_display_container: 2
2025-03-15 10:07:09,945:INFO:PassiveAggressiveRegressor(random_state=123)
2025-03-15 10:07:09,945:INFO:create_model() successfully completed......................................
2025-03-15 10:07:10,007:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:10,007:INFO:Creating metrics dataframe
2025-03-15 10:07:10,013:INFO:Initializing Huber Regressor
2025-03-15 10:07:10,013:INFO:Total runtime is 0.10952090422312417 minutes
2025-03-15 10:07:10,016:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:10,016:INFO:Initializing create_model()
2025-03-15 10:07:10,016:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=huber, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:10,016:INFO:Checking exceptions
2025-03-15 10:07:10,016:INFO:Importing libraries
2025-03-15 10:07:10,016:INFO:Copying training dataset
2025-03-15 10:07:10,024:INFO:Defining folds
2025-03-15 10:07:10,024:INFO:Declaring metric variables
2025-03-15 10:07:10,025:INFO:Importing untrained model
2025-03-15 10:07:10,028:INFO:Huber Regressor Imported successfully
2025-03-15 10:07:10,032:INFO:Starting cross validation
2025-03-15 10:07:10,034:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:10,257:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 10:07:10,262:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 10:07:10,269:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 10:07:10,281:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 10:07:10,283:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 10:07:10,285:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 10:07:10,288:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 10:07:10,295:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 10:07:10,297:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 10:07:10,301:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 10:07:10,306:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 10:07:10,322:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 10:07:10,337:INFO:Calculating mean and std
2025-03-15 10:07:10,337:INFO:Creating metrics dataframe
2025-03-15 10:07:10,339:INFO:Uploading results into container
2025-03-15 10:07:10,339:INFO:Uploading model into container now
2025-03-15 10:07:10,340:INFO:_master_model_container: 10
2025-03-15 10:07:10,340:INFO:_display_container: 2
2025-03-15 10:07:10,340:INFO:HuberRegressor()
2025-03-15 10:07:10,340:INFO:create_model() successfully completed......................................
2025-03-15 10:07:10,401:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:10,401:INFO:Creating metrics dataframe
2025-03-15 10:07:10,407:INFO:Initializing K Neighbors Regressor
2025-03-15 10:07:10,407:INFO:Total runtime is 0.11607804695765177 minutes
2025-03-15 10:07:10,410:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:10,410:INFO:Initializing create_model()
2025-03-15 10:07:10,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=knn, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:10,410:INFO:Checking exceptions
2025-03-15 10:07:10,410:INFO:Importing libraries
2025-03-15 10:07:10,410:INFO:Copying training dataset
2025-03-15 10:07:10,417:INFO:Defining folds
2025-03-15 10:07:10,417:INFO:Declaring metric variables
2025-03-15 10:07:10,420:INFO:Importing untrained model
2025-03-15 10:07:10,421:INFO:K Neighbors Regressor Imported successfully
2025-03-15 10:07:10,426:INFO:Starting cross validation
2025-03-15 10:07:10,427:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:10,771:INFO:Calculating mean and std
2025-03-15 10:07:10,772:INFO:Creating metrics dataframe
2025-03-15 10:07:10,773:INFO:Uploading results into container
2025-03-15 10:07:10,773:INFO:Uploading model into container now
2025-03-15 10:07:10,773:INFO:_master_model_container: 11
2025-03-15 10:07:10,773:INFO:_display_container: 2
2025-03-15 10:07:10,775:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-15 10:07:10,775:INFO:create_model() successfully completed......................................
2025-03-15 10:07:10,828:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:10,828:INFO:Creating metrics dataframe
2025-03-15 10:07:10,832:INFO:Initializing Decision Tree Regressor
2025-03-15 10:07:10,834:INFO:Total runtime is 0.12319736083348591 minutes
2025-03-15 10:07:10,835:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:10,835:INFO:Initializing create_model()
2025-03-15 10:07:10,835:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=dt, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:10,835:INFO:Checking exceptions
2025-03-15 10:07:10,835:INFO:Importing libraries
2025-03-15 10:07:10,835:INFO:Copying training dataset
2025-03-15 10:07:10,843:INFO:Defining folds
2025-03-15 10:07:10,843:INFO:Declaring metric variables
2025-03-15 10:07:10,844:INFO:Importing untrained model
2025-03-15 10:07:10,846:INFO:Decision Tree Regressor Imported successfully
2025-03-15 10:07:10,851:INFO:Starting cross validation
2025-03-15 10:07:10,851:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:11,106:INFO:Calculating mean and std
2025-03-15 10:07:11,106:INFO:Creating metrics dataframe
2025-03-15 10:07:11,108:INFO:Uploading results into container
2025-03-15 10:07:11,108:INFO:Uploading model into container now
2025-03-15 10:07:11,109:INFO:_master_model_container: 12
2025-03-15 10:07:11,109:INFO:_display_container: 2
2025-03-15 10:07:11,109:INFO:DecisionTreeRegressor(random_state=123)
2025-03-15 10:07:11,109:INFO:create_model() successfully completed......................................
2025-03-15 10:07:11,166:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:11,166:INFO:Creating metrics dataframe
2025-03-15 10:07:11,175:INFO:Initializing Random Forest Regressor
2025-03-15 10:07:11,175:INFO:Total runtime is 0.1288811484972636 minutes
2025-03-15 10:07:11,178:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:11,178:INFO:Initializing create_model()
2025-03-15 10:07:11,178:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=rf, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:11,179:INFO:Checking exceptions
2025-03-15 10:07:11,179:INFO:Importing libraries
2025-03-15 10:07:11,179:INFO:Copying training dataset
2025-03-15 10:07:11,190:INFO:Defining folds
2025-03-15 10:07:11,190:INFO:Declaring metric variables
2025-03-15 10:07:11,193:INFO:Importing untrained model
2025-03-15 10:07:11,194:INFO:Random Forest Regressor Imported successfully
2025-03-15 10:07:11,199:INFO:Starting cross validation
2025-03-15 10:07:11,200:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:12,663:INFO:Calculating mean and std
2025-03-15 10:07:12,663:INFO:Creating metrics dataframe
2025-03-15 10:07:12,665:INFO:Uploading results into container
2025-03-15 10:07:12,666:INFO:Uploading model into container now
2025-03-15 10:07:12,666:INFO:_master_model_container: 13
2025-03-15 10:07:12,666:INFO:_display_container: 2
2025-03-15 10:07:12,666:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-15 10:07:12,668:INFO:create_model() successfully completed......................................
2025-03-15 10:07:12,721:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:12,722:INFO:Creating metrics dataframe
2025-03-15 10:07:12,728:INFO:Initializing Extra Trees Regressor
2025-03-15 10:07:12,728:INFO:Total runtime is 0.1547755757967631 minutes
2025-03-15 10:07:12,731:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:12,731:INFO:Initializing create_model()
2025-03-15 10:07:12,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=et, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:12,731:INFO:Checking exceptions
2025-03-15 10:07:12,731:INFO:Importing libraries
2025-03-15 10:07:12,731:INFO:Copying training dataset
2025-03-15 10:07:12,739:INFO:Defining folds
2025-03-15 10:07:12,741:INFO:Declaring metric variables
2025-03-15 10:07:12,742:INFO:Importing untrained model
2025-03-15 10:07:12,744:INFO:Extra Trees Regressor Imported successfully
2025-03-15 10:07:12,749:INFO:Starting cross validation
2025-03-15 10:07:12,749:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:13,576:INFO:Calculating mean and std
2025-03-15 10:07:13,576:INFO:Creating metrics dataframe
2025-03-15 10:07:13,578:INFO:Uploading results into container
2025-03-15 10:07:13,578:INFO:Uploading model into container now
2025-03-15 10:07:13,579:INFO:_master_model_container: 14
2025-03-15 10:07:13,579:INFO:_display_container: 2
2025-03-15 10:07:13,579:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-15 10:07:13,579:INFO:create_model() successfully completed......................................
2025-03-15 10:07:13,638:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:13,638:INFO:Creating metrics dataframe
2025-03-15 10:07:13,644:INFO:Initializing AdaBoost Regressor
2025-03-15 10:07:13,644:INFO:Total runtime is 0.17004132668177285 minutes
2025-03-15 10:07:13,647:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:13,647:INFO:Initializing create_model()
2025-03-15 10:07:13,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=ada, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:13,647:INFO:Checking exceptions
2025-03-15 10:07:13,647:INFO:Importing libraries
2025-03-15 10:07:13,649:INFO:Copying training dataset
2025-03-15 10:07:13,655:INFO:Defining folds
2025-03-15 10:07:13,655:INFO:Declaring metric variables
2025-03-15 10:07:13,656:INFO:Importing untrained model
2025-03-15 10:07:13,660:INFO:AdaBoost Regressor Imported successfully
2025-03-15 10:07:13,663:INFO:Starting cross validation
2025-03-15 10:07:13,664:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:14,210:INFO:Calculating mean and std
2025-03-15 10:07:14,210:INFO:Creating metrics dataframe
2025-03-15 10:07:14,212:INFO:Uploading results into container
2025-03-15 10:07:14,213:INFO:Uploading model into container now
2025-03-15 10:07:14,213:INFO:_master_model_container: 15
2025-03-15 10:07:14,213:INFO:_display_container: 2
2025-03-15 10:07:14,215:INFO:AdaBoostRegressor(random_state=123)
2025-03-15 10:07:14,215:INFO:create_model() successfully completed......................................
2025-03-15 10:07:14,276:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:14,276:INFO:Creating metrics dataframe
2025-03-15 10:07:14,284:INFO:Initializing Gradient Boosting Regressor
2025-03-15 10:07:14,285:INFO:Total runtime is 0.1807198405265808 minutes
2025-03-15 10:07:14,290:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:14,290:INFO:Initializing create_model()
2025-03-15 10:07:14,290:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=gbr, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:14,290:INFO:Checking exceptions
2025-03-15 10:07:14,290:INFO:Importing libraries
2025-03-15 10:07:14,290:INFO:Copying training dataset
2025-03-15 10:07:14,301:INFO:Defining folds
2025-03-15 10:07:14,301:INFO:Declaring metric variables
2025-03-15 10:07:14,304:INFO:Importing untrained model
2025-03-15 10:07:14,307:INFO:Gradient Boosting Regressor Imported successfully
2025-03-15 10:07:14,313:INFO:Starting cross validation
2025-03-15 10:07:14,315:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:15,234:INFO:Calculating mean and std
2025-03-15 10:07:15,234:INFO:Creating metrics dataframe
2025-03-15 10:07:15,235:INFO:Uploading results into container
2025-03-15 10:07:15,235:INFO:Uploading model into container now
2025-03-15 10:07:15,237:INFO:_master_model_container: 16
2025-03-15 10:07:15,237:INFO:_display_container: 2
2025-03-15 10:07:15,237:INFO:GradientBoostingRegressor(random_state=123)
2025-03-15 10:07:15,237:INFO:create_model() successfully completed......................................
2025-03-15 10:07:15,296:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:15,296:INFO:Creating metrics dataframe
2025-03-15 10:07:15,302:INFO:Initializing Light Gradient Boosting Machine
2025-03-15 10:07:15,302:INFO:Total runtime is 0.1976645270983378 minutes
2025-03-15 10:07:15,305:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:15,305:INFO:Initializing create_model()
2025-03-15 10:07:15,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=lightgbm, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:15,305:INFO:Checking exceptions
2025-03-15 10:07:15,305:INFO:Importing libraries
2025-03-15 10:07:15,305:INFO:Copying training dataset
2025-03-15 10:07:15,312:INFO:Defining folds
2025-03-15 10:07:15,312:INFO:Declaring metric variables
2025-03-15 10:07:15,314:INFO:Importing untrained model
2025-03-15 10:07:15,317:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-15 10:07:15,321:INFO:Starting cross validation
2025-03-15 10:07:15,321:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:16,251:INFO:Calculating mean and std
2025-03-15 10:07:16,253:INFO:Creating metrics dataframe
2025-03-15 10:07:16,255:INFO:Uploading results into container
2025-03-15 10:07:16,255:INFO:Uploading model into container now
2025-03-15 10:07:16,255:INFO:_master_model_container: 17
2025-03-15 10:07:16,256:INFO:_display_container: 2
2025-03-15 10:07:16,256:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-15 10:07:16,256:INFO:create_model() successfully completed......................................
2025-03-15 10:07:16,329:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:16,329:INFO:Creating metrics dataframe
2025-03-15 10:07:16,340:INFO:Initializing Dummy Regressor
2025-03-15 10:07:16,340:INFO:Total runtime is 0.2149618665377299 minutes
2025-03-15 10:07:16,344:INFO:SubProcess create_model() called ==================================
2025-03-15 10:07:16,344:INFO:Initializing create_model()
2025-03-15 10:07:16,344:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=dummy, fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018C8391B010>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:16,344:INFO:Checking exceptions
2025-03-15 10:07:16,344:INFO:Importing libraries
2025-03-15 10:07:16,344:INFO:Copying training dataset
2025-03-15 10:07:16,354:INFO:Defining folds
2025-03-15 10:07:16,354:INFO:Declaring metric variables
2025-03-15 10:07:16,357:INFO:Importing untrained model
2025-03-15 10:07:16,360:INFO:Dummy Regressor Imported successfully
2025-03-15 10:07:16,364:INFO:Starting cross validation
2025-03-15 10:07:16,364:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:16,595:INFO:Calculating mean and std
2025-03-15 10:07:16,595:INFO:Creating metrics dataframe
2025-03-15 10:07:16,596:INFO:Uploading results into container
2025-03-15 10:07:16,596:INFO:Uploading model into container now
2025-03-15 10:07:16,598:INFO:_master_model_container: 18
2025-03-15 10:07:16,598:INFO:_display_container: 2
2025-03-15 10:07:16,598:INFO:DummyRegressor()
2025-03-15 10:07:16,598:INFO:create_model() successfully completed......................................
2025-03-15 10:07:16,655:INFO:SubProcess create_model() end ==================================
2025-03-15 10:07:16,655:INFO:Creating metrics dataframe
2025-03-15 10:07:16,663:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-03-15 10:07:16,669:INFO:Initializing create_model()
2025-03-15 10:07:16,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:16,669:INFO:Checking exceptions
2025-03-15 10:07:16,671:INFO:Importing libraries
2025-03-15 10:07:16,671:INFO:Copying training dataset
2025-03-15 10:07:16,677:INFO:Defining folds
2025-03-15 10:07:16,677:INFO:Declaring metric variables
2025-03-15 10:07:16,677:INFO:Importing untrained model
2025-03-15 10:07:16,677:INFO:Declaring custom model
2025-03-15 10:07:16,677:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-15 10:07:16,677:INFO:Cross validation set to False
2025-03-15 10:07:16,677:INFO:Fitting Model
2025-03-15 10:07:16,783:INFO:OrthogonalMatchingPursuit()
2025-03-15 10:07:16,783:INFO:create_model() successfully completed......................................
2025-03-15 10:07:16,844:INFO:Initializing create_model()
2025-03-15 10:07:16,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=AdaBoostRegressor(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:16,844:INFO:Checking exceptions
2025-03-15 10:07:16,845:INFO:Importing libraries
2025-03-15 10:07:16,845:INFO:Copying training dataset
2025-03-15 10:07:16,852:INFO:Defining folds
2025-03-15 10:07:16,852:INFO:Declaring metric variables
2025-03-15 10:07:16,852:INFO:Importing untrained model
2025-03-15 10:07:16,852:INFO:Declaring custom model
2025-03-15 10:07:16,852:INFO:AdaBoost Regressor Imported successfully
2025-03-15 10:07:16,852:INFO:Cross validation set to False
2025-03-15 10:07:16,852:INFO:Fitting Model
2025-03-15 10:07:17,141:INFO:AdaBoostRegressor(random_state=123)
2025-03-15 10:07:17,141:INFO:create_model() successfully completed......................................
2025-03-15 10:07:17,208:INFO:Initializing create_model()
2025-03-15 10:07:17,208:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:17,208:INFO:Checking exceptions
2025-03-15 10:07:17,210:INFO:Importing libraries
2025-03-15 10:07:17,210:INFO:Copying training dataset
2025-03-15 10:07:17,216:INFO:Defining folds
2025-03-15 10:07:17,216:INFO:Declaring metric variables
2025-03-15 10:07:17,216:INFO:Importing untrained model
2025-03-15 10:07:17,217:INFO:Declaring custom model
2025-03-15 10:07:17,217:INFO:Extra Trees Regressor Imported successfully
2025-03-15 10:07:17,217:INFO:Cross validation set to False
2025-03-15 10:07:17,217:INFO:Fitting Model
2025-03-15 10:07:17,408:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-15 10:07:17,408:INFO:create_model() successfully completed......................................
2025-03-15 10:07:17,470:INFO:Initializing create_model()
2025-03-15 10:07:17,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=BayesianRidge(), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:17,470:INFO:Checking exceptions
2025-03-15 10:07:17,472:INFO:Importing libraries
2025-03-15 10:07:17,472:INFO:Copying training dataset
2025-03-15 10:07:17,481:INFO:Defining folds
2025-03-15 10:07:17,481:INFO:Declaring metric variables
2025-03-15 10:07:17,481:INFO:Importing untrained model
2025-03-15 10:07:17,481:INFO:Declaring custom model
2025-03-15 10:07:17,481:INFO:Bayesian Ridge Imported successfully
2025-03-15 10:07:17,481:INFO:Cross validation set to False
2025-03-15 10:07:17,481:INFO:Fitting Model
2025-03-15 10:07:17,603:INFO:BayesianRidge()
2025-03-15 10:07:17,603:INFO:create_model() successfully completed......................................
2025-03-15 10:07:17,667:INFO:Initializing create_model()
2025-03-15 10:07:17,667:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=LassoLars(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:17,668:INFO:Checking exceptions
2025-03-15 10:07:17,670:INFO:Importing libraries
2025-03-15 10:07:17,670:INFO:Copying training dataset
2025-03-15 10:07:17,681:INFO:Defining folds
2025-03-15 10:07:17,681:INFO:Declaring metric variables
2025-03-15 10:07:17,681:INFO:Importing untrained model
2025-03-15 10:07:17,681:INFO:Declaring custom model
2025-03-15 10:07:17,681:INFO:Lasso Least Angle Regression Imported successfully
2025-03-15 10:07:17,681:INFO:Cross validation set to False
2025-03-15 10:07:17,681:INFO:Fitting Model
2025-03-15 10:07:17,784:INFO:LassoLars(random_state=123)
2025-03-15 10:07:17,784:INFO:create_model() successfully completed......................................
2025-03-15 10:07:17,848:INFO:Initializing create_model()
2025-03-15 10:07:17,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=Lasso(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:17,849:INFO:Checking exceptions
2025-03-15 10:07:17,851:INFO:Importing libraries
2025-03-15 10:07:17,851:INFO:Copying training dataset
2025-03-15 10:07:17,858:INFO:Defining folds
2025-03-15 10:07:17,858:INFO:Declaring metric variables
2025-03-15 10:07:17,858:INFO:Importing untrained model
2025-03-15 10:07:17,858:INFO:Declaring custom model
2025-03-15 10:07:17,860:INFO:Lasso Regression Imported successfully
2025-03-15 10:07:17,860:INFO:Cross validation set to False
2025-03-15 10:07:17,860:INFO:Fitting Model
2025-03-15 10:07:17,967:INFO:Lasso(random_state=123)
2025-03-15 10:07:17,967:INFO:create_model() successfully completed......................................
2025-03-15 10:07:18,039:INFO:Initializing create_model()
2025-03-15 10:07:18,040:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:18,040:INFO:Checking exceptions
2025-03-15 10:07:18,040:INFO:Importing libraries
2025-03-15 10:07:18,040:INFO:Copying training dataset
2025-03-15 10:07:18,050:INFO:Defining folds
2025-03-15 10:07:18,050:INFO:Declaring metric variables
2025-03-15 10:07:18,050:INFO:Importing untrained model
2025-03-15 10:07:18,050:INFO:Declaring custom model
2025-03-15 10:07:18,051:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-15 10:07:18,052:INFO:Cross validation set to False
2025-03-15 10:07:18,052:INFO:Fitting Model
2025-03-15 10:07:18,164:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000527 seconds.
2025-03-15 10:07:18,166:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-15 10:07:18,166:INFO:[LightGBM] [Info] Total Bins 5183
2025-03-15 10:07:18,167:INFO:[LightGBM] [Info] Number of data points in the train set: 332, number of used features: 59
2025-03-15 10:07:18,167:INFO:[LightGBM] [Info] Start training from score 20.304244
2025-03-15 10:07:18,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:18,216:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-15 10:07:18,216:INFO:create_model() successfully completed......................................
2025-03-15 10:07:18,286:INFO:Initializing create_model()
2025-03-15 10:07:18,286:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=HuberRegressor(), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:18,286:INFO:Checking exceptions
2025-03-15 10:07:18,287:INFO:Importing libraries
2025-03-15 10:07:18,287:INFO:Copying training dataset
2025-03-15 10:07:18,295:INFO:Defining folds
2025-03-15 10:07:18,295:INFO:Declaring metric variables
2025-03-15 10:07:18,296:INFO:Importing untrained model
2025-03-15 10:07:18,296:INFO:Declaring custom model
2025-03-15 10:07:18,296:INFO:Huber Regressor Imported successfully
2025-03-15 10:07:18,297:INFO:Cross validation set to False
2025-03-15 10:07:18,297:INFO:Fitting Model
2025-03-15 10:07:18,440:WARNING:d:\Normal File\Coder\MINI_PROJECT_1-2\pycaret_venv\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 10:07:18,440:INFO:HuberRegressor()
2025-03-15 10:07:18,440:INFO:create_model() successfully completed......................................
2025-03-15 10:07:18,501:INFO:Initializing create_model()
2025-03-15 10:07:18,501:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:18,501:INFO:Checking exceptions
2025-03-15 10:07:18,503:INFO:Importing libraries
2025-03-15 10:07:18,503:INFO:Copying training dataset
2025-03-15 10:07:18,507:INFO:Defining folds
2025-03-15 10:07:18,507:INFO:Declaring metric variables
2025-03-15 10:07:18,509:INFO:Importing untrained model
2025-03-15 10:07:18,509:INFO:Declaring custom model
2025-03-15 10:07:18,509:INFO:Gradient Boosting Regressor Imported successfully
2025-03-15 10:07:18,509:INFO:Cross validation set to False
2025-03-15 10:07:18,509:INFO:Fitting Model
2025-03-15 10:07:19,144:INFO:GradientBoostingRegressor(random_state=123)
2025-03-15 10:07:19,144:INFO:create_model() successfully completed......................................
2025-03-15 10:07:19,214:INFO:Initializing create_model()
2025-03-15 10:07:19,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=ElasticNet(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:19,214:INFO:Checking exceptions
2025-03-15 10:07:19,215:INFO:Importing libraries
2025-03-15 10:07:19,215:INFO:Copying training dataset
2025-03-15 10:07:19,223:INFO:Defining folds
2025-03-15 10:07:19,223:INFO:Declaring metric variables
2025-03-15 10:07:19,223:INFO:Importing untrained model
2025-03-15 10:07:19,223:INFO:Declaring custom model
2025-03-15 10:07:19,223:INFO:Elastic Net Imported successfully
2025-03-15 10:07:19,223:INFO:Cross validation set to False
2025-03-15 10:07:19,224:INFO:Fitting Model
2025-03-15 10:07:19,356:INFO:ElasticNet(random_state=123)
2025-03-15 10:07:19,356:INFO:create_model() successfully completed......................................
2025-03-15 10:07:19,414:INFO:Initializing create_model()
2025-03-15 10:07:19,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:19,414:INFO:Checking exceptions
2025-03-15 10:07:19,415:INFO:Importing libraries
2025-03-15 10:07:19,415:INFO:Copying training dataset
2025-03-15 10:07:19,421:INFO:Defining folds
2025-03-15 10:07:19,421:INFO:Declaring metric variables
2025-03-15 10:07:19,421:INFO:Importing untrained model
2025-03-15 10:07:19,421:INFO:Declaring custom model
2025-03-15 10:07:19,421:INFO:Random Forest Regressor Imported successfully
2025-03-15 10:07:19,421:INFO:Cross validation set to False
2025-03-15 10:07:19,421:INFO:Fitting Model
2025-03-15 10:07:19,669:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-15 10:07:19,669:INFO:create_model() successfully completed......................................
2025-03-15 10:07:19,728:INFO:Initializing create_model()
2025-03-15 10:07:19,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=Ridge(random_state=123), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:19,728:INFO:Checking exceptions
2025-03-15 10:07:19,729:INFO:Importing libraries
2025-03-15 10:07:19,729:INFO:Copying training dataset
2025-03-15 10:07:19,736:INFO:Defining folds
2025-03-15 10:07:19,736:INFO:Declaring metric variables
2025-03-15 10:07:19,736:INFO:Importing untrained model
2025-03-15 10:07:19,736:INFO:Declaring custom model
2025-03-15 10:07:19,737:INFO:Ridge Regression Imported successfully
2025-03-15 10:07:19,737:INFO:Cross validation set to False
2025-03-15 10:07:19,737:INFO:Fitting Model
2025-03-15 10:07:19,843:INFO:Ridge(random_state=123)
2025-03-15 10:07:19,843:INFO:create_model() successfully completed......................................
2025-03-15 10:07:19,906:INFO:Initializing create_model()
2025-03-15 10:07:19,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:19,906:INFO:Checking exceptions
2025-03-15 10:07:19,908:INFO:Importing libraries
2025-03-15 10:07:19,908:INFO:Copying training dataset
2025-03-15 10:07:19,914:INFO:Defining folds
2025-03-15 10:07:19,914:INFO:Declaring metric variables
2025-03-15 10:07:19,914:INFO:Importing untrained model
2025-03-15 10:07:19,914:INFO:Declaring custom model
2025-03-15 10:07:19,914:INFO:Linear Regression Imported successfully
2025-03-15 10:07:19,915:INFO:Cross validation set to False
2025-03-15 10:07:19,915:INFO:Fitting Model
2025-03-15 10:07:20,023:INFO:LinearRegression(n_jobs=-1)
2025-03-15 10:07:20,023:INFO:create_model() successfully completed......................................
2025-03-15 10:07:20,087:INFO:Initializing create_model()
2025-03-15 10:07:20,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=KNeighborsRegressor(n_jobs=-1), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:20,087:INFO:Checking exceptions
2025-03-15 10:07:20,088:INFO:Importing libraries
2025-03-15 10:07:20,088:INFO:Copying training dataset
2025-03-15 10:07:20,094:INFO:Defining folds
2025-03-15 10:07:20,094:INFO:Declaring metric variables
2025-03-15 10:07:20,094:INFO:Importing untrained model
2025-03-15 10:07:20,094:INFO:Declaring custom model
2025-03-15 10:07:20,094:INFO:K Neighbors Regressor Imported successfully
2025-03-15 10:07:20,094:INFO:Cross validation set to False
2025-03-15 10:07:20,094:INFO:Fitting Model
2025-03-15 10:07:20,192:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-15 10:07:20,192:INFO:create_model() successfully completed......................................
2025-03-15 10:07:20,255:INFO:Initializing create_model()
2025-03-15 10:07:20,255:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=DummyRegressor(), fold=KFold(n_splits=12, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:20,255:INFO:Checking exceptions
2025-03-15 10:07:20,258:INFO:Importing libraries
2025-03-15 10:07:20,258:INFO:Copying training dataset
2025-03-15 10:07:20,265:INFO:Defining folds
2025-03-15 10:07:20,265:INFO:Declaring metric variables
2025-03-15 10:07:20,265:INFO:Importing untrained model
2025-03-15 10:07:20,265:INFO:Declaring custom model
2025-03-15 10:07:20,265:INFO:Dummy Regressor Imported successfully
2025-03-15 10:07:20,267:INFO:Cross validation set to False
2025-03-15 10:07:20,267:INFO:Fitting Model
2025-03-15 10:07:20,386:INFO:DummyRegressor()
2025-03-15 10:07:20,386:INFO:create_model() successfully completed......................................
2025-03-15 10:07:20,454:INFO:_master_model_container: 18
2025-03-15 10:07:20,454:INFO:_display_container: 2
2025-03-15 10:07:20,457:INFO:[OrthogonalMatchingPursuit(), AdaBoostRegressor(random_state=123), ExtraTreesRegressor(n_jobs=-1, random_state=123), BayesianRidge(), LassoLars(random_state=123), Lasso(random_state=123), LGBMRegressor(n_jobs=-1, random_state=123), HuberRegressor(), GradientBoostingRegressor(random_state=123), ElasticNet(random_state=123), RandomForestRegressor(n_jobs=-1, random_state=123), Ridge(random_state=123), LinearRegression(n_jobs=-1), KNeighborsRegressor(n_jobs=-1), DummyRegressor()]
2025-03-15 10:07:20,457:INFO:compare_models() successfully completed......................................
2025-03-15 10:07:20,469:INFO:Initializing create_model()
2025-03-15 10:07:20,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:20,469:INFO:Checking exceptions
2025-03-15 10:07:20,484:INFO:Importing libraries
2025-03-15 10:07:20,484:INFO:Copying training dataset
2025-03-15 10:07:20,492:INFO:Defining folds
2025-03-15 10:07:20,492:INFO:Declaring metric variables
2025-03-15 10:07:20,496:INFO:Importing untrained model
2025-03-15 10:07:20,499:INFO:Random Forest Regressor Imported successfully
2025-03-15 10:07:20,504:INFO:Starting cross validation
2025-03-15 10:07:20,505:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:21,970:INFO:Calculating mean and std
2025-03-15 10:07:21,970:INFO:Creating metrics dataframe
2025-03-15 10:07:21,973:INFO:Finalizing model
2025-03-15 10:07:22,268:INFO:Uploading results into container
2025-03-15 10:07:22,269:INFO:Uploading model into container now
2025-03-15 10:07:22,275:INFO:_master_model_container: 19
2025-03-15 10:07:22,275:INFO:_display_container: 3
2025-03-15 10:07:22,275:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-03-15 10:07:22,277:INFO:create_model() successfully completed......................................
2025-03-15 10:07:22,364:INFO:Initializing plot_model()
2025-03-15 10:07:22,364:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), plot=learning, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-03-15 10:07:22,364:INFO:Checking exceptions
2025-03-15 10:07:22,384:INFO:Preloading libraries
2025-03-15 10:07:22,392:INFO:Copying training dataset
2025-03-15 10:07:22,392:INFO:Plot type: learning
2025-03-15 10:07:22,515:INFO:Fitting Model
2025-03-15 10:07:31,528:INFO:Visual Rendered Successfully
2025-03-15 10:07:31,607:INFO:plot_model() successfully completed......................................
2025-03-15 10:07:31,695:INFO:Initializing create_model()
2025-03-15 10:07:31,695:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:31,696:INFO:Checking exceptions
2025-03-15 10:07:31,713:INFO:Importing libraries
2025-03-15 10:07:31,713:INFO:Copying training dataset
2025-03-15 10:07:31,725:INFO:Defining folds
2025-03-15 10:07:31,725:INFO:Declaring metric variables
2025-03-15 10:07:31,731:INFO:Importing untrained model
2025-03-15 10:07:31,736:INFO:AdaBoost Regressor Imported successfully
2025-03-15 10:07:31,745:INFO:Starting cross validation
2025-03-15 10:07:31,746:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:32,235:INFO:Calculating mean and std
2025-03-15 10:07:32,235:INFO:Creating metrics dataframe
2025-03-15 10:07:32,238:INFO:Finalizing model
2025-03-15 10:07:32,507:INFO:Uploading results into container
2025-03-15 10:07:32,509:INFO:Uploading model into container now
2025-03-15 10:07:32,516:INFO:_master_model_container: 20
2025-03-15 10:07:32,516:INFO:_display_container: 4
2025-03-15 10:07:32,516:INFO:AdaBoostRegressor(random_state=123)
2025-03-15 10:07:32,516:INFO:create_model() successfully completed......................................
2025-03-15 10:07:32,572:INFO:Initializing create_model()
2025-03-15 10:07:32,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:32,572:INFO:Checking exceptions
2025-03-15 10:07:32,585:INFO:Importing libraries
2025-03-15 10:07:32,587:INFO:Copying training dataset
2025-03-15 10:07:32,600:INFO:Defining folds
2025-03-15 10:07:32,600:INFO:Declaring metric variables
2025-03-15 10:07:32,603:INFO:Importing untrained model
2025-03-15 10:07:32,604:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-15 10:07:32,609:INFO:Starting cross validation
2025-03-15 10:07:32,610:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:33,373:INFO:Calculating mean and std
2025-03-15 10:07:33,373:INFO:Creating metrics dataframe
2025-03-15 10:07:33,377:INFO:Finalizing model
2025-03-15 10:07:33,509:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000552 seconds.
2025-03-15 10:07:33,509:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-03-15 10:07:33,509:INFO:[LightGBM] [Info] Total Bins 5183
2025-03-15 10:07:33,509:INFO:[LightGBM] [Info] Number of data points in the train set: 332, number of used features: 59
2025-03-15 10:07:33,510:INFO:[LightGBM] [Info] Start training from score 20.304244
2025-03-15 10:07:33,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-03-15 10:07:33,569:INFO:Uploading results into container
2025-03-15 10:07:33,569:INFO:Uploading model into container now
2025-03-15 10:07:33,578:INFO:_master_model_container: 21
2025-03-15 10:07:33,578:INFO:_display_container: 5
2025-03-15 10:07:33,578:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-03-15 10:07:33,578:INFO:create_model() successfully completed......................................
2025-03-15 10:07:33,644:INFO:Initializing create_model()
2025-03-15 10:07:33,645:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=br, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:33,645:INFO:Checking exceptions
2025-03-15 10:07:33,656:INFO:Importing libraries
2025-03-15 10:07:33,657:INFO:Copying training dataset
2025-03-15 10:07:33,666:INFO:Defining folds
2025-03-15 10:07:33,666:INFO:Declaring metric variables
2025-03-15 10:07:33,669:INFO:Importing untrained model
2025-03-15 10:07:33,670:INFO:Bayesian Ridge Imported successfully
2025-03-15 10:07:33,674:INFO:Starting cross validation
2025-03-15 10:07:33,674:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:33,941:INFO:Calculating mean and std
2025-03-15 10:07:33,941:INFO:Creating metrics dataframe
2025-03-15 10:07:33,944:INFO:Finalizing model
2025-03-15 10:07:34,054:INFO:Uploading results into container
2025-03-15 10:07:34,055:INFO:Uploading model into container now
2025-03-15 10:07:34,062:INFO:_master_model_container: 22
2025-03-15 10:07:34,062:INFO:_display_container: 6
2025-03-15 10:07:34,062:INFO:BayesianRidge()
2025-03-15 10:07:34,062:INFO:create_model() successfully completed......................................
2025-03-15 10:07:34,118:INFO:Initializing create_model()
2025-03-15 10:07:34,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=et, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 10:07:34,118:INFO:Checking exceptions
2025-03-15 10:07:34,132:INFO:Importing libraries
2025-03-15 10:07:34,132:INFO:Copying training dataset
2025-03-15 10:07:34,142:INFO:Defining folds
2025-03-15 10:07:34,142:INFO:Declaring metric variables
2025-03-15 10:07:34,145:INFO:Importing untrained model
2025-03-15 10:07:34,146:INFO:Extra Trees Regressor Imported successfully
2025-03-15 10:07:34,152:INFO:Starting cross validation
2025-03-15 10:07:34,152:INFO:Cross validating with KFold(n_splits=12, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 10:07:34,981:INFO:Calculating mean and std
2025-03-15 10:07:34,981:INFO:Creating metrics dataframe
2025-03-15 10:07:34,984:INFO:Finalizing model
2025-03-15 10:07:35,186:INFO:Uploading results into container
2025-03-15 10:07:35,186:INFO:Uploading model into container now
2025-03-15 10:07:35,193:INFO:_master_model_container: 23
2025-03-15 10:07:35,193:INFO:_display_container: 7
2025-03-15 10:07:35,195:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-03-15 10:07:35,195:INFO:create_model() successfully completed......................................
2025-03-15 10:07:35,262:INFO:Initializing evaluate_model()
2025-03-15 10:07:35,262:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2025-03-15 10:07:35,292:INFO:Initializing plot_model()
2025-03-15 10:07:35,292:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), plot=pipeline, scale=1, save=False, fold=KFold(n_splits=12, random_state=None, shuffle=False), fit_kwargs={}, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=False, system=True, display=None, display_format=None)
2025-03-15 10:07:35,292:INFO:Checking exceptions
2025-03-15 10:07:35,296:INFO:Preloading libraries
2025-03-15 10:07:35,300:INFO:Copying training dataset
2025-03-15 10:07:35,300:INFO:Plot type: pipeline
2025-03-15 10:07:35,596:INFO:Visual Rendered Successfully
2025-03-15 10:07:35,667:INFO:plot_model() successfully completed......................................
2025-03-15 10:07:35,684:INFO:Initializing predict_model()
2025-03-15 10:07:35,686:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C7F637560>)
2025-03-15 10:07:35,686:INFO:Checking exceptions
2025-03-15 10:07:35,686:INFO:Preloading libraries
2025-03-15 10:07:35,687:INFO:Set up data.
2025-03-15 10:07:35,693:INFO:Set up index.
2025-03-15 10:07:36,058:INFO:Initializing save_model()
2025-03-15 10:07:36,058:INFO:save_model(model=RandomForestRegressor(n_jobs=-1, random_state=123), model_name=pm2_5_model_1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Saeb0m\AppData\Local\Temp\joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['humidity', 'temperature', 'year',
                                             'month', 'day', 'day_of_week',
                                             'week_of_year', 'season',
                                             'dew_point', 'is_weekend',
                                             'tem...
                                             'pm_2_5_lag_4', 'pm_2_5_lag_5',
                                             'pm_2_5_lag_6', 'pm_2_5_lag_7',
                                             'pm_2_5_lag_8', 'pm_2_5_lag_9',
                                             'pm_2_5_lag_10', 'pm_2_5_lag_11',
                                             'pm_2_5_lag_12', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-15 10:07:36,058:INFO:Adding model into prep_pipe
2025-03-15 10:07:36,082:INFO:pm2_5_model_1.pkl saved in current working directory
2025-03-15 10:07:36,087:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['date'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['humidity', 'temperature', 'year',
                                             'month', 'day', 'day_of_week',
                                             'week_of_year', 'season',
                                             'dew_point', 'is_weekend',
                                             'temp_humidity_ratio',
                                             'heat_index', 'rh_index'...
                                             'pm_2_5_lag_8', 'pm_2_5_lag_9',
                                             'pm_2_5_lag_10', 'pm_2_5_lag_11',
                                             'pm_2_5_lag_12', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('trained_model',
                 RandomForestRegressor(n_jobs=-1, random_state=123))])
2025-03-15 10:07:36,087:INFO:save_model() successfully completed......................................
2025-03-15 10:07:36,176:INFO:Initializing predict_model()
2025-03-15 10:07:36,176:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3100>)
2025-03-15 10:07:36,176:INFO:Checking exceptions
2025-03-15 10:07:36,176:INFO:Preloading libraries
2025-03-15 10:07:36,178:INFO:Set up data.
2025-03-15 10:07:36,186:INFO:Set up index.
2025-03-15 10:07:36,309:INFO:Initializing predict_model()
2025-03-15 10:07:36,309:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D37E0>)
2025-03-15 10:07:36,309:INFO:Checking exceptions
2025-03-15 10:07:36,309:INFO:Preloading libraries
2025-03-15 10:07:36,311:INFO:Set up data.
2025-03-15 10:07:36,319:INFO:Set up index.
2025-03-15 10:07:36,432:INFO:Initializing predict_model()
2025-03-15 10:07:36,432:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D2A20>)
2025-03-15 10:07:36,432:INFO:Checking exceptions
2025-03-15 10:07:36,432:INFO:Preloading libraries
2025-03-15 10:07:36,432:INFO:Set up data.
2025-03-15 10:07:36,438:INFO:Set up index.
2025-03-15 10:07:36,553:INFO:Initializing predict_model()
2025-03-15 10:07:36,553:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D2A20>)
2025-03-15 10:07:36,553:INFO:Checking exceptions
2025-03-15 10:07:36,553:INFO:Preloading libraries
2025-03-15 10:07:36,554:INFO:Set up data.
2025-03-15 10:07:36,561:INFO:Set up index.
2025-03-15 10:07:36,678:INFO:Initializing predict_model()
2025-03-15 10:07:36,678:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D2AC0>)
2025-03-15 10:07:36,678:INFO:Checking exceptions
2025-03-15 10:07:36,679:INFO:Preloading libraries
2025-03-15 10:07:36,680:INFO:Set up data.
2025-03-15 10:07:36,686:INFO:Set up index.
2025-03-15 10:07:36,806:INFO:Initializing predict_model()
2025-03-15 10:07:36,806:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D31A0>)
2025-03-15 10:07:36,806:INFO:Checking exceptions
2025-03-15 10:07:36,806:INFO:Preloading libraries
2025-03-15 10:07:36,807:INFO:Set up data.
2025-03-15 10:07:36,813:INFO:Set up index.
2025-03-15 10:07:36,927:INFO:Initializing predict_model()
2025-03-15 10:07:36,927:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D2D40>)
2025-03-15 10:07:36,927:INFO:Checking exceptions
2025-03-15 10:07:36,927:INFO:Preloading libraries
2025-03-15 10:07:36,929:INFO:Set up data.
2025-03-15 10:07:36,935:INFO:Set up index.
2025-03-15 10:07:37,046:INFO:Initializing predict_model()
2025-03-15 10:07:37,046:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D2F20>)
2025-03-15 10:07:37,046:INFO:Checking exceptions
2025-03-15 10:07:37,046:INFO:Preloading libraries
2025-03-15 10:07:37,048:INFO:Set up data.
2025-03-15 10:07:37,056:INFO:Set up index.
2025-03-15 10:07:37,185:INFO:Initializing predict_model()
2025-03-15 10:07:37,185:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3BA0>)
2025-03-15 10:07:37,185:INFO:Checking exceptions
2025-03-15 10:07:37,185:INFO:Preloading libraries
2025-03-15 10:07:37,187:INFO:Set up data.
2025-03-15 10:07:37,196:INFO:Set up index.
2025-03-15 10:07:37,315:INFO:Initializing predict_model()
2025-03-15 10:07:37,315:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3BA0>)
2025-03-15 10:07:37,315:INFO:Checking exceptions
2025-03-15 10:07:37,315:INFO:Preloading libraries
2025-03-15 10:07:37,315:INFO:Set up data.
2025-03-15 10:07:37,321:INFO:Set up index.
2025-03-15 10:07:37,447:INFO:Initializing predict_model()
2025-03-15 10:07:37,447:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3BA0>)
2025-03-15 10:07:37,447:INFO:Checking exceptions
2025-03-15 10:07:37,448:INFO:Preloading libraries
2025-03-15 10:07:37,448:INFO:Set up data.
2025-03-15 10:07:37,457:INFO:Set up index.
2025-03-15 10:07:37,581:INFO:Initializing predict_model()
2025-03-15 10:07:37,581:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3BA0>)
2025-03-15 10:07:37,581:INFO:Checking exceptions
2025-03-15 10:07:37,581:INFO:Preloading libraries
2025-03-15 10:07:37,582:INFO:Set up data.
2025-03-15 10:07:37,588:INFO:Set up index.
2025-03-15 10:07:37,701:INFO:Initializing predict_model()
2025-03-15 10:07:37,701:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3BA0>)
2025-03-15 10:07:37,701:INFO:Checking exceptions
2025-03-15 10:07:37,701:INFO:Preloading libraries
2025-03-15 10:07:37,702:INFO:Set up data.
2025-03-15 10:07:37,708:INFO:Set up index.
2025-03-15 10:07:37,821:INFO:Initializing predict_model()
2025-03-15 10:07:37,821:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3BA0>)
2025-03-15 10:07:37,821:INFO:Checking exceptions
2025-03-15 10:07:37,821:INFO:Preloading libraries
2025-03-15 10:07:37,823:INFO:Set up data.
2025-03-15 10:07:37,829:INFO:Set up index.
2025-03-15 10:07:37,946:INFO:Initializing predict_model()
2025-03-15 10:07:37,946:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D2660>)
2025-03-15 10:07:37,946:INFO:Checking exceptions
2025-03-15 10:07:37,946:INFO:Preloading libraries
2025-03-15 10:07:37,946:INFO:Set up data.
2025-03-15 10:07:37,954:INFO:Set up index.
2025-03-15 10:07:38,073:INFO:Initializing predict_model()
2025-03-15 10:07:38,073:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D2660>)
2025-03-15 10:07:38,073:INFO:Checking exceptions
2025-03-15 10:07:38,073:INFO:Preloading libraries
2025-03-15 10:07:38,074:INFO:Set up data.
2025-03-15 10:07:38,080:INFO:Set up index.
2025-03-15 10:07:38,198:INFO:Initializing predict_model()
2025-03-15 10:07:38,198:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D2660>)
2025-03-15 10:07:38,198:INFO:Checking exceptions
2025-03-15 10:07:38,198:INFO:Preloading libraries
2025-03-15 10:07:38,200:INFO:Set up data.
2025-03-15 10:07:38,206:INFO:Set up index.
2025-03-15 10:07:38,321:INFO:Initializing predict_model()
2025-03-15 10:07:38,321:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3920>)
2025-03-15 10:07:38,321:INFO:Checking exceptions
2025-03-15 10:07:38,321:INFO:Preloading libraries
2025-03-15 10:07:38,322:INFO:Set up data.
2025-03-15 10:07:38,328:INFO:Set up index.
2025-03-15 10:07:38,443:INFO:Initializing predict_model()
2025-03-15 10:07:38,444:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3920>)
2025-03-15 10:07:38,444:INFO:Checking exceptions
2025-03-15 10:07:38,444:INFO:Preloading libraries
2025-03-15 10:07:38,444:INFO:Set up data.
2025-03-15 10:07:38,450:INFO:Set up index.
2025-03-15 10:07:38,564:INFO:Initializing predict_model()
2025-03-15 10:07:38,564:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D28E0>)
2025-03-15 10:07:38,564:INFO:Checking exceptions
2025-03-15 10:07:38,564:INFO:Preloading libraries
2025-03-15 10:07:38,566:INFO:Set up data.
2025-03-15 10:07:38,572:INFO:Set up index.
2025-03-15 10:07:38,688:INFO:Initializing predict_model()
2025-03-15 10:07:38,688:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D2340>)
2025-03-15 10:07:38,688:INFO:Checking exceptions
2025-03-15 10:07:38,688:INFO:Preloading libraries
2025-03-15 10:07:38,688:INFO:Set up data.
2025-03-15 10:07:38,696:INFO:Set up index.
2025-03-15 10:07:38,807:INFO:Initializing predict_model()
2025-03-15 10:07:38,809:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3E20>)
2025-03-15 10:07:38,809:INFO:Checking exceptions
2025-03-15 10:07:38,809:INFO:Preloading libraries
2025-03-15 10:07:38,809:INFO:Set up data.
2025-03-15 10:07:38,815:INFO:Set up index.
2025-03-15 10:07:38,952:INFO:Initializing predict_model()
2025-03-15 10:07:38,952:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3E20>)
2025-03-15 10:07:38,952:INFO:Checking exceptions
2025-03-15 10:07:38,952:INFO:Preloading libraries
2025-03-15 10:07:38,954:INFO:Set up data.
2025-03-15 10:07:38,960:INFO:Set up index.
2025-03-15 10:07:39,078:INFO:Initializing predict_model()
2025-03-15 10:07:39,078:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3E20>)
2025-03-15 10:07:39,078:INFO:Checking exceptions
2025-03-15 10:07:39,078:INFO:Preloading libraries
2025-03-15 10:07:39,080:INFO:Set up data.
2025-03-15 10:07:39,086:INFO:Set up index.
2025-03-15 10:07:39,207:INFO:Initializing predict_model()
2025-03-15 10:07:39,207:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3E20>)
2025-03-15 10:07:39,207:INFO:Checking exceptions
2025-03-15 10:07:39,207:INFO:Preloading libraries
2025-03-15 10:07:39,208:INFO:Set up data.
2025-03-15 10:07:39,214:INFO:Set up index.
2025-03-15 10:07:39,336:INFO:Initializing predict_model()
2025-03-15 10:07:39,336:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D2480>)
2025-03-15 10:07:39,336:INFO:Checking exceptions
2025-03-15 10:07:39,336:INFO:Preloading libraries
2025-03-15 10:07:39,337:INFO:Set up data.
2025-03-15 10:07:39,343:INFO:Set up index.
2025-03-15 10:07:39,462:INFO:Initializing predict_model()
2025-03-15 10:07:39,462:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D2480>)
2025-03-15 10:07:39,462:INFO:Checking exceptions
2025-03-15 10:07:39,462:INFO:Preloading libraries
2025-03-15 10:07:39,463:INFO:Set up data.
2025-03-15 10:07:39,469:INFO:Set up index.
2025-03-15 10:07:39,588:INFO:Initializing predict_model()
2025-03-15 10:07:39,588:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D2A20>)
2025-03-15 10:07:39,588:INFO:Checking exceptions
2025-03-15 10:07:39,588:INFO:Preloading libraries
2025-03-15 10:07:39,590:INFO:Set up data.
2025-03-15 10:07:39,596:INFO:Set up index.
2025-03-15 10:07:39,717:INFO:Initializing predict_model()
2025-03-15 10:07:39,717:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3BA0>)
2025-03-15 10:07:39,717:INFO:Checking exceptions
2025-03-15 10:07:39,717:INFO:Preloading libraries
2025-03-15 10:07:39,718:INFO:Set up data.
2025-03-15 10:07:39,726:INFO:Set up index.
2025-03-15 10:07:39,840:INFO:Initializing predict_model()
2025-03-15 10:07:39,840:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000018C813D5210>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000018C839D3240>)
2025-03-15 10:07:39,840:INFO:Checking exceptions
2025-03-15 10:07:39,840:INFO:Preloading libraries
2025-03-15 10:07:39,841:INFO:Set up data.
2025-03-15 10:07:39,847:INFO:Set up index.
